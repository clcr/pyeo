{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c075ae52-fa2e-4490-acd5-99baaa8fa569",
   "metadata": {
    "id": "c075ae52-fa2e-4490-acd5-99baaa8fa569"
   },
   "source": [
    "# PyEO Forest Alerts: How to detect land cover changes between a time-series of Sentinel-2 images and a baseline image composite from the past using a trained machine learning classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acb1d3-96a5-452a-8914-b176287f3ae7",
   "metadata": {
    "id": "f8acb1d3-96a5-452a-8914-b176287f3ae7",
    "tags": []
   },
   "source": [
    "This notebook was developed for pyeo on a Linux VM for Azure Labs.\n",
    "\n",
    "- This notebook will cover how to query the Sentinel-2 image archive on the Copernicus Data Space Ecosystem (CDSE) to download selected images, and how to download a set of Sentinel-2 images from which we can detect changes in land cover since the baseline image composite.\n",
    "- Only changes from a subset of forest classes to non-forest classes will be identified as a candidate forest alert.\n",
    "- This will be done by classifying the baseline composite and each change detection image using the same machine learning model.\n",
    "- The machine learning model is checked against a change in NDVI over time to increase the confidence in a true forest alert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bd835",
   "metadata": {
    "id": "1f5bd835",
    "tags": []
   },
   "source": [
    "## Downloading and pre-processing a time series of Sentinel-2 images for change detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af63284",
   "metadata": {
    "id": "2af63284"
   },
   "source": [
    "- This section will take us stepwise through the imagery query, download and cloud-masking aspects of the `run_acd_national.py` script, which runs the full PyEO pipeline from the command line in a terminal.  \n",
    "- Jupyter notebooks provide a useful and engaging interface to understand the components of this script, so we will follow an extracted version throughout this notebook.\n",
    "\n",
    "This section comprises several stages:   \n",
    "1. Directory and Variable setup.\n",
    "1. Querying for Sentinel-2 imagery that meets our search criteria.\n",
    "1. Downloading the Sentinel-2 imagery identified from the Query.\n",
    "1. If necessary, preprocess any L1C to L2A by applying atmospheric corrections.\n",
    "1. Cloud-masking the L2A imagery.\n",
    "1. Classification of all Change Detection Images\n",
    "1. Creation of Forest Alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea452e7-c5a0-4d5f-9cda-82333f2b1545",
   "metadata": {
    "id": "9ea452e7-c5a0-4d5f-9cda-82333f2b1545"
   },
   "source": [
    "## Setup: Requirements to use this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "XQzvA2-rWR9W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1726524854310,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "XQzvA2-rWR9W",
    "outputId": "8afd6dfa-98cf-44aa-a6cd-d953f5b03752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cmsstudent/pyeo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pyeo_dir = '/home/cmsstudent/pyeo'\n",
    "os.chdir(pyeo_dir)\n",
    "workdir = os.getcwd()\n",
    "print(workdir)\n",
    "config_path = os.path.join(pyeo_dir, 'pyeo_linux_azure.ini')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f950c",
   "metadata": {
    "id": "8c7f950c"
   },
   "source": [
    "We did this in the previous notebook step-by-step. Here, we initialie the notebook in one code cell to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423f8dec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11006,
     "status": "ok",
     "timestamp": 1726524865307,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "423f8dec",
    "outputId": "7f063af5-ecff-412b-9501-c88b17d9205c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:14:50,710: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:14:50,711: INFO: ---                 PROCESSING START                        ---\n",
      "2024-09-25 16:14:50,712: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:14:50,712: INFO: conda environment path found: /home/cmsstudent/miniconda3//envs/pyeo_env\n",
      "2024-09-25 16:14:50,713: INFO: True\n",
      "2024-09-25 16:14:50,713: INFO: Reading in parameters defined in: /home/cmsstudent/pyeo/pyeo_linux_azure.ini\n",
      "2024-09-25 16:14:50,714: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:14:50,714: INFO: ----------------------------\n",
      "2024-09-25 16:14:50,715: INFO: Contents of the config file:\n",
      "2024-09-25 16:14:50,716: INFO: ----------------------------\n",
      "2024-09-25 16:14:50,716: INFO:   run_mode :  watch_period_seconds\n",
      "2024-09-25 16:14:50,717: INFO:   forest_sentinel :  model\n",
      "2024-09-25 16:14:50,717: INFO:   environment :  sen2cor_path\n",
      "2024-09-25 16:14:50,718: INFO:   raster_processing_parameters :  change_to_classes\n",
      "2024-09-25 16:14:50,719: INFO:   vector_processing_parameters :  minimum_area_to_report_m2\n",
      "2024-09-25 16:14:50,719: INFO:   alerts_sending_options :  whatsapp_list_file\n",
      "2024-09-25 16:14:50,720: INFO:   qsub_processor_options :  nodes=1:ppn=16,vmem=64Gb\n",
      "2024-09-25 16:14:50,720: WARNING:    --do_parallel is depracated\n",
      "2024-09-25 16:14:50,721: INFO:   wall_time_hours :  3\n",
      "2024-09-25 16:14:50,721: INFO:   watch_time_hours :  3\n",
      "2024-09-25 16:14:50,722: INFO:   watch_period_seconds :  60\n",
      "2024-09-25 16:14:50,723: INFO:   --do_tile_intersection selected. It enables Sentinel-2 tile intersection with region of interest (ROI) vector file.\n",
      "2024-09-25 16:14:50,723: WARNING:    --do_raster is depracated\n",
      "2024-09-25 16:14:50,724: WARNING:    --do_dev is depracated\n",
      "2024-09-25 16:14:50,725: INFO:   do_all :  False\n",
      "2024-09-25 16:14:50,725: INFO:   --do_classify selected. It applies the random forest model and creates classification layers\n",
      "2024-09-25 16:14:50,726: INFO:   --do_change selected. It produces change detection layers and report images\n",
      "2024-09-25 16:14:50,727: INFO:     --download_source = dataspace\n",
      "2024-09-25 16:14:50,727: INFO:       change start date : 20240201\n",
      "2024-09-25 16:14:50,728: INFO:       change end date   : TODAY\n",
      "2024-09-25 16:14:50,728: INFO:   --do_download is selected. Download of change detection images enabled\n",
      "2024-09-25 16:14:50,729: WARNING:    --do_update is depracated\n",
      "2024-09-25 16:14:50,729: INFO:   --do_quicklooks selected. It saves image quicklooks for visual quality checking\n",
      "2024-09-25 16:14:50,730: INFO:   do_delete :  False\n",
      "2024-09-25 16:14:50,731: INFO:   --do_zip selected. It archives downloaded and intermediate image products    to reduce disk space usage.\n",
      "2024-09-25 16:14:50,732: INFO:   --build_composite is selected. It makes a baseline image composite\n",
      "2024-09-25 16:14:50,732: INFO:     --download_source = dataspace\n",
      "2024-09-25 16:14:50,733: INFO:       composite start date :  20220101\n",
      "2024-09-25 16:14:50,734: INFO:       composite end date   : 20221231\n",
      "2024-09-25 16:14:50,734: INFO:   build_prob_image :  False\n",
      "2024-09-25 16:14:50,735: INFO:   do_skip_existing :  True\n",
      "2024-09-25 16:14:50,736: INFO:   aoi_name :  Kenya\n",
      "2024-09-25 16:14:50,737: INFO:   start_date :  20240201\n",
      "2024-09-25 16:14:50,737: INFO:   end_date :  TODAY\n",
      "2024-09-25 16:14:50,738: INFO:   composite_start :  20220101\n",
      "2024-09-25 16:14:50,738: INFO:   composite_end :  20221231\n",
      "2024-09-25 16:14:50,739: INFO:   EPSG code for output map projection: 21097\n",
      "2024-09-25 16:14:50,739: INFO:   cloud_cover :  25\n",
      "2024-09-25 16:14:50,740: INFO:   cloud_certainty_threshold :  0\n",
      "2024-09-25 16:14:50,741: INFO: Machine learning model used: ./models/model_36MYE_Unoptimised_20230505_no_haze.pkl\n",
      "2024-09-25 16:14:50,741: INFO:   Model path exists.\n",
      "2024-09-25 16:14:50,742: INFO: dataspace selected as download source for the Copernicus Data Space Ecosystem.\n",
      "2024-09-25 16:14:50,743: INFO:     Faulty Granule Threshold: 200\n",
      "2024-09-25 16:14:50,743: INFO:   download_source :  dataspace\n",
      "2024-09-25 16:14:50,744: INFO:   List of image bands: ['B02', 'B03', 'B04', 'B08']\n",
      "2024-09-25 16:14:50,744: INFO:   resolution_string :  \"10m\"\n",
      "2024-09-25 16:14:50,745: INFO:   output_resolution :  10\n",
      "2024-09-25 16:14:50,746: INFO:   buffer_size_cloud_masking :  20\n",
      "2024-09-25 16:14:50,746: INFO:   buffer_size_cloud_masking_composite :  10\n",
      "2024-09-25 16:14:50,747: INFO:   download_limit :  3\n",
      "2024-09-25 16:14:50,747: INFO:   faulty_granule_threshold :  200\n",
      "2024-09-25 16:14:50,748: INFO:   sieve :  0\n",
      "2024-09-25 16:14:50,749: INFO:   chunks :  8\n",
      "2024-09-25 16:14:50,749: INFO:   List of class labels:\n",
      "2024-09-25 16:14:50,749: INFO:     1 : primary forest\n",
      "2024-09-25 16:14:50,750: INFO:     2 : plantation forest\n",
      "2024-09-25 16:14:50,751: INFO:     3 : bare soil\n",
      "2024-09-25 16:14:50,752: INFO:     4 : crops\n",
      "2024-09-25 16:14:50,752: INFO:     5 : grassland\n",
      "2024-09-25 16:14:50,753: INFO:     6 : open water\n",
      "2024-09-25 16:14:50,753: INFO:     7 : burn scar\n",
      "2024-09-25 16:14:50,754: INFO:     8 : cloud\n",
      "2024-09-25 16:14:50,754: INFO:     9 : cloud shadow\n",
      "2024-09-25 16:14:50,755: INFO:     10 : haze\n",
      "2024-09-25 16:14:50,755: INFO:     11 : sparse woodland\n",
      "2024-09-25 16:14:50,755: INFO:     12 : dense woodland\n",
      "2024-09-25 16:14:50,756: INFO:     13 : artificial\n",
      "2024-09-25 16:14:50,756: INFO: Detecting changes from any of the classes: [1, 2]\n",
      "2024-09-25 16:14:50,757: INFO:                     to any of the classes: [3]\n",
      "2024-09-25 16:14:50,757: INFO:   from_classes :  [1, 2]\n",
      "2024-09-25 16:14:50,758: INFO:   to_classes :  [3]\n",
      "2024-09-25 16:14:50,758: INFO:     Environment Manager to use is : conda\n",
      "2024-09-25 16:14:50,759: INFO: The Conda Environment specified in .ini file is :  pyeo_env\n",
      "2024-09-25 16:14:50,761: INFO:   conda_directory :  /home/cmsstudent/miniconda3/\n",
      "2024-09-25 16:14:50,762: INFO:   conda_env_name :  pyeo_env\n",
      "2024-09-25 16:14:50,762: INFO: Pyeo Working Directory is   : /home/cmsstudent/pyeo\n",
      "2024-09-25 16:14:50,763: INFO:   Integrated Directory           : ./integrated\n",
      "2024-09-25 16:14:50,764: INFO:   ROI Directory for image search : ./roi\n",
      "2024-09-25 16:14:50,764: INFO:   Geometry Directory for admin shapefile : ./geometry\n",
      "2024-09-25 16:14:50,765: INFO:   Path to the Admin Boundaries for Vectorisation : ./geometry/gadm41_KEN_1.json\n",
      "2024-09-25 16:14:50,766: INFO: Main Tile Directory for tile subdirs : /home/cmsstudent/Desktop/pyeo_data\n",
      "2024-09-25 16:14:50,766: INFO:   integrated_dir :  ./integrated\n",
      "2024-09-25 16:14:50,767: INFO:   roi_dir :  ./roi\n",
      "2024-09-25 16:14:50,768: INFO:   roi_filename :  kfs_roi_subset_c.shp\n",
      "2024-09-25 16:14:50,769: INFO:   geometry_dir :  ./geometry\n",
      "2024-09-25 16:14:50,770: INFO:   s2_tiles_filename :  kenya_s2_tiles.shp\n",
      "2024-09-25 16:14:50,770: INFO:   log_dir :  /home/cmsstudent/Desktop/pyeo_data/log\n",
      "2024-09-25 16:14:50,771: INFO:   log_filename :  my_log.log\n",
      "2024-09-25 16:14:50,772: INFO: Path to Sen2Cor is   : /home/cmsstudent/Sen2Cor-02.10.01-Linux64/bin/L2A_Process\n",
      "2024-09-25 16:14:50,772: WARNING:   Sen2Cor path does not exist. Cannot convert L1C to L2A.\n",
      "2024-09-25 16:14:50,773: INFO:   level_1_filename :  gadm41_KEN_1.json\n",
      "2024-09-25 16:14:50,773: INFO:   level_2_filename :  gadm41_KEN_2.json\n",
      "2024-09-25 16:14:50,774: INFO:   level_3_filename :  gadm41_KEN_3.json\n",
      "2024-09-25 16:14:50,775: INFO:   level_1_boundaries_path :  ./geometry/gadm41_KEN_1.json\n",
      "2024-09-25 16:14:50,776: INFO:   --do_delete_existing_vector selected. When vectorising the change report rasters,\n",
      "2024-09-25 16:14:50,777: INFO:     existing vectors files will be deleted and new vector files created.\n",
      "2024-09-25 16:14:50,778: INFO:   --do_vectorise selected. It produces vector files from raster report images\n",
      "2024-09-25 16:14:50,778: INFO:   --do_integrate selected. It merges vectorised reports together\n",
      "2024-09-25 16:14:50,779: INFO:   do_filter :  False\n",
      "2024-09-25 16:14:50,780: INFO:   --admin_areas_of_interest\n",
      "2024-09-25 16:14:50,780: INFO:         Admin areas of interest to filter the national geodataframe:\n",
      "2024-09-25 16:14:50,781: INFO:   --minimum_area_to_report_m2\n",
      "2024-09-25 16:14:50,781: INFO:     Only Change Detections > 120 square metres will be reported\n",
      "2024-09-25 16:14:50,782: INFO:   minimum_area_to_report_m2 :  120\n",
      "2024-09-25 16:14:50,783: INFO:   do_distribution :  False\n",
      "2024-09-25 16:14:50,784: INFO:   email_alerts :  True\n",
      "2024-09-25 16:14:50,785: INFO:   email_list_file :  /home/cmsstudent/pyeo/subscribers.txt\n",
      "2024-09-25 16:14:50,786: INFO:   whatsapp_alerts :  False\n",
      "2024-09-25 16:14:50,786: INFO:   whatsapp_list_file :  /home/cmsstudent/pyeo/whatsapp_list.txt\n",
      "2024-09-25 16:14:50,787: INFO:   credentials_path :  /home/cmsstudent/pyeo/credentials/credentials.ini\n",
      "2024-09-25 16:14:50,788: INFO: -----------------------------------------------------------\n",
      "2024-09-25 16:14:50,852: INFO: The provided ROI intersects with 2 Sentinel-2 tiles:\n",
      "2024-09-25 16:14:50,853: INFO:   1 : 36NXG\n",
      "2024-09-25 16:14:50,854: INFO:   2 : 36NYG\n",
      "2024-09-25 16:14:50,855: INFO: Writing Sentinel-2 tile list to : /home/cmsstudent/Desktop/pyeo_data/tilelist.csv\n",
      "2024-09-25 16:14:50,857: INFO: Finished ROI / tile intersection\n",
      "2024-09-25 16:14:50,858: INFO: /home/cmsstudent/Desktop/pyeo_data/tilelist.csv\n",
      "2024-09-25 16:14:50,862: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:14:50,863: INFO: ---                 PROCESSING START                        ---\n",
      "2024-09-25 16:14:50,864: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:14:50,864: INFO: dataspace API is the download source\n",
      "2024-09-25 16:14:50,866: INFO: Running download handler for dataspace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 28.1 ms, total: 176 ms\n",
      "Wall time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import shutil\n",
    "import sys\n",
    "import configparser\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "from pyeo import (\n",
    "    classification,\n",
    "    filesystem_utilities,\n",
    "    queries_and_downloads,\n",
    "    raster_manipulation,\n",
    "    vectorisation\n",
    ")\n",
    "\n",
    "from pyeo.filesystem_utilities import (\n",
    "    initialisation,\n",
    "    config_to_log,\n",
    "    move_file,\n",
    "    move_and_rename_old_file\n",
    ")\n",
    "\n",
    "from pyeo.raster_manipulation import roi_tile_intersection\n",
    "\n",
    "gdal.UseExceptions()\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# navigate into the pyeo directory\n",
    "os.chdir(pyeo_dir)\n",
    "#----------------------------------------------------------\n",
    "# read in the ini file into a dictionary and start the log file\n",
    "config_dict, my_log = initialisation(config_path)\n",
    "#----------------------------------------------------------\n",
    "# print the contents of the ini file to the log file\n",
    "config_to_log(config_dict, my_log)\n",
    "#----------------------------------------------------------\n",
    "# get the tile IDs that intersect with the ROI (region of interest)\n",
    "tilelist_filepath = roi_tile_intersection(config_dict, my_log)\n",
    "my_log.info(tilelist_filepath)\n",
    "#----------------------------------------------------------\n",
    "# Select only the first tile for the purposes of this notebook\n",
    "tile_to_process = pd.read_csv(tilelist_filepath)[\"tile\"][0]\n",
    "# create a subdirectory for that tile\n",
    "individual_tile_directory_path = os.path.join(\n",
    "    config_dict[\"tile_dir\"],\n",
    "    tile_to_process\n",
    "    )\n",
    "# create all necessary subdirectories there\n",
    "filesystem_utilities.create_folder_structure_for_tiles(\n",
    "    individual_tile_directory_path\n",
    "    )\n",
    "#----------------------------------------------------------\n",
    "# initialise the tile_log file for that tile\n",
    "tile_log = filesystem_utilities.init_log_acd(\n",
    "    log_path=os.path.join(\n",
    "        individual_tile_directory_path,\n",
    "        \"log\",\n",
    "        tile_to_process + \".log\"\n",
    "        ),\n",
    "    logger_name=f\"pyeo_{tile_to_process}\"\n",
    ")\n",
    "#----------------------------------------------------------\n",
    "# assign some contents of the ini file dictionary to simpler variables\n",
    "start_date = config_dict[\"start_date\"]\n",
    "# convert the TODAY flag if specified into the current date and time stamp\n",
    "if start_date == \"TODAY\":\n",
    "  start_date = datetime.today().strftime('%Y%m%d')\n",
    "end_date = config_dict[\"end_date\"]\n",
    "if end_date == \"TODAY\":\n",
    "  end_date = datetime.today().strftime('%Y%m%d')\n",
    "composite_start_date = config_dict[\"composite_start\"]\n",
    "composite_end_date = config_dict[\"composite_end\"]\n",
    "cloud_cover = config_dict[\"cloud_cover\"]\n",
    "cloud_certainty_threshold = config_dict[\"cloud_certainty_threshold\"]\n",
    "model_path = config_dict[\"model_path\"]\n",
    "sen2cor_path = config_dict[\"sen2cor_path\"]\n",
    "epsg = config_dict[\"epsg\"]\n",
    "bands = config_dict[\"bands\"]\n",
    "resolution = config_dict[\"resolution_string\"]\n",
    "out_resolution = config_dict[\"output_resolution\"]\n",
    "buffer_size = config_dict[\"buffer_size_cloud_masking\"]\n",
    "buffer_size_composite = config_dict[\"buffer_size_cloud_masking_composite\"]\n",
    "download_limit = config_dict[\"download_limit\"]\n",
    "faulty_granule_threshold = config_dict[\"faulty_granule_threshold\"]\n",
    "skip_existing = config_dict[\"do_skip_existing\"]\n",
    "sieve = config_dict[\"sieve\"]\n",
    "from_classes = config_dict[\"from_classes\"]\n",
    "to_classes = config_dict[\"to_classes\"]\n",
    "\n",
    "download_source = config_dict[\"download_source\"]\n",
    "if download_source == \"scihub\":\n",
    "    tile_log.info(\"scihub API is the download source\")\n",
    "if download_source == \"dataspace\":\n",
    "    tile_log.info(\"dataspace API is the download source\")\n",
    "\n",
    "credentials_path = config_dict[\"credentials_path\"]\n",
    "if not os.path.exists(credentials_path):\n",
    "    tile_log.error(f\"The credentials path does not exist  :{credentials_path}\")\n",
    "    tile_log.error(f\"Current working directory :{os.getcwd()}\")\n",
    "    tile_log.error(\"Exiting raster pipeline\")\n",
    "    sys.exit(1)\n",
    "conf = configparser.ConfigParser(allow_no_value=True, interpolation=None)\n",
    "conf.read(credentials_path)\n",
    "credentials_dict = {}\n",
    "#----------------------------------------------------------------------\n",
    "# define variables that point to the directory paths\n",
    "change_image_dir = os.path.join(individual_tile_directory_path, r\"images\")\n",
    "l1_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"L1C\")\n",
    "l2_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"L2A\")\n",
    "l2_masked_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"cloud_masked\")\n",
    "categorised_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"classifications\")\n",
    "probability_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"probabilities\")\n",
    "report_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"reports\")\n",
    "sieved_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"sieved\")\n",
    "composite_dir = os.path.join(individual_tile_directory_path, r\"composite\")\n",
    "quicklook_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"quicklooks\")\n",
    "#------------------------------------------------------------------------\n",
    "if download_source == \"dataspace\":\n",
    "    tile_log.info(f'Running download handler for {download_source}')\n",
    "    credentials_dict[\"sent_2\"] = {}\n",
    "    credentials_dict[\"sent_2\"][\"user\"] = conf[\"dataspace\"][\"user\"]\n",
    "    credentials_dict[\"sent_2\"][\"pass\"] = conf[\"dataspace\"][\"pass\"]\n",
    "    sen_user = credentials_dict[\"sent_2\"][\"user\"]\n",
    "    sen_pass = credentials_dict[\"sent_2\"][\"pass\"]\n",
    "if download_source == \"scihub\":\n",
    "    tile_log.info(f'Running download handler for {download_source}')\n",
    "    credentials_dict[\"sent_2\"] = {}\n",
    "    credentials_dict[\"sent_2\"][\"user\"] = conf[\"sent_2\"][\"user\"]\n",
    "    credentials_dict[\"sent_2\"][\"pass\"] = conf[\"sent_2\"][\"pass\"]\n",
    "    sen_user = credentials_dict[\"sent_2\"][\"user\"]\n",
    "    sen_pass = credentials_dict[\"sent_2\"][\"pass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2fd99-edad-42ca-ba27-82019c48fa2b",
   "metadata": {
    "id": "dbe2fd99-edad-42ca-ba27-82019c48fa2b"
   },
   "source": [
    "# Download Sentinel-2 change detection images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e11d368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3670,
     "status": "ok",
     "timestamp": 1726524868945,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "3e11d368",
    "outputId": "55e08e67-2cc9-46ff-d412-d6c5c120b0dc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:15:03,523: INFO: 36NXG\n",
      "2024-09-25 16:15:03,524: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:15:03,525: INFO: Downloading change detection images between 20240201 and 20240925 with cloud cover <= 25\n",
      "2024-09-25 16:15:03,526: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:15:05,374: INFO: Removed 3 faulty scenes <200MB in size from the list:\n",
      "2024-09-25 16:15:05,378: INFO:    199.97 MB: S2B_MSIL1C_20240223T075929_N0510_R035_T36NXG_20240223T095005.SAFE\n",
      "2024-09-25 16:15:05,379: INFO:    197.15 MB: S2B_MSIL1C_20240602T075609_N0510_R035_T36NXG_20240602T094607.SAFE\n",
      "2024-09-25 16:15:05,380: INFO:    198.23 MB: S2B_MSIL1C_20240702T075609_N0510_R035_T36NXG_20240702T094619.SAFE\n",
      "2024-09-25 16:15:05,382: INFO:     54 L1C products\n",
      "2024-09-25 16:15:05,383: INFO:     37 L2A products\n",
      "2024-09-25 16:15:05,383: INFO: Filtering out L1C products that have the same 'beginposition' time stamp as an existing L2A product.\n",
      "2024-09-25 16:15:05,384: INFO: Before filtering, 54 L1C and 37 L2A\n",
      "2024-09-25 16:15:05,386: INFO: L1C : S2A_MSIL1C_20240326T074611_N0510_R135_T36NXG_20240326T093633.SAFE\n",
      "2024-09-25 16:15:05,387: INFO: L1C : S2A_MSIL1C_20240316T074651_N0510_R135_T36NXG_20240316T093624.SAFE\n",
      "2024-09-25 16:15:05,388: INFO: L1C : S2B_MSIL1C_20240301T074839_N0510_R135_T36NXG_20240301T093712.SAFE\n",
      "2024-09-25 16:15:05,388: INFO: L1C : S2B_MSIL1C_20240314T075709_N0510_R035_T36NXG_20240314T094856.SAFE\n",
      "2024-09-25 16:15:05,389: INFO: L1C : S2A_MSIL1C_20240306T074801_N0510_R135_T36NXG_20240306T093744.SAFE\n",
      "2024-09-25 16:15:05,390: INFO: L1C : S2A_MSIL1C_20240205T075121_N0510_R135_T36NXG_20240205T094155.SAFE\n",
      "2024-09-25 16:15:05,390: INFO: L1C : S2A_MSIL1C_20240208T080101_N0510_R035_T36NXG_20240208T095708.SAFE\n",
      "2024-09-25 16:15:05,393: INFO: L1C : S2B_MSIL1C_20240304T075819_N0510_R035_T36NXG_20240304T094924.SAFE\n",
      "2024-09-25 16:15:05,393: INFO: L1C : S2B_MSIL1C_20240311T074719_N0510_R135_T36NXG_20240311T094027.SAFE\n",
      "2024-09-25 16:15:05,394: INFO: L1C : S2A_MSIL1C_20240309T075741_N0510_R035_T36NXG_20240309T094743.SAFE\n",
      "2024-09-25 16:15:05,395: INFO: L1C : S2B_MSIL1C_20240213T080009_N0510_R035_T36NXG_20240213T094521.SAFE\n",
      "2024-09-25 16:15:05,396: INFO: L1C : S2B_MSIL1C_20240220T074949_N0510_R135_T36NXG_20240220T093707.SAFE\n",
      "2024-09-25 16:15:05,396: INFO: L1C : S2B_MSIL1C_20240321T074609_N0510_R135_T36NXG_20240321T095008.SAFE\n",
      "2024-09-25 16:15:05,398: INFO: L1C : S2A_MSIL1C_20240329T075611_N0510_R035_T36NXG_20240329T094656.SAFE\n",
      "2024-09-25 16:15:05,399: INFO: L1C : S2B_MSIL1C_20240513T075609_N0510_R035_T36NXG_20240513T094411.SAFE\n",
      "2024-09-25 16:15:05,400: INFO: L1C : S2A_MSIL1C_20240405T074611_N0510_R135_T36NXG_20240405T093819.SAFE\n",
      "2024-09-25 16:15:05,401: INFO: L1C : S2B_MSIL1C_20240410T074609_N0510_R135_T36NXG_20240410T093644.SAFE\n",
      "2024-09-25 16:15:05,401: INFO: L1C : S2A_MSIL1C_20240528T075611_N0510_R035_T36NXG_20240528T095755.SAFE\n",
      "2024-09-25 16:15:05,402: INFO: L1C : S2B_MSIL1C_20240530T074609_N0510_R135_T36NXG_20240530T095125.SAFE\n",
      "2024-09-25 16:15:05,403: INFO: L1C : S2A_MSIL1C_20240505T074611_N0510_R135_T36NXG_20240505T094134.SAFE\n",
      "2024-09-25 16:15:05,403: INFO: L1C : S2B_MSIL1C_20240622T075609_N0510_R035_T36NXG_20240622T094704.SAFE\n",
      "2024-09-25 16:15:05,404: INFO: L1C : S2A_MSIL1C_20240508T075611_N0510_R035_T36NXG_20240508T095513.SAFE\n",
      "2024-09-25 16:15:05,405: INFO: L1C : S2A_MSIL1C_20240418T075731_N0510_R035_T36NXG_20240418T095754.SAFE\n",
      "2024-09-25 16:15:05,405: INFO: L1C : S2B_MSIL1C_20240420T074609_N0510_R135_T36NXG_20240420T093826.SAFE\n",
      "2024-09-25 16:15:05,407: INFO: L1C : S2B_MSIL1C_20240423T075609_N0510_R035_T36NXG_20240423T094526.SAFE\n",
      "2024-09-25 16:15:05,408: INFO: L1C : S2B_MSIL1C_20240430T074609_N0510_R135_T36NXG_20240430T093438.SAFE\n",
      "2024-09-25 16:15:05,408: INFO: L1C : S2A_MSIL1C_20240515T074611_N0510_R135_T36NXG_20240515T094807.SAFE\n",
      "2024-09-25 16:15:05,409: INFO: L1C : S2A_MSIL1C_20240518T075611_N0510_R035_T36NXG_20240518T103314.SAFE\n",
      "2024-09-25 16:15:05,410: INFO: L1C : S2B_MSIL1C_20240520T074609_N0510_R135_T36NXG_20240520T094946.SAFE\n",
      "2024-09-25 16:15:05,411: INFO: L1C : S2A_MSIL1C_20240607T075611_N0510_R035_T36NXG_20240607T100035.SAFE\n",
      "2024-09-25 16:15:05,412: INFO: L1C : S2A_MSIL1C_20240525T074611_N0510_R135_T36NXG_20240525T094913.SAFE\n",
      "2024-09-25 16:15:05,412: INFO: L1C : S2B_MSIL1C_20240619T074619_N0510_R135_T36NXG_20240619T093414.SAFE\n",
      "2024-09-25 16:15:05,414: INFO: L1C : S2A_MSIL1C_20240816T075611_N0511_R035_T36NXG_20240816T101726.SAFE\n",
      "2024-09-25 16:15:05,414: INFO: L1C : S2A_MSIL1C_20240803T074611_N0511_R135_T36NXG_20240803T102343.SAFE\n",
      "2024-09-25 16:15:05,415: INFO: L1C : S2A_MSIL1C_20240704T074611_N0510_R135_T36NXG_20240704T093938.SAFE\n",
      "2024-09-25 16:15:05,416: INFO: L1C : S2A_MSIL1C_20240823T074611_N0511_R135_T36NXG_20240823T113151.SAFE\n",
      "2024-09-25 16:15:05,416: INFO: L1C : S2B_MSIL1C_20240828T074609_N0511_R135_T36NXG_20240828T100920.SAFE\n",
      "2024-09-25 16:15:05,417: INFO: L1C : S2B_MSIL1C_20240709T074619_N0510_R135_T36NXG_20240709T093843.SAFE\n",
      "2024-09-25 16:15:05,418: INFO: L1C : S2B_MSIL1C_20240801T075609_N0511_R035_T36NXG_20240801T094603.SAFE\n",
      "2024-09-25 16:15:05,418: INFO: L1C : S2B_MSIL1C_20240712T075609_N0510_R035_T36NXG_20240712T094802.SAFE\n",
      "2024-09-25 16:15:05,420: INFO: L1C : S2A_MSIL1C_20240806T075611_N0511_R035_T36NXG_20240806T101813.SAFE\n",
      "2024-09-25 16:15:05,420: INFO: L1C : S2A_MSIL1C_20240714T074611_N0510_R135_T36NXG_20240714T094857.SAFE\n",
      "2024-09-25 16:15:05,421: INFO: L1C : S2B_MSIL1C_20240808T074619_N0511_R135_T36NXG_20240808T100741.SAFE\n",
      "2024-09-25 16:15:05,422: INFO: L1C : S2A_MSIL1C_20240912T080601_N0511_R135_T36NXG_20240912T100522.SAFE\n",
      "2024-09-25 16:15:05,422: INFO: L1C : S2B_MSIL1C_20240811T075609_N0511_R035_T36NXG_20240811T101413.SAFE\n",
      "2024-09-25 16:15:05,423: INFO: L1C : S2B_MSIL1C_20240910T075609_N0511_R035_T36NXG_20240910T102718.SAFE\n",
      "2024-09-25 16:15:05,423: INFO: L1C : S2A_MSIL1C_20240813T074611_N0511_R135_T36NXG_20240813T102446.SAFE\n",
      "2024-09-25 16:15:05,424: INFO: L1C : S2A_MSIL1C_20240727T075611_N0511_R035_T36NXG_20240727T103318.SAFE\n",
      "2024-09-25 16:15:05,425: INFO: L1C : S2A_MSIL1C_20240915T075611_N0511_R035_T36NXG_20240915T101431.SAFE\n",
      "2024-09-25 16:15:05,426: INFO: L1C : S2B_MSIL1C_20240917T074609_N0511_R135_T36NXG_20240917T095007.SAFE\n",
      "2024-09-25 16:15:05,427: INFO: L1C : S2B_MSIL1C_20240831T075609_N0511_R035_T36NXG_20240831T101953.SAFE\n",
      "2024-09-25 16:15:05,427: INFO: L1C : S2A_MSIL1C_20240905T075611_N0511_R035_T36NXG_20240905T120731.SAFE\n",
      "2024-09-25 16:15:05,428: INFO: L1C : S2B_MSIL1C_20240907T074619_N0511_R135_T36NXG_20240907T102826.SAFE\n",
      "2024-09-25 16:15:05,429: INFO: L1C : S2A_MSIL1C_20240922T074631_N0511_R135_T36NXG_20240922T094322.SAFE\n",
      "2024-09-25 16:15:05,431: INFO: L2A : S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:15:05,432: INFO: L2A : S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:15:05,432: INFO: L2A : S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE\n",
      "2024-09-25 16:15:05,433: INFO: L2A : S2A_MSIL2A_20240306T074801_N0510_R135_T36NXG_20240306T110851.SAFE\n",
      "2024-09-25 16:15:05,434: INFO: L2A : S2A_MSIL2A_20240326T074611_N0510_R135_T36NXG_20240326T111352.SAFE\n",
      "2024-09-25 16:15:05,434: INFO: L2A : S2B_MSIL2A_20240304T075819_N0510_R035_T36NXG_20240304T102020.SAFE\n",
      "2024-09-25 16:15:05,435: INFO: L2A : S2B_MSIL2A_20240311T074719_N0510_R135_T36NXG_20240311T101147.SAFE\n",
      "2024-09-25 16:15:05,436: INFO: L2A : S2A_MSIL2A_20240309T075741_N0510_R035_T36NXG_20240309T111449.SAFE\n",
      "2024-09-25 16:15:05,437: INFO: L2A : S2B_MSIL2A_20240321T074609_N0510_R135_T36NXG_20240321T103033.SAFE\n",
      "2024-09-25 16:15:05,438: INFO: L2A : S2A_MSIL2A_20240329T075611_N0510_R035_T36NXG_20240329T111052.SAFE\n",
      "2024-09-25 16:15:05,439: INFO: L2A : S2B_MSIL2A_20240513T075609_N0510_R035_T36NXG_20240513T101811.SAFE\n",
      "2024-09-25 16:15:05,439: INFO: L2A : S2A_MSIL2A_20240528T075611_N0510_R035_T36NXG_20240528T121054.SAFE\n",
      "2024-09-25 16:15:05,440: INFO: L2A : S2B_MSIL2A_20240530T074609_N0510_R135_T36NXG_20240530T103100.SAFE\n",
      "2024-09-25 16:15:05,440: INFO: L2A : S2A_MSIL2A_20240508T075611_N0510_R035_T36NXG_20240508T112554.SAFE\n",
      "2024-09-25 16:15:05,441: INFO: L2A : S2B_MSIL2A_20240423T075609_N0510_R035_T36NXG_20240423T101339.SAFE\n",
      "2024-09-25 16:15:05,442: INFO: L2A : S2B_MSIL2A_20240622T075609_N0510_R035_T36NXG_20240622T101459.SAFE\n",
      "2024-09-25 16:15:05,442: INFO: L2A : S2A_MSIL2A_20240518T075611_N0510_R035_T36NXG_20240518T130054.SAFE\n",
      "2024-09-25 16:15:05,443: INFO: L2A : S2A_MSIL2A_20240525T074611_N0510_R135_T36NXG_20240525T115752.SAFE\n",
      "2024-09-25 16:15:05,443: INFO: L2A : S2A_MSIL2A_20240607T075611_N0510_R035_T36NXG_20240607T120650.SAFE\n",
      "2024-09-25 16:15:05,444: INFO: L2A : S2B_MSIL2A_20240619T074619_N0510_R135_T36NXG_20240619T100330.SAFE\n",
      "2024-09-25 16:15:05,445: INFO: L2A : S2B_MSIL2A_20240801T075609_N0511_R035_T36NXG_20240801T101920.SAFE\n",
      "2024-09-25 16:15:05,446: INFO: L2A : S2B_MSIL2A_20240702T075609_N0510_R035_T36NXG_20240702T101727.SAFE\n",
      "2024-09-25 16:15:05,447: INFO: L2A : S2A_MSIL2A_20240803T074611_N0511_R135_T36NXG_20240803T122946.SAFE\n",
      "2024-09-25 16:15:05,448: INFO: L2A : S2A_MSIL2A_20240704T074611_N0510_R135_T36NXG_20240704T110852.SAFE\n",
      "2024-09-25 16:15:05,449: INFO: L2A : S2A_MSIL2A_20240823T074611_N0511_R135_T36NXG_20240823T140159.SAFE\n",
      "2024-09-25 16:15:05,450: INFO: L2A : S2A_MSIL2A_20240816T075611_N0511_R035_T36NXG_20240816T123949.SAFE\n",
      "2024-09-25 16:15:05,451: INFO: L2A : S2B_MSIL2A_20240828T074609_N0511_R135_T36NXG_20240828T105719.SAFE\n",
      "2024-09-25 16:15:05,451: INFO: L2A : S2A_MSIL2A_20240806T075611_N0511_R035_T36NXG_20240806T130054.SAFE\n",
      "2024-09-25 16:15:05,452: INFO: L2A : S2B_MSIL2A_20240811T075609_N0511_R035_T36NXG_20240811T110330.SAFE\n",
      "2024-09-25 16:15:05,453: INFO: L2A : S2A_MSIL2A_20240912T080601_N0511_R135_T36NXG_20240912T123247.SAFE\n",
      "2024-09-25 16:15:05,453: INFO: L2A : S2B_MSIL2A_20240910T075609_N0511_R035_T36NXG_20240910T110646.SAFE\n",
      "2024-09-25 16:15:05,454: INFO: L2A : S2A_MSIL2A_20240813T074611_N0511_R135_T36NXG_20240813T125752.SAFE\n",
      "2024-09-25 16:15:05,454: INFO: L2A : S2A_MSIL2A_20240915T075611_N0511_R035_T36NXG_20240915T123949.SAFE\n",
      "2024-09-25 16:15:05,456: INFO: L2A : S2B_MSIL2A_20240831T075609_N0511_R035_T36NXG_20240831T110838.SAFE\n",
      "2024-09-25 16:15:05,456: INFO: L2A : S2A_MSIL2A_20240905T075611_N0511_R035_T36NXG_20240905T143649.SAFE\n",
      "2024-09-25 16:15:05,457: INFO: L2A : S2B_MSIL2A_20240917T074609_N0511_R135_T36NXG_20240917T103429.SAFE\n",
      "2024-09-25 16:15:05,457: INFO: L2A : S2B_MSIL2A_20240907T074619_N0511_R135_T36NXG_20240907T112146.SAFE\n",
      "2024-09-25 16:15:05,470: INFO: After filtering, 18 L1C and 37 L2A\n",
      "2024-09-25 16:15:05,472: INFO: Unique L1C : S2B_MSIL1C_20240301T074839_N0510_R135_T36NXG_20240301T093712.SAFE\n",
      "2024-09-25 16:15:05,472: INFO: Unique L1C : S2A_MSIL1C_20240205T075121_N0510_R135_T36NXG_20240205T094155.SAFE\n",
      "2024-09-25 16:15:05,473: INFO: Unique L1C : S2A_MSIL1C_20240208T080101_N0510_R035_T36NXG_20240208T095708.SAFE\n",
      "2024-09-25 16:15:05,473: INFO: Unique L1C : S2B_MSIL1C_20240213T080009_N0510_R035_T36NXG_20240213T094521.SAFE\n",
      "2024-09-25 16:15:05,474: INFO: Unique L1C : S2A_MSIL1C_20240405T074611_N0510_R135_T36NXG_20240405T093819.SAFE\n",
      "2024-09-25 16:15:05,474: INFO: Unique L1C : S2B_MSIL1C_20240410T074609_N0510_R135_T36NXG_20240410T093644.SAFE\n",
      "2024-09-25 16:15:05,476: INFO: Unique L1C : S2A_MSIL1C_20240505T074611_N0510_R135_T36NXG_20240505T094134.SAFE\n",
      "2024-09-25 16:15:05,476: INFO: Unique L1C : S2A_MSIL1C_20240418T075731_N0510_R035_T36NXG_20240418T095754.SAFE\n",
      "2024-09-25 16:15:05,477: INFO: Unique L1C : S2B_MSIL1C_20240420T074609_N0510_R135_T36NXG_20240420T093826.SAFE\n",
      "2024-09-25 16:15:05,477: INFO: Unique L1C : S2B_MSIL1C_20240430T074609_N0510_R135_T36NXG_20240430T093438.SAFE\n",
      "2024-09-25 16:15:05,478: INFO: Unique L1C : S2A_MSIL1C_20240515T074611_N0510_R135_T36NXG_20240515T094807.SAFE\n",
      "2024-09-25 16:15:05,479: INFO: Unique L1C : S2B_MSIL1C_20240520T074609_N0510_R135_T36NXG_20240520T094946.SAFE\n",
      "2024-09-25 16:15:05,479: INFO: Unique L1C : S2B_MSIL1C_20240709T074619_N0510_R135_T36NXG_20240709T093843.SAFE\n",
      "2024-09-25 16:15:05,480: INFO: Unique L1C : S2B_MSIL1C_20240712T075609_N0510_R035_T36NXG_20240712T094802.SAFE\n",
      "2024-09-25 16:15:05,481: INFO: Unique L1C : S2A_MSIL1C_20240714T074611_N0510_R135_T36NXG_20240714T094857.SAFE\n",
      "2024-09-25 16:15:05,481: INFO: Unique L1C : S2B_MSIL1C_20240808T074619_N0511_R135_T36NXG_20240808T100741.SAFE\n",
      "2024-09-25 16:15:05,482: INFO: Unique L1C : S2A_MSIL1C_20240727T075611_N0511_R035_T36NXG_20240727T103318.SAFE\n",
      "2024-09-25 16:15:05,483: INFO: Unique L1C : S2A_MSIL1C_20240922T074631_N0511_R135_T36NXG_20240922T094322.SAFE\n",
      "2024-09-25 16:15:05,484: INFO: Unique L2A : S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:15:05,484: INFO: Unique L2A : S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:15:05,485: INFO: Unique L2A : S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE\n",
      "2024-09-25 16:15:05,486: INFO: Unique L2A : S2A_MSIL2A_20240306T074801_N0510_R135_T36NXG_20240306T110851.SAFE\n",
      "2024-09-25 16:15:05,486: INFO: Unique L2A : S2A_MSIL2A_20240326T074611_N0510_R135_T36NXG_20240326T111352.SAFE\n",
      "2024-09-25 16:15:05,487: INFO: Unique L2A : S2B_MSIL2A_20240304T075819_N0510_R035_T36NXG_20240304T102020.SAFE\n",
      "2024-09-25 16:15:05,488: INFO: Unique L2A : S2B_MSIL2A_20240311T074719_N0510_R135_T36NXG_20240311T101147.SAFE\n",
      "2024-09-25 16:15:05,488: INFO: Unique L2A : S2A_MSIL2A_20240309T075741_N0510_R035_T36NXG_20240309T111449.SAFE\n",
      "2024-09-25 16:15:05,489: INFO: Unique L2A : S2B_MSIL2A_20240321T074609_N0510_R135_T36NXG_20240321T103033.SAFE\n",
      "2024-09-25 16:15:05,490: INFO: Unique L2A : S2A_MSIL2A_20240329T075611_N0510_R035_T36NXG_20240329T111052.SAFE\n",
      "2024-09-25 16:15:05,490: INFO: Unique L2A : S2B_MSIL2A_20240513T075609_N0510_R035_T36NXG_20240513T101811.SAFE\n",
      "2024-09-25 16:15:05,491: INFO: Unique L2A : S2A_MSIL2A_20240528T075611_N0510_R035_T36NXG_20240528T121054.SAFE\n",
      "2024-09-25 16:15:05,492: INFO: Unique L2A : S2B_MSIL2A_20240530T074609_N0510_R135_T36NXG_20240530T103100.SAFE\n",
      "2024-09-25 16:15:05,492: INFO: Unique L2A : S2A_MSIL2A_20240508T075611_N0510_R035_T36NXG_20240508T112554.SAFE\n",
      "2024-09-25 16:15:05,493: INFO: Unique L2A : S2B_MSIL2A_20240423T075609_N0510_R035_T36NXG_20240423T101339.SAFE\n",
      "2024-09-25 16:15:05,493: INFO: Unique L2A : S2B_MSIL2A_20240622T075609_N0510_R035_T36NXG_20240622T101459.SAFE\n",
      "2024-09-25 16:15:05,494: INFO: Unique L2A : S2A_MSIL2A_20240518T075611_N0510_R035_T36NXG_20240518T130054.SAFE\n",
      "2024-09-25 16:15:05,494: INFO: Unique L2A : S2A_MSIL2A_20240525T074611_N0510_R135_T36NXG_20240525T115752.SAFE\n",
      "2024-09-25 16:15:05,495: INFO: Unique L2A : S2A_MSIL2A_20240607T075611_N0510_R035_T36NXG_20240607T120650.SAFE\n",
      "2024-09-25 16:15:05,496: INFO: Unique L2A : S2B_MSIL2A_20240619T074619_N0510_R135_T36NXG_20240619T100330.SAFE\n",
      "2024-09-25 16:15:05,497: INFO: Unique L2A : S2B_MSIL2A_20240801T075609_N0511_R035_T36NXG_20240801T101920.SAFE\n",
      "2024-09-25 16:15:05,497: INFO: Unique L2A : S2B_MSIL2A_20240702T075609_N0510_R035_T36NXG_20240702T101727.SAFE\n",
      "2024-09-25 16:15:05,498: INFO: Unique L2A : S2A_MSIL2A_20240803T074611_N0511_R135_T36NXG_20240803T122946.SAFE\n",
      "2024-09-25 16:15:05,499: INFO: Unique L2A : S2A_MSIL2A_20240704T074611_N0510_R135_T36NXG_20240704T110852.SAFE\n",
      "2024-09-25 16:15:05,499: INFO: Unique L2A : S2A_MSIL2A_20240823T074611_N0511_R135_T36NXG_20240823T140159.SAFE\n",
      "2024-09-25 16:15:05,500: INFO: Unique L2A : S2A_MSIL2A_20240816T075611_N0511_R035_T36NXG_20240816T123949.SAFE\n",
      "2024-09-25 16:15:05,500: INFO: Unique L2A : S2B_MSIL2A_20240828T074609_N0511_R135_T36NXG_20240828T105719.SAFE\n",
      "2024-09-25 16:15:05,501: INFO: Unique L2A : S2A_MSIL2A_20240806T075611_N0511_R035_T36NXG_20240806T130054.SAFE\n",
      "2024-09-25 16:15:05,502: INFO: Unique L2A : S2B_MSIL2A_20240811T075609_N0511_R035_T36NXG_20240811T110330.SAFE\n",
      "2024-09-25 16:15:05,502: INFO: Unique L2A : S2A_MSIL2A_20240912T080601_N0511_R135_T36NXG_20240912T123247.SAFE\n",
      "2024-09-25 16:15:05,503: INFO: Unique L2A : S2B_MSIL2A_20240910T075609_N0511_R035_T36NXG_20240910T110646.SAFE\n",
      "2024-09-25 16:15:05,503: INFO: Unique L2A : S2A_MSIL2A_20240813T074611_N0511_R135_T36NXG_20240813T125752.SAFE\n",
      "2024-09-25 16:15:05,504: INFO: Unique L2A : S2A_MSIL2A_20240915T075611_N0511_R035_T36NXG_20240915T123949.SAFE\n",
      "2024-09-25 16:15:05,505: INFO: Unique L2A : S2B_MSIL2A_20240831T075609_N0511_R035_T36NXG_20240831T110838.SAFE\n",
      "2024-09-25 16:15:05,505: INFO: Unique L2A : S2A_MSIL2A_20240905T075611_N0511_R035_T36NXG_20240905T143649.SAFE\n",
      "2024-09-25 16:15:05,505: INFO: Unique L2A : S2B_MSIL2A_20240917T074609_N0511_R135_T36NXG_20240917T103429.SAFE\n",
      "2024-09-25 16:15:05,506: INFO: Unique L2A : S2B_MSIL2A_20240907T074619_N0511_R135_T36NXG_20240907T112146.SAFE\n",
      "2024-09-25 16:15:05,507: INFO: --> 55 L1C and L2A products with unique 'beginposition' time stamp:\n",
      "2024-09-25 16:15:05,508: INFO:  18 L1C Change Images\n",
      "2024-09-25 16:15:05,508: INFO:  37 L2A Change Images\n",
      "2024-09-25 16:15:05,509: INFO: Cell successfully finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 29.1 ms, total: 241 ms\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tile_log.info(tile_to_process)\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(f\"Downloading change detection images between {start_date} and \"+\n",
    "        f\"{end_date} with cloud cover <= {cloud_cover}\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    if download_source == \"dataspace\":\n",
    "        try:\n",
    "            tiles_geom_path = os.path.join(\n",
    "                pyeo_dir,\n",
    "                config_dict[\"geometry_dir\"],\n",
    "                config_dict[\"s2_tiles_filename\"]\n",
    "                )\n",
    "            tiles_geom = gpd.read_file(os.path.abspath(tiles_geom_path))\n",
    "        except FileNotFoundError:\n",
    "            tile_log.error(f\"tiles_geom does not exist, the path is :{tiles_geom_path}\")\n",
    "\n",
    "        tile_geom = tiles_geom[tiles_geom[\"Name\"] == tile_to_process]\n",
    "        tile_geom = tile_geom.to_crs(epsg=4326)\n",
    "        geometry = tile_geom[\"geometry\"].iloc[0]\n",
    "        geometry = geometry.representative_point()\n",
    "\n",
    "        # convert date string to YYYY-MM-DD\n",
    "        date_object = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "        dataspace_change_start = date_object.strftime(\"%Y-%m-%d\")\n",
    "        date_object = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "        dataspace_change_end = date_object.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        try:\n",
    "            dataspace_change_products_all = queries_and_downloads.query_dataspace_by_tile_id(\n",
    "                max_cloud_cover=cloud_cover,\n",
    "                start_date=dataspace_change_start,\n",
    "                end_date=dataspace_change_end,\n",
    "                tile_id = tile_to_process,\n",
    "                max_records=100,\n",
    "                log=tile_log\n",
    "            )\n",
    "        except Exception as error:\n",
    "            tile_log.error(f\"query_dataspace_by_tile_id received this error: {error}\")\n",
    "\n",
    "        titles = dataspace_change_products_all[\"title\"].tolist()\n",
    "        sizes = list()\n",
    "        uuids = list()\n",
    "        for elem in dataspace_change_products_all.itertuples(index=False):\n",
    "            sizes.append(elem[-2][\"download\"][\"size\"])\n",
    "            uuids.append(elem[-2][\"download\"][\"url\"].split(\"/\")[-1])\n",
    "\n",
    "        relative_orbit_numbers = dataspace_change_products_all[\"relativeOrbitNumber\"].tolist()\n",
    "        processing_levels = dataspace_change_products_all[\"processingLevel\"].tolist()\n",
    "        transformed_levels = ['Level-1C' if level == 'S2MSI1C' else 'Level-2A' for level in processing_levels]\n",
    "        cloud_covers = dataspace_change_products_all[\"cloudCover\"].tolist()\n",
    "        begin_positions = dataspace_change_products_all[\"startDate\"].tolist()\n",
    "        statuses = dataspace_change_products_all[\"status\"].tolist()\n",
    "\n",
    "        scihub_compatible_df = pd.DataFrame({\"title\": titles,\n",
    "                                            \"size\": sizes,\n",
    "                                            \"beginposition\": begin_positions,\n",
    "                                            \"relativeorbitnumber\": relative_orbit_numbers,\n",
    "                                            \"cloudcoverpercentage\": cloud_covers,\n",
    "                                            \"processinglevel\": transformed_levels,\n",
    "                                            \"uuid\": uuids,\n",
    "                                            \"status\": statuses})\n",
    "\n",
    "        # check granule sizes on the server\n",
    "        scihub_compatible_df[\"size\"] = scihub_compatible_df[\"size\"].apply(lambda x: round(float(x) * 1e-6, 2))\n",
    "\n",
    "        # reassign to match the scihub variable\n",
    "        df_all = scihub_compatible_df\n",
    "\n",
    "    if download_source == \"scihub\":\n",
    "        products_all = queries_and_downloads.check_for_s2_data_by_date(\n",
    "            config_dict[\"tile_dir\"],\n",
    "            start_date,\n",
    "            end_date,\n",
    "            credentials_dict,\n",
    "            cloud_cover=cloud_cover,\n",
    "            tile_id=tile_to_process,\n",
    "            producttype=None,  # \"S2MSI2A\" or \"S2MSI1C\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"--> Found {} L1C and L2A products for change detection:\".format(\n",
    "                len(products_all)\n",
    "            )\n",
    "        )\n",
    "        df_all = pd.DataFrame.from_dict(products_all, orient=\"index\")\n",
    "\n",
    "        # check granule sizes on the server\n",
    "        df_all[\"size\"] = (\n",
    "            df_all[\"size\"]\n",
    "            .str.split(\" \")\n",
    "            .apply(lambda x: float(x[0]) * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]])\n",
    "        )\n",
    "\n",
    "    # here the main call (from if download_source == \"scihub\" branch) is resumed\n",
    "    df = df_all.query(\"size >= \" + str(faulty_granule_threshold))\n",
    "    tile_log.info(\n",
    "        \"Removed {} faulty scenes <{}MB in size from the list:\".format(\n",
    "            len(df_all) - len(df), faulty_granule_threshold\n",
    "        )\n",
    "    )\n",
    "    df_faulty = df_all.query(\"size < \" + str(faulty_granule_threshold))\n",
    "    for r in range(len(df_faulty)):\n",
    "        tile_log.info(\n",
    "            \"   {} MB: {}\".format(\n",
    "                df_faulty.iloc[r, :][\"size\"], df_faulty.iloc[r, :][\"title\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    l1c_products = df[df.processinglevel == \"Level-1C\"]\n",
    "    l2a_products = df[df.processinglevel == \"Level-2A\"]\n",
    "    tile_log.info(\"    {} L1C products\".format(l1c_products.shape[0]))\n",
    "    tile_log.info(\"    {} L2A products\".format(l2a_products.shape[0]))\n",
    "\n",
    "    if l1c_products.shape[0] > 0 and l2a_products.shape[0] > 0:\n",
    "        tile_log.info(\n",
    "            \"Filtering out L1C products that have the same 'beginposition' time \"+\n",
    "            \"stamp as an existing L2A product.\"\n",
    "            )\n",
    "        if download_source == \"scihub\":\n",
    "            (l1c_products,l2a_products,) = \\\n",
    "                queries_and_downloads.filter_unique_l1c_and_l2a_data(\n",
    "                    df,\n",
    "                    log=tile_log\n",
    "                    )\n",
    "\n",
    "        if download_source == \"dataspace\":\n",
    "            l1c_products = \\\n",
    "                queries_and_downloads.filter_unique_dataspace_products(\n",
    "                    l1c_products=l1c_products,\n",
    "                    l2a_products=l2a_products,\n",
    "                    log=tile_log\n",
    "                    )\n",
    "\n",
    "        n = l1c_products.shape[0] + l2a_products.shape[0]\n",
    "        tile_log.info(f\"--> {n} L1C and L2A products with unique 'beginposition' \"+\n",
    "            \"time stamp:\")\n",
    "\n",
    "    df = None\n",
    "    tile_log.info(f\" {len(l1c_products['title'])} L1C Change Images\")\n",
    "    tile_log.info(f\" {len(l2a_products['title'])} L2A Change Images\")\n",
    "\n",
    "    tile_log.info(\"Cell successfully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989363f8-0ad7-4ac2-8c4a-1619abde3f4e",
   "metadata": {
    "id": "989363f8-0ad7-4ac2-8c4a-1619abde3f4e"
   },
   "source": [
    "## Search for L2A Images Corresponding to L1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d243e7c-4db3-4547-9845-b212a8fd6e08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1726524868946,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "4d243e7c-4db3-4547-9845-b212a8fd6e08",
    "outputId": "7d22a230-7ab7-4dd8-cc5d-babcf055f1a0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:15:20,887: INFO:     37 L2A products remaining for download\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.71 ms, total: 2.71 ms\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    if download_source == \"scihub\":\n",
    "        if l1c_products.shape[0] > 0:\n",
    "            tile_log.info(\"Checking for availability of L2A products to minimise download and atmospheric correction of L1C products.\")\n",
    "            n = len(l1c_products)\n",
    "            drop = []\n",
    "            add = []\n",
    "            for r in range(n):\n",
    "                id = l1c_products.iloc[r, :][\"title\"]\n",
    "                search_term = (\n",
    "                    \"*\"\n",
    "                    + id.split(\"_\")[2]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[3]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[4]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[5]\n",
    "                    + \"*\"\n",
    "                )\n",
    "                tile_log.info(\"Search term: {}.\".format(search_term))\n",
    "                matching_l2a_products = queries_and_downloads._file_api_query(\n",
    "                    user=sen_user,\n",
    "                    passwd=sen_pass,\n",
    "                    start_date=start_date,\n",
    "                    end_date=end_date,\n",
    "                    filename=search_term,\n",
    "                    cloud=cloud_cover,\n",
    "                    producttype=\"S2MSI2A\",\n",
    "                )\n",
    "\n",
    "                matching_l2a_products_df = pd.DataFrame.from_dict(\n",
    "                    matching_l2a_products, orient=\"index\"\n",
    "                )\n",
    "                if len(matching_l2a_products_df) == 1:\n",
    "                    tile_log.info(matching_l2a_products_df.iloc[0, :][\"size\"])\n",
    "                    matching_l2a_products_df[\"size\"] = (\n",
    "                        matching_l2a_products_df[\"size\"]\n",
    "                        .str.split(\" \")\n",
    "                        .apply(\n",
    "                            lambda x: float(x[0])\n",
    "                            * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]]\n",
    "                        )\n",
    "                    )\n",
    "                    if (\n",
    "                        matching_l2a_products_df.iloc[0, :][\"size\"]\n",
    "                        > faulty_granule_threshold\n",
    "                    ):\n",
    "                        tile_log.info(\"Replacing L1C {} with L2A product:\".format(id))\n",
    "                        tile_log.info(\n",
    "                            \"              {}\".format(\n",
    "                                matching_l2a_products_df.iloc[0, :][\"title\"]\n",
    "                            )\n",
    "                        )\n",
    "                        drop.append(l1c_products.index[r])\n",
    "                        add.append(matching_l2a_products_df.iloc[0, :])\n",
    "                if len(matching_l2a_products_df) == 0:\n",
    "                    tile_log.info(\"Found no match for L1C: {}.\".format(id))\n",
    "                if len(matching_l2a_products_df) > 1:\n",
    "                    # check granule sizes on the server\n",
    "                    matching_l2a_products_df[\"size\"] = (\n",
    "                        matching_l2a_products_df[\"size\"]\n",
    "                        .str.split(\" \")\n",
    "                        .apply(\n",
    "                            lambda x: float(x[0])\n",
    "                            * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]]\n",
    "                        )\n",
    "                    )\n",
    "                    if (\n",
    "                        matching_l2a_products_df.iloc[0, :][\"size\"]\n",
    "                        > faulty_granule_threshold\n",
    "                    ):\n",
    "                        tile_log.info(\"Replacing L1C {} with L2A product:\".format(id))\n",
    "                        tile_log.info(\n",
    "                            \"              {}\".format(\n",
    "                                matching_l2a_products_df.iloc[0, :][\"title\"]\n",
    "                            )\n",
    "                        )\n",
    "                        drop.append(l1c_products.index[r])\n",
    "                        add.append(matching_l2a_products_df.iloc[0, :])\n",
    "\n",
    "            if len(drop) > 0:\n",
    "                l1c_products = l1c_products.drop(index=drop)\n",
    "            if len(add) > 0:\n",
    "                if config_dict[\"do_dev\"]:\n",
    "                    add = pd.DataFrame(add)\n",
    "                    l2a_products = pd.concat([l2a_products, add])\n",
    "                else:\n",
    "                    add = pd.DataFrame(add)\n",
    "                    l2a_products = pd.concat([l2a_products, add])\n",
    "\n",
    "            tile_log.info(\n",
    "                \"    {} L1C products remaining for download\".format(\n",
    "                    l1c_products.shape[0]\n",
    "                )\n",
    "            )\n",
    "    l2a_products = l2a_products.drop_duplicates(subset=\"title\")\n",
    "    tile_log.info(\"    {} L2A products remaining for download\".format(l2a_products.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a4b6f",
   "metadata": {
    "id": "b24a4b6f"
   },
   "source": [
    "## Download and Pre-Process L1C Change Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb442923",
   "metadata": {
    "id": "bb442923"
   },
   "source": [
    "- If there any L1C products in the change images search query that are not matched with L2A products, then download these L1Cs and apply `atmospheric_correction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ea3ce7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1726524868946,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "38ea3ce7",
    "outputId": "0af09d05-b176-4449-8cbf-67e1a1a95669",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:15:28,608: WARNING:   Sen2Cor path does not exist. Cannot convert L1C to L2A. Skipping download of L1C images.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 0 ns, total: 2 ms\n",
      "Wall time: 1.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    if l1c_products.shape[0] > 0:\n",
    "        # only download the L1C products if we have sen2cor installed to\n",
    "        #   apply the atmospheric correction to L2A level\n",
    "        if os.path.exists(config_dict['sen2cor_path']):\n",
    "            tile_log.info(\"  Sen2Cor path found.\")\n",
    "\n",
    "            tile_log.info(f\"Downloading Sentinel-2 L1C products from {download_source}\")\n",
    "\n",
    "            if download_source == \"scihub\":\n",
    "                queries_and_downloads.download_s2_data_from_df(\n",
    "                    l1c_products,\n",
    "                    l1_image_dir,\n",
    "                    l2_image_dir,\n",
    "                    download_source,\n",
    "                    user=sen_user,\n",
    "                    passwd=sen_pass,\n",
    "                    try_scihub_on_fail=True,\n",
    "                )\n",
    "            elif download_source == \"dataspace\":\n",
    "                    queries_and_downloads.download_s2_data_from_dataspace(\n",
    "                    product_df=l1c_products,\n",
    "                    l1c_directory=l1_image_dir,\n",
    "                    l2a_directory=l2_image_dir,\n",
    "                    dataspace_username=sen_user,\n",
    "                    dataspace_password=sen_pass,\n",
    "                    log=tile_log\n",
    "                )\n",
    "            else:\n",
    "                tile_log.error(\n",
    "                    f\"download source specified did not match 'scihub' or 'dataspace'\"\n",
    "                    )\n",
    "                tile_log.error(\n",
    "                    f\"download source supplied was  :  {download_source}\"\n",
    "                    )\n",
    "                tile_log.error(\"Exiting pipeline...\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            tile_log.info(\"Downloaded the Sentinel-2 L1C products.\")\n",
    "            tile_log.info(\"Atmospheric correction with sen2cor.\")\n",
    "            raster_manipulation.atmospheric_correction(\n",
    "                l1_image_dir,\n",
    "                l2_image_dir,\n",
    "                sen2cor_path,\n",
    "                delete_unprocessed_image=False,\n",
    "                log=tile_log,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            tile_log.warning(\"  Sen2Cor path does not exist. Cannot convert L1C \"+\n",
    "                        \"to L2A. Skipping download of L1C images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4490a3d",
   "metadata": {
    "id": "a4490a3d"
   },
   "source": [
    "## Download L2A Change Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7340dee5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173478,
     "status": "ok",
     "timestamp": 1726525042420,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "7340dee5",
    "outputId": "a93c99b6-5fca-4321-ed9f-aad1cbc77844",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:15:34,461: WARNING: L2A image download list contains 37 L2A products. This exceeds the set download limit of 3. Only the first images will be downloaded.\n",
      "2024-09-25 16:15:34,463: INFO: Downloading Sentinel-2 L2A products from dataspace\n",
      "2024-09-25 16:15:34,465: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 16:15:34,465: INFO: Checking 1 of 3 : S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:15:34,467: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE does not exist.\n",
      "2024-09-25 16:15:34,468: INFO:     Downloading  : S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:15:35,128: INFO: response.status_code: 301\n",
      "2024-09-25 16:15:35,129: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(f3b18418-8a26-4059-b833-1a74eab07dbd)/$value\n",
      "2024-09-25 16:22:51,510: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 16:22:51,511: INFO: Checking 2 of 3 : S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:22:51,513: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE does not exist.\n",
      "2024-09-25 16:22:51,514: INFO:     Downloading  : S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:22:52,193: INFO: response.status_code: 301\n",
      "2024-09-25 16:22:52,194: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(a6fa0dde-45f4-4e9f-9e37-c2688803ed82)/$value\n",
      "2024-09-25 16:25:57,058: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 16:25:57,059: INFO: Checking 3 of 3 : S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE\n",
      "2024-09-25 16:25:57,060: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE does not exist.\n",
      "2024-09-25 16:25:57,061: INFO:     Downloading  : S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE\n",
      "2024-09-25 16:25:57,521: INFO: response.status_code: 301\n",
      "2024-09-25 16:25:57,522: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(e50758da-6ca5-4e4b-8464-c991136e2fcc)/$value\n",
      "2024-09-25 16:29:37,767: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:37,768: INFO: L2A image download of change detection images is complete.\n",
      "2024-09-25 16:29:37,768: INFO: ---------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 16.2 s, total: 38.2 s\n",
      "Wall time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    if l2a_products.shape[0] > download_limit:\n",
    "       tile_log.warning(f\"L2A image download list contains {l2a_products.shape[0]}\"+\n",
    "                        \" L2A products. This exceeds the set download limit \"+\n",
    "                        f\"of {download_limit}. Only the first images will be downloaded.\")\n",
    "       l2a_products = l2a_products[0:download_limit]\n",
    "    if l2a_products.shape[0] > 0:\n",
    "        tile_log.info(f\"Downloading Sentinel-2 L2A products from {download_source}\")\n",
    "\n",
    "        if download_source == \"scihub\":\n",
    "            queries_and_downloads.download_s2_data(\n",
    "                l2a_products.to_dict(\"index\"),\n",
    "                l1_image_dir,\n",
    "                l2_image_dir,\n",
    "                download_source,\n",
    "                user=sen_user,\n",
    "                passwd=sen_pass,\n",
    "                try_scihub_on_fail=True,\n",
    "            )\n",
    "        if download_source == \"dataspace\":\n",
    "            queries_and_downloads.download_s2_data_from_dataspace(\n",
    "                product_df=l2a_products,\n",
    "                l1c_directory=l1_image_dir,\n",
    "                l2a_directory=l2_image_dir,\n",
    "                dataspace_username=sen_user,\n",
    "                dataspace_password=sen_pass,\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "    # check for incomplete L2A downloads and remove them\n",
    "    incomplete_downloads, sizes = raster_manipulation.find_small_safe_dirs(\n",
    "        l2_image_dir, threshold=faulty_granule_threshold * 1024 * 1024\n",
    "    )\n",
    "    if len(incomplete_downloads) > 0:\n",
    "        for index, safe_dir in enumerate(incomplete_downloads):\n",
    "            if sizes[\n",
    "                index\n",
    "            ] / 1024 / 1024 < faulty_granule_threshold and os.path.exists(safe_dir):\n",
    "                tile_log.warning(\n",
    "                    \"Found likely incomplete download of size {} MB: {}\".format(\n",
    "                        str(round(sizes[index] / 1024 / 1024)), safe_dir\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"L2A image download of change detection images is complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce831c1e",
   "metadata": {
    "id": "ce831c1e"
   },
   "source": [
    "## Housekeeping - Compress L1Cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9ba5c",
   "metadata": {
    "id": "01c9ba5c"
   },
   "source": [
    "If you have set your `do_zip` argument to `True`, then this cell will compress the L1Cs now that they have been atmospherically corrected and relabelled as L2As."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3db0ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1726525042420,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "fd3db0ed",
    "outputId": "8ea6bd75-8e55-4e16-dbdd-06768899c40b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:29:37,778: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:37,780: INFO: Zipping L1C images downloaded for change detection\n",
      "2024-09-25 16:29:37,780: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:38,505: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:38,506: INFO: Zipping complete\n",
      "2024-09-25 16:29:38,507: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:38,508: INFO: Housekeeping cell successfully finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.83 ms, sys: 2.59 ms, total: 8.42 ms\n",
      "Wall time: 730 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    if config_dict[\"do_delete\"]:\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Deleting L1C images downloaded for change detection.\")\n",
    "        tile_log.info(\"Keeping only the derived L2A images after atmospheric correction.\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        directory = l1_image_dir\n",
    "        tile_log.info(\"Deleting {}\".format(directory))\n",
    "        shutil.rmtree(directory)\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Deletion complete\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "    else:\n",
    "        if config_dict[\"do_zip\"]:\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(\"Zipping L1C images downloaded for change detection\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            filesystem_utilities.zip_contents(l1_image_dir)\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(\"Zipping complete\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    tile_log.info(\"Housekeeping cell successfully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d8827",
   "metadata": {
    "id": "ae9d8827"
   },
   "source": [
    "# Cloud Masking, Offsetting and Quicklooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfa11e",
   "metadata": {
    "id": "c8dfa11e"
   },
   "source": [
    "Here, like before in the previous session, we cloud mask, apply the baseline offset correction and produce quicklooks (if selected).  \n",
    "\n",
    "Additionally, if you have set the `do_zip` flag to True, then `pyeo` will compress the cloud masked L2A images, as we no longer need these once classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca3e0d-2fea-4d33-a21b-109d42b03c67",
   "metadata": {
    "id": "e1ca3e0d-2fea-4d33-a21b-109d42b03c67"
   },
   "source": [
    "## Cloud Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000a7f4-43b0-414e-8991-e596ede13c09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 852262,
     "status": "ok",
     "timestamp": 1726525894665,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "3000a7f4-43b0-414e-8991-e596ede13c09",
    "outputId": "64025f66-96a1-41c8-d6f3-21c0343bac60",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:29:39,497: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:39,498: INFO: Applying simple cloud, cloud shadow and haze mask based on SCL files and stacking the masked band raster files.\n",
      "2024-09-25 16:29:39,499: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 16:29:39,502: INFO: Files for cloud masking:\n",
      "2024-09-25 16:29:39,502: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:29:39,503: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:29:39,504: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2A_MSIL2A_20240316T074651_N0510_R135_T36NXG_20240316T110248.SAFE\n",
      "2024-09-25 16:29:39,504: INFO: 3 L2A raster files are in the file list for SCL cloud masking.\n",
      "2024-09-25 16:29:39,505: INFO:   Applying SCL cloud mask to L2A raster file: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:29:39,506: INFO: TMP:  Granule ID  : S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645\n",
      "2024-09-25 16:29:39,506: INFO: TMP:  File pattern: S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG\n",
      "2024-09-25 16:29:39,520: INFO: Merging band rasters into a single file:\n",
      "2024-09-25 16:29:39,521: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE/GRANULE/L2A_T36NXG_A036669_20240314T081324/IMG_DATA/R10m/T36NXG_20240314T075709_B02_10m.jp2\n",
      "2024-09-25 16:29:39,521: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE/GRANULE/L2A_T36NXG_A036669_20240314T081324/IMG_DATA/R10m/T36NXG_20240314T075709_B03_10m.jp2\n",
      "2024-09-25 16:29:39,522: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE/GRANULE/L2A_T36NXG_A036669_20240314T081324/IMG_DATA/R10m/T36NXG_20240314T075709_B04_10m.jp2\n",
      "2024-09-25 16:29:39,523: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE/GRANULE/L2A_T36NXG_A036669_20240314T081324/IMG_DATA/R10m/T36NXG_20240314T075709_B08_10m.jp2\n",
      "2024-09-25 16:32:22,969: INFO: stacked file stats:\n",
      "2024-09-25 16:32:42,470: INFO: Raster file stats for /home/cmsstudent/Desktop/pyeo_data/36NXG/tmpombty_6t/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645_stacked.tif\n",
      "2024-09-25 16:32:42,471: INFO:    band_1 : min=1.000, max=19376.000000, mean=1523.595520, stdev=257.471078\n",
      "2024-09-25 16:32:42,471: INFO:    band_2 : min=969.000, max=14368.000000, mean=1780.015152, stdev=262.087637\n",
      "2024-09-25 16:32:42,472: INFO:    band_3 : min=1012.000, max=15904.000000, mean=1862.998406, stdev=330.651841\n",
      "2024-09-25 16:32:42,473: INFO:    band_4 : min=1019.000, max=14856.000000, mean=3342.231077, stdev=517.907904\n",
      "2024-09-25 16:32:42,474: INFO: Creating scene classification mask for /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE\n",
      "2024-09-25 16:32:42,475: INFO:   containing SCL classes: [0, 1, 2, 3, 8, 9, 10, 11]\n",
      "2024-09-25 16:32:42,478: INFO:   Opening scene classification layer (SCL) file: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645.SAFE/GRANULE/L2A_T36NXG_A036669_20240314T081324/IMG_DATA/R20m/T36NXG_20240314T075709_SCL_20m.jp2\n",
      "2024-09-25 16:32:42,479: INFO: TMP:  SCL class values to be masked out: [0, 1, 2, 3, 8, 9, 10, 11]\n",
      "2024-09-25 16:32:43,288: INFO: TMP:  SCL class value histogram:\n",
      "2024-09-25 16:32:43,289: INFO: TMP:    0: 23071121 --> NO_DATA\n",
      "2024-09-25 16:32:43,290: INFO: TMP:    2: 6 --> DARK_AREA_PIXELS\n",
      "2024-09-25 16:32:43,290: INFO: TMP:    3: 178 --> CLOUD_SHADOWS\n",
      "2024-09-25 16:32:43,291: INFO: TMP:    4: 4030831 --> VEGETATION\n",
      "2024-09-25 16:32:43,291: INFO: TMP:    5: 2740416 --> NOT_VEGETATED\n",
      "2024-09-25 16:32:43,292: INFO: TMP:    6: 219806 --> WATER\n",
      "2024-09-25 16:32:43,292: INFO: TMP:    7: 32498 --> UNCLASSIFIED\n",
      "2024-09-25 16:32:43,293: INFO: TMP:    8: 41510 --> CLOUD_MEDIUM_PROBABILITY\n",
      "2024-09-25 16:32:43,293: INFO: TMP:    10: 3734 --> THIN_CIRRUS\n",
      "2024-09-25 16:32:44,414: INFO: TMP:  Mask value histogram:\n",
      "2024-09-25 16:32:44,415: INFO: TMP:    0: 23116549\n",
      "2024-09-25 16:32:44,416: INFO: TMP:    1: 7023551\n",
      "2024-09-25 16:32:48,048: INFO: mask file stats:\n",
      "2024-09-25 16:32:49,134: INFO: Raster file stats for /home/cmsstudent/Desktop/pyeo_data/36NXG/tmpombty_6t/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645_stacked.msk\n",
      "2024-09-25 16:32:49,135: INFO:    band_1 : min=0.000, max=1.000000, mean=0.225887, stdev=0.418165\n",
      "2024-09-25 16:33:47,250: INFO: masked file stats:\n",
      "2024-09-25 16:33:56,389: INFO: Raster file stats for /home/cmsstudent/Desktop/pyeo_data/36NXG/tmpombty_6t/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645_stacked_masked.tif\n",
      "2024-09-25 16:33:56,390: INFO:    band_1 : min=270.000, max=19376.000000, mean=1507.026367, stdev=222.190170\n",
      "2024-09-25 16:33:56,391: INFO:    band_2 : min=969.000, max=14368.000000, mean=1766.216919, stdev=239.739182\n",
      "2024-09-25 16:33:56,391: INFO:    band_3 : min=1012.000, max=15904.000000, mean=1853.254150, stdev=321.915100\n",
      "2024-09-25 16:33:56,392: INFO:    band_4 : min=1019.000, max=14856.000000, mean=3358.235840, stdev=506.357178\n",
      "2024-09-25 16:34:04,290: INFO: masked file after resampling in place - stats:\n",
      "2024-09-25 16:34:12,529: INFO: Raster file stats for /home/cmsstudent/Desktop/pyeo_data/36NXG/tmpombty_6t/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645_stacked_masked.tif\n",
      "2024-09-25 16:34:12,529: INFO:    band_1 : min=270.000, max=19376.000000, mean=1507.026367, stdev=222.190170\n",
      "2024-09-25 16:34:12,530: INFO:    band_2 : min=969.000, max=14368.000000, mean=1766.216919, stdev=239.739182\n",
      "2024-09-25 16:34:12,530: INFO:    band_3 : min=1012.000, max=15904.000000, mean=1853.254150, stdev=321.915100\n",
      "2024-09-25 16:34:12,531: INFO:    band_4 : min=1019.000, max=14856.000000, mean=3358.235840, stdev=506.357178\n",
      "2024-09-25 16:34:12,531: INFO:   Reprojecting stacked and masked image to EPSG code 21097\n",
      "2024-09-25 16:34:12,532: INFO: Reprojecting /home/cmsstudent/Desktop/pyeo_data/36NXG/tmpombty_6t/S2B_MSIL2A_20240314T075709_N0510_R035_T36NXG_20240314T101645_stacked_masked.tif\n",
      "2024-09-25 16:34:42,106: INFO:   Applying SCL cloud mask to L2A raster file: /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE\n",
      "2024-09-25 16:34:45,118: INFO: TMP:  Granule ID  : S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534\n",
      "2024-09-25 16:34:45,118: INFO: TMP:  File pattern: S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG\n",
      "2024-09-25 16:34:45,175: INFO: Merging band rasters into a single file:\n",
      "2024-09-25 16:34:45,176: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE/GRANULE/L2A_T36NXG_A036340_20240220T080450/IMG_DATA/R10m/T36NXG_20240220T074949_B02_10m.jp2\n",
      "2024-09-25 16:34:45,177: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE/GRANULE/L2A_T36NXG_A036340_20240220T080450/IMG_DATA/R10m/T36NXG_20240220T074949_B03_10m.jp2\n",
      "2024-09-25 16:34:45,178: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE/GRANULE/L2A_T36NXG_A036340_20240220T080450/IMG_DATA/R10m/T36NXG_20240220T074949_B04_10m.jp2\n",
      "2024-09-25 16:34:45,178: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/images/L2A/S2B_MSIL2A_20240220T074949_N0510_R135_T36NXG_20240220T100534.SAFE/GRANULE/L2A_T36NXG_A036340_20240220T080450/IMG_DATA/R10m/T36NXG_20240220T074949_B08_10m.jp2\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_change\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Applying simple cloud, cloud shadow and haze mask based on SCL files \"+\n",
    "        \"and stacking the masked band raster files.\"\n",
    "    )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    directory = l2_masked_image_dir\n",
    "    masked_file_paths = [\n",
    "        f\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(\".tif\") and os.path.isfile(os.path.join(directory, f))\n",
    "    ]\n",
    "\n",
    "    # unzip any zip files in the l2_image_dir if they have not been cloud masked yet\n",
    "    directory = l2_image_dir\n",
    "    l2a_zip_file_paths = [f for f in os.listdir(directory) if f.endswith(\".zip\")]\n",
    "    if len(l2a_zip_file_paths) > 0:\n",
    "        for f in l2a_zip_file_paths:\n",
    "            # check whether the zipped file has already been cloud masked\n",
    "            zip_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "                os.path.basename(f)\n",
    "            ).strftime(\"%Y%m%dT%H%M%S\")\n",
    "            if any(zip_timestamp in f for f in masked_file_paths):\n",
    "                continue\n",
    "            else:\n",
    "                # extract it if not\n",
    "                filesystem_utilities.unzip_contents(\n",
    "                    os.path.join(directory, f),\n",
    "                    ifstartswith=\"S2\",\n",
    "                    ending=\".SAFE\",\n",
    "                )\n",
    "\n",
    "    # get list of .SAFE files for cloud masking after unzipping\n",
    "    l2a_safe_file_paths = [\n",
    "        os.path.join(directory, f)\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(\".SAFE\") and os.path.isdir(os.path.join(directory, f))\n",
    "    ]\n",
    "\n",
    "    files_for_cloud_masking = []\n",
    "    if len(l2a_safe_file_paths) > 0:\n",
    "        for f in l2a_safe_file_paths:\n",
    "            # check whether the L2A SAFE file has already been cloud masked\n",
    "            safe_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "                os.path.basename(f)\n",
    "            ).strftime(\"%Y%m%dT%H%M%S\")\n",
    "            if any(safe_timestamp in f for f in masked_file_paths):\n",
    "                continue\n",
    "            else:\n",
    "                # add it to the list of files to do if it has not been cloud masked yet\n",
    "                files_for_cloud_masking = files_for_cloud_masking + [f]\n",
    "\n",
    "    if len(files_for_cloud_masking) == 0:\n",
    "        tile_log.info(\"No L2A images found for cloud masking. They may already have been done.\")\n",
    "    else:\n",
    "        tile_log.info(\"Files for cloud masking:\")\n",
    "        for f in files_for_cloud_masking:\n",
    "            tile_log.info(f\"  {f}\")\n",
    "        raster_manipulation.apply_scl_cloud_mask_to_filelist(\n",
    "            files_for_cloud_masking,\n",
    "            l2_masked_image_dir,\n",
    "            scl_classes=[0, 1, 2, 3, 8, 9, 10, 11],\n",
    "            buffer_size=buffer_size,\n",
    "            bands=bands,\n",
    "            out_resolution=out_resolution,\n",
    "            haze=None,\n",
    "            epsg=epsg,\n",
    "            skip_existing=skip_existing,\n",
    "            log=tile_log\n",
    "        )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Cloud masking and band stacking of new L2A images are complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac6cee-3923-4eeb-b6a8-f5565bcf2521",
   "metadata": {
    "id": "adac6cee-3923-4eeb-b6a8-f5565bcf2521"
   },
   "source": [
    "## Radiometric Offsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccdee14-a46a-45ae-a6dc-78309ab67856",
   "metadata": {
    "id": "2ccdee14-a46a-45ae-a6dc-78309ab67856"
   },
   "source": [
    "Let's correct for the radiometric offset to the digital numbers in the Sentinel-2 images that were processed with processing baseline 4.00 or later.\n",
    "https://sentiwiki.copernicus.eu/web/s2-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75c142-0712-46c9-ac9a-c438c3bd21e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162360,
     "status": "ok",
     "timestamp": 1726526056997,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "5e75c142-0712-46c9-ac9a-c438c3bd21e2",
    "outputId": "e5bc4a63-71b4-4c3a-cdc5-c1b9044e6177",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_change\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Offsetting cloud masked L2A images.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    raster_manipulation.apply_processing_baseline_offset_correction_to_tiff_file_directory(\n",
    "        in_tif_directory = l2_masked_image_dir,\n",
    "        out_tif_directory = l2_masked_image_dir,\n",
    "        bands_to_offset_labels=(\"B02\", \"B03\", \"B04\", \"B08\"),\n",
    "        bands_to_offset_index=[0, 1, 2, 3],\n",
    "        BOA_ADD_OFFSET=-1000,\n",
    "        backup_flag=False,\n",
    "        log = tile_log\n",
    "    )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Offsetting of cloud masked L2A images complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93749bf8-f962-4e75-b519-d772bcb5428c",
   "metadata": {
    "id": "93749bf8-f962-4e75-b519-d772bcb5428c"
   },
   "source": [
    "##Making Quicklooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa6e6c-ab81-4f7f-ad6f-d4f8dc325cf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1726526057265,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "37aa6e6c-ab81-4f7f-ad6f-d4f8dc325cf2",
    "outputId": "7662a2d4-48f4-444b-c98d-c130cc148abe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_download\"]:\n",
    "    if config_dict[\"do_quicklooks\"] or config_dict[\"do_all\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Producing quicklooks.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        dirs_for_quicklooks = [l2_masked_image_dir, l2_image_dir]\n",
    "        for main_dir in dirs_for_quicklooks:\n",
    "            files = [\n",
    "                f.path\n",
    "                for f in os.scandir(main_dir)\n",
    "                if f.is_file() and os.path.basename(f).endswith(\".tif\")\n",
    "            ]\n",
    "            if len(files) == 0:\n",
    "                tile_log.warning(\"No images found in {}.\".format(main_dir))\n",
    "            else:\n",
    "                for f in files:\n",
    "                    quicklook_path = os.path.join(\n",
    "                        quicklook_dir,\n",
    "                        os.path.basename(f).split(\".\")[0] + \".png\",\n",
    "                    )\n",
    "                    tile_log.info(\"Creating quicklook: {}\".format(quicklook_path))\n",
    "                    raster_manipulation.create_quicklook(\n",
    "                        f,\n",
    "                        quicklook_path,\n",
    "                        width=512,\n",
    "                        height=512,\n",
    "                        format=\"PNG\",\n",
    "                        bands=[3, 2, 1],\n",
    "                        nodata=0,\n",
    "                        scale_factors=[[0, 2000, 0, 255]],\n",
    "                        log=tile_log,\n",
    "                    )\n",
    "        tile_log.info(\"Quicklooks complete.\")\n",
    "    else:\n",
    "        tile_log.info(\"Quicklooks disabled in ini file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767a42f-5983-41bc-a0eb-97b971d4a11e",
   "metadata": {
    "id": "a767a42f-5983-41bc-a0eb-97b971d4a11e"
   },
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314ea16-18f7-4bb8-a720-ba14c69535b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60610,
     "status": "ok",
     "timestamp": 1726526117865,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "8314ea16-18f7-4bb8-a720-ba14c69535b6",
    "outputId": "f7dbefa0-8d77-4c5d-ace0-0148e21f1d7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_change\"]:\n",
    "    if config_dict[\"do_zip\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Zipping L2A images downloaded for change detection\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        filesystem_utilities.zip_contents(l2_image_dir)\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Zipping complete\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Compressing tiff files in directory {} and all subdirectories\".format(\n",
    "            l2_masked_image_dir\n",
    "        )\n",
    "    )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    for root, dirs, files in os.walk(l2_masked_image_dir):\n",
    "        all_tiffs = [\n",
    "            image_name for image_name in files if image_name.endswith(\".tif\")\n",
    "        ]\n",
    "        for this_tiff in all_tiffs:\n",
    "            raster_manipulation.compress_tiff(\n",
    "                os.path.join(root, this_tiff),\n",
    "                os.path.join(root, this_tiff),\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Pre-processing of change detection images, file compression, zipping\"\n",
    "    )\n",
    "    tile_log.info(\n",
    "        \"and deletion of intermediate file products (if selected) are complete.\"\n",
    "    )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abe8bf",
   "metadata": {
    "id": "d0abe8bf"
   },
   "source": [
    "# Classification of the Baseline Composite and Change Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QnFACkZb26Sl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63567,
     "status": "ok",
     "timestamp": 1726526228922,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "QnFACkZb26Sl",
    "outputId": "9618abaf-a3ce-4c05-a8bd-01e3b1e85f60"
   },
   "outputs": [],
   "source": [
    "# get all file names from composite_dir that start with \"composite\"\n",
    "composite_paths = [\n",
    "    os.path.join(composite_dir, f)\n",
    "    for f in os.listdir(composite_dir)\n",
    "    if f.startswith(\"composite\") and f.endswith(\".tif\") and\n",
    "    os.path.isfile(os.path.join(composite_dir, f))\n",
    "]\n",
    "\n",
    "if len(composite_paths) == 0:\n",
    "    tile_log.warning(\"No composite images found in {}\".format(composite_dir))\n",
    "else:\n",
    "    tile_log.info(\"Found image composite files:\")\n",
    "    for f in composite_paths:\n",
    "        tile_log.info(\"  {}\".format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db3d39-535f-415e-aab0-fc14c4a43291",
   "metadata": {
    "id": "27db3d39-535f-415e-aab0-fc14c4a43291"
   },
   "source": [
    "## Run the classification and apply the machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42244da4",
   "metadata": {
    "id": "42244da4"
   },
   "source": [
    "Here, we classify the Baseline Composite and the Change images using the model we created in the model training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13b672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2033607,
     "status": "ok",
     "timestamp": 1726528269068,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "8c13b672",
    "outputId": "74452e7c-09a2-4a48-e3e5-e3b731cb92ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    if config_dict[\"do_all\"] or config_dict[\"do_classify\"]:\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\n",
    "            \"Classify a land cover map for each L2A change detection image and \"+\n",
    "            \"composite image using a saved model\"\n",
    "        )\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Model used: {}\".format(model_path))\n",
    "\n",
    "        if skip_existing:\n",
    "            tile_log.info(\"Skipping existing classification images if found.\")\n",
    "\n",
    "        classification.classify_directory(\n",
    "            composite_dir,\n",
    "            model_path,\n",
    "            categorised_image_dir,\n",
    "            prob_out_dir=None,\n",
    "            apply_mask=False,\n",
    "            out_type=\"GTiff\",\n",
    "            chunks=config_dict[\"chunks\"],\n",
    "            skip_existing=skip_existing,\n",
    "            log=tile_log\n",
    "        )\n",
    "\n",
    "        classification.classify_directory(\n",
    "            l2_masked_image_dir,\n",
    "            model_path,\n",
    "            categorised_image_dir,\n",
    "            prob_out_dir=None,\n",
    "            apply_mask=False,\n",
    "            out_type=\"GTiff\",\n",
    "            chunks=config_dict[\"chunks\"],\n",
    "            skip_existing=skip_existing,\n",
    "            log=tile_log\n",
    "        )\n",
    "\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\n",
    "            f\"LZW-compressing tiff files in directory {categorised_image_dir} \"+\n",
    "            \"and all subdirectories\"\n",
    "            )\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "        for root, dirs, files in os.walk(categorised_image_dir):\n",
    "            all_tiffs = [\n",
    "                image_name for image_name in files if image_name.endswith(\".tif\")\n",
    "            ]\n",
    "            for this_tiff in all_tiffs:\n",
    "                raster_manipulation.compress_tiff(\n",
    "                    os.path.join(root, this_tiff),\n",
    "                    os.path.join(root, this_tiff),\n",
    "                    tile_log\n",
    "                )\n",
    "\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Classification of all images is complete.\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711cffd-1bb2-4fe2-96d8-2d50b777ae88",
   "metadata": {
    "id": "2711cffd-1bb2-4fe2-96d8-2d50b777ae88"
   },
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef962a98-5d2e-48e2-825d-2af21c94e2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1726528269069,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "ef962a98-5d2e-48e2-825d-2af21c94e2b3",
    "outputId": "0c1e7aab-7c70-41a8-cdd0-cfb7d367860f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_classify\"]:\n",
    "    if config_dict[\"do_quicklooks\"] or config_dict[\"do_all\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Producing quicklooks.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "        # do classification images only\n",
    "        dirs_for_quicklooks = [categorised_image_dir]\n",
    "\n",
    "        for main_dir in dirs_for_quicklooks:\n",
    "            files = [\n",
    "                os.path.join(main_dir, f)\n",
    "                for f in os.listdir(main_dir)\n",
    "                if os.path.isfile(os.path.join(main_dir, f)) and\n",
    "                f.endswith(\"class.tif\")\n",
    "            ]\n",
    "            if len(files) == 0:\n",
    "                tile_log.warning(\"No images found in {}.\".format(main_dir))\n",
    "            else:\n",
    "                for f in files:\n",
    "                    quicklook_path = os.path.join(\n",
    "                        quicklook_dir,\n",
    "                        os.path.basename(f).split(\".\")[0] + \".png\",\n",
    "                    )\n",
    "                    tile_log.info(\"Creating quicklook: {}\".format(quicklook_path))\n",
    "                    raster_manipulation.create_quicklook(\n",
    "                        in_raster_path = f,\n",
    "                        out_raster_path = quicklook_path,\n",
    "                        width=512,\n",
    "                        height=512,\n",
    "                        format=\"PNG\",\n",
    "                        bands=[1],\n",
    "                        nodata=None,\n",
    "                        scale_factors=None,\n",
    "                        log=tile_log\n",
    "                    )\n",
    "        tile_log.info(\"Quicklooks complete.\")\n",
    "    else:\n",
    "        tile_log.info(\"Quicklooks disabled in ini file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923b743",
   "metadata": {
    "id": "6923b743",
    "tags": []
   },
   "source": [
    "# Post-classification Change Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab11aae",
   "metadata": {
    "id": "fab11aae"
   },
   "source": [
    "To perform Change Detection, we take the Classified Change Imagery and compare it with the Classified Baseline Composite.\n",
    "\n",
    "Because we are concerned with monitoring deforestation for our Change Detection, `pyeo` examines whether any forest classes (*classes 1, 11 and 12*) change to non-forest classes (*classes 3, 4, 5 and 13*).  \n",
    "\n",
    "As new change imagery becomes available (*as deforestation monitoring is an iterative process through time*), these change images are classified and compared to the baseline, again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f0d36",
   "metadata": {
    "id": "404f0d36"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafa5d9",
   "metadata": {
    "id": "4cafa5d9"
   },
   "source": [
    "## Detect change between a new stack of images and the baseline composite\n",
    "\n",
    "detect_change.pyis an application that downloads and preprocesses a stack of Sentinel-2 images for change detection and classifies them using a machine learning model. It performs change detection against a baseline median image composite. The application then generates a report image file and optionally vectorises it if selected in the ini file.\n",
    "\n",
    "It can be run in two basic ways:\n",
    "\n",
    "1. detect_change.py ini_file_path.ini\n",
    "In this configuration, the composite creation is based on the processing parameters defined in the ini file.\n",
    "\n",
    "2. detect_change.py ini_file_path.ini --tile $tile_id\n",
    "The --tile flag identifies a tile ID of the Sentinel-2 tile. Specifying a tile ID overrides the geojson location of the area of interest from the ini file with a Sentinel-2 tile ID location.\n",
    "\n",
    "\n",
    "The overall Change Detection can be summarised as this:\n",
    "- PyEO first looks for the composite and change imagery classifications and orders them by most recent.\n",
    "- Then, it searches for existing report files created from previous PyEO runs and archive them, moving them to an archived folder.\n",
    "- Then it creates the change report by sequentially comparing the classified change imagery against the classified baseline composite.\n",
    "- Once finished, PyEO does some housekeeping, compressing unneeded files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08c081",
   "metadata": {
    "id": "4a08c081"
   },
   "source": [
    "## Meaning of the report file layers (bands), starting numbering from 0:\n",
    "Layer 0: Total Image Count: Counts the number of images processed per pixel - number of available images within overall cloud percentage cover limit set in pyeo.ini file.\n",
    "\n",
    "Layer 1: Occluded Image Count: Counts number of occasions a pixel is obscured by cloud or out-of-orbit\n",
    "\n",
    "Layer 2: Classifier Change Detection Count: Count if a from/to change of land cover classes was detected\n",
    "\n",
    "Layer 3: First-Change Trigger for Combined Classifier + dNDVI Hybrid Change Detection: Records the earliest date of a change detection between classes of interest where values are greater than zero (not missing data and not cloud). Where Layer 3 is zero and the change array contains a value > 0, this date will be burned into the report layer 3. Where Layer 3 is non-zero it is set to the earlier date.\n",
    "\n",
    "Layer 4: Combined Classifier + dNDVI Hybrid Change Detection Count: Count if a change was detected after a first change had already been detected previously.\n",
    "\n",
    "Layer 5: Combined Classifier + dNDVI Validated No Change Detection Count: Count if no change was detected after a first change had previously been detected.\n",
    "\n",
    "Layer 6: Cloud Occlusion Count: Count if a pixel is obscured by cloud or out-of-orbit after a first change had been detected.\n",
    "\n",
    "Layer 7: Valid Pixel Count: Total number of valid (no cloud, no missing data) images covering this pixel since first change was detected.\n",
    "\n",
    "Layer 8: Change Detection Repeatability: Repeatability of change detection after first change is detected - as a percentage of available valid images.\n",
    "\n",
    "Layer 9: Binary time-series decision: Based on percentage_probability_threshold and minimum_required_validated_detections_threshold.\n",
    "\n",
    "Layer 10: Binary time-series decision by first-change date: First change date masked by Binary Decision - Layer 9.\n",
    "\n",
    "Layer 11: dNDVI Only Change Detection Count: Count if a change was detected by the dNDVI test and that was not cloud occluded (or out-of-orbit).\n",
    "\n",
    "Layer 12: Binary time-series decision: Based on dNDVI Only and minimum_required_dNDVI_detections_threshold.\n",
    "\n",
    "Layer 13: Binary time-series decision: Based on Machine Learning Classifier Only.\n",
    "\n",
    "Layer 14: Combined Classifier+dNDVI Binary time-series decision: Based on machine learning classifier and dNDVI.\n",
    "\n",
    "Layer 15: FROM Classification Count.\n",
    "\n",
    "Layer 16: TO Classification Count.\n",
    "\n",
    "Layer 17: Binary Decision Thresholds on FROM and TO Classification Counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d5345-54bd-4d75-84ef-7f9a27274e5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1837522,
     "status": "ok",
     "timestamp": 1726530106537,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "484d5345-54bd-4d75-84ef-7f9a27274e5c",
    "outputId": "7f336f97-4bc1-4a6e-a559-87d18015ce26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_change\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Creating change layers from stacked class images.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Changes of interest:\")\n",
    "    tile_log.info(\n",
    "        \"  from any of the classes {}\".format(config_dict[\"from_classes\"])\n",
    "    )\n",
    "    tile_log.info(\"  to   any of the classes {}\".format(config_dict[\"to_classes\"]))\n",
    "\n",
    "    # optionally sieve the class images\n",
    "    if sieve > 0:\n",
    "        tile_log.info(\"Applying sieve to classification outputs.\")\n",
    "        sieved_paths = raster_manipulation.sieve_directory(\n",
    "            in_dir=categorised_image_dir,\n",
    "            out_dir=sieved_image_dir,\n",
    "            neighbours=8,\n",
    "            sieve=sieve,\n",
    "            out_type=\"GTiff\",\n",
    "            skip_existing=skip_existing,\n",
    "        )\n",
    "        # if sieve was chosen, work with the sieved class images\n",
    "        class_image_dir = sieved_image_dir\n",
    "    else:\n",
    "        # if sieve was not chosen, work with the original class images\n",
    "        class_image_dir = categorised_image_dir\n",
    "\n",
    "    # get all image paths in the classification maps directory except the class composites\n",
    "    class_image_paths = [\n",
    "        f.path\n",
    "        for f in os.scandir(class_image_dir)\n",
    "        if f.is_file() and f.name.endswith(\".tif\") and not \"composite_\" in f.name\n",
    "    ]\n",
    "    if len(class_image_paths) == 0:\n",
    "        raise FileNotFoundError(\n",
    "            \"No class images found in {}.\".format(class_image_dir)\n",
    "        )\n",
    "\n",
    "    # sort class images by image acquisition date\n",
    "    class_image_paths = list(\n",
    "        filter(filesystem_utilities.get_image_acquisition_time, class_image_paths)\n",
    "    )\n",
    "    class_image_paths.sort(\n",
    "        key=lambda x: filesystem_utilities.get_image_acquisition_time(x)\n",
    "    )\n",
    "    for index, image in enumerate(class_image_paths):\n",
    "        tile_log.info(\"{}: {}\".format(index, image))\n",
    "\n",
    "    # find the latest available composite\n",
    "    try:\n",
    "        latest_composite_name = filesystem_utilities.sort_by_timestamp(\n",
    "            [\n",
    "                image_name\n",
    "                for image_name in os.listdir(composite_dir)\n",
    "                if image_name.endswith(\".tif\")\n",
    "            ],\n",
    "            recent_first=True,\n",
    "        )[0]\n",
    "        latest_composite_path = os.path.join(composite_dir, latest_composite_name)\n",
    "        tile_log.info(\"Most recent composite at {}\".format(latest_composite_path))\n",
    "    except IndexError:\n",
    "        tile_log.critical(\n",
    "            \"Latest composite not found. The first time you run this script, you need to include the \"\n",
    "            \"--build-composite flag to create a base composite to work off. If you have already done this,\"\n",
    "            \"check that the earliest dated image in your images/merged folder is later than the earliest\"\n",
    "            \" dated image in your composite/ folder.\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    latest_class_composite_path = os.path.join(\n",
    "        class_image_dir,\n",
    "        [\n",
    "            f.path\n",
    "            for f in os.scandir(class_image_dir)\n",
    "            if f.is_file()\n",
    "            and os.path.basename(latest_composite_path)[:-4] in f.name\n",
    "            and f.name.endswith(\".tif\")\n",
    "        ][0],\n",
    "    )\n",
    "\n",
    "    tile_log.info(\n",
    "        f\"Most recent classification map of a composite at {latest_class_composite_path}\"\n",
    "    )\n",
    "    if not os.path.exists(latest_class_composite_path):\n",
    "        tile_log.critical(\n",
    "            \"Latest class composite not found. The first time you run this \"+\n",
    "            \"script, you need to include the --build-composite flag to create \"+\n",
    "            \"a base composite to work off. If you have already done this,\"+\n",
    "            \" check that the earliest dated image in your images/merged folder \"+\n",
    "            \"is later than the earliest dated image in your composite/ folder. \"+\n",
    "            \"Then, you need to run the --classify option.\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    before_timestamp = filesystem_utilities.get_change_detection_dates(\n",
    "        os.path.basename(latest_class_composite_path)\n",
    "    )[0]\n",
    "    # Timestamp report with the date of most recent classified image that contributes to it\n",
    "    after_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "        os.path.basename(class_image_paths[-1])\n",
    "    )\n",
    "    output_product = os.path.join(\n",
    "        report_image_dir,\n",
    "        \"report_{}_{}_{}.tif\".format(\n",
    "            before_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "            tile_to_process,\n",
    "            after_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "        ),\n",
    "    )\n",
    "    tile_log.info(\"Report file name will be {}\".format(output_product))\n",
    "\n",
    "    # if a report file exists, archive it\n",
    "    if os.path.isfile(output_product):\n",
    "        tile_log.info(f\"Report file already exists:  {output_product}\")\n",
    "        # if an earlier report file exists, archive it\n",
    "        output_products_existing = [\n",
    "            f.path\n",
    "            for f in os.scandir(report_image_dir)\n",
    "            if f.is_file()\n",
    "            and f.name.startswith(\"report_\")\n",
    "            and f.name.endswith(\".tif\")\n",
    "        ]\n",
    "        n_report_files = len(output_products_existing)\n",
    "\n",
    "        if n_report_files > 0:\n",
    "            for output_product_existing in output_products_existing:\n",
    "                # do not archive the current report image file\n",
    "                if output_product_existing != output_product:\n",
    "                    tile_log.info(\n",
    "                        \"Found existing earlier report image product: \"+\n",
    "                        f\" {output_product_existing}\"\n",
    "                        )\n",
    "\n",
    "                    output_product_existing_archived = os.path.join(\n",
    "                        os.path.dirname(output_product_existing),\n",
    "                        \"archived_\" + os.path.basename(output_product_existing),\n",
    "                    )\n",
    "\n",
    "                    i = 1\n",
    "                    if len(output_product_existing_archived.split(\".\")) == 2:\n",
    "                        beginning = output_product_existing_archived.split(\".\")[0]\n",
    "                    else:\n",
    "                        if len(output_product_existing_archived.split(\".\")) > 2:\n",
    "                            beginning = \".\".join(\n",
    "                                output_product_existing_archived.split(\".\")[0:-1]\n",
    "                                )\n",
    "                    # instead of appending _1 indefinitely, isolate the _N part\n",
    "                    #   of the filename and increase it by one\n",
    "                    archive_path = beginning + f\"_{i}.\" + output_product_existing_archived.split(\".\")[-1]\n",
    "                    if os.path.exists(archive_path):\n",
    "                        while os.path.exists(archive_path):\n",
    "                            i = i + 1\n",
    "                            archive_path = beginning + f\"_{i}.\" + to_path.split(\".\")[-1]\n",
    "                    output_product_existing_archived = archive_path\n",
    "\n",
    "                    filesystem_utilities.move_and_rename_old_file(\n",
    "                        output_product_existing,\n",
    "                        output_product_existing_archived\n",
    "                        )\n",
    "    else:\n",
    "        tile_log.info(f\"Report file to be created:  {output_product}\")\n",
    "\n",
    "    # find change patterns in the stack of classification images\n",
    "    for index, image in enumerate(class_image_paths):\n",
    "        before_timestamp = filesystem_utilities.get_change_detection_dates(\n",
    "            os.path.basename(latest_class_composite_path)\n",
    "        )[0]\n",
    "        after_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "            os.path.basename(image)\n",
    "        )\n",
    "        tile_log.info(\"-----------------------------------------------------------------------------\")\n",
    "        tile_log.info(\n",
    "            \"Processing classification image {} of {}: {}\".format(\n",
    "                index+1, len(class_image_paths), image\n",
    "            )\n",
    "        )\n",
    "        tile_log.info(\"  early time stamp: {}\".format(before_timestamp))\n",
    "        tile_log.info(\"  late  time stamp: {}\".format(after_timestamp))\n",
    "        change_raster = os.path.join(\n",
    "            probability_image_dir,\n",
    "            \"change_{}_{}_{}.tif\".format(\n",
    "                before_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "                tile_to_process,\n",
    "                after_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "            ),\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"  Change raster file to be created: {}\".format(change_raster)\n",
    "        )\n",
    "\n",
    "        dNDVI_raster = os.path.join(\n",
    "            probability_image_dir,\n",
    "            \"dNDVI_{}_{}_{}.tif\".format(\n",
    "                before_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "                tile_to_process,\n",
    "                after_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "            ),\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"  dNDVI raster file to be created: {}\".format(dNDVI_raster)\n",
    "        )\n",
    "\n",
    "        NDVI_raster = os.path.join(\n",
    "            probability_image_dir,\n",
    "            \"NDVI_{}_{}_{}.tif\".format(\n",
    "                before_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "                tile_to_process,\n",
    "                after_timestamp.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "            ),\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"  NDVI raster file of change image to be created: {}\".format(\n",
    "                NDVI_raster\n",
    "            )\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        The change_from_class_maps() function looks for changes from class\n",
    "        'change_from' in the composite to any of the 'change_to_classes'\n",
    "        in the change images. Pixel values are the acquisition date of the\n",
    "        detected change of interest or zero.\n",
    "        Optionally, changes will be confirmed by thresholding a vegetation\n",
    "        index calculated from two bands if the difference between\n",
    "        the more recent date and the older date is below the confirmation\n",
    "        threshold (e.g. NDVI < -0.2).\n",
    "        '''\n",
    "\n",
    "        tile_log.info(\"Update of the report image product based on change \"+\n",
    "                      \"detection image.\")\n",
    "        raster_manipulation.change_from_class_maps(\n",
    "            old_class_path=latest_class_composite_path,\n",
    "            new_class_path=image,\n",
    "            change_raster=change_raster,\n",
    "            dNDVI_raster=dNDVI_raster,\n",
    "            NDVI_raster=NDVI_raster,\n",
    "            change_from=from_classes,\n",
    "            change_to=to_classes,\n",
    "            report_path=output_product,\n",
    "            skip_existing=skip_existing,\n",
    "            old_image_dir=composite_dir,\n",
    "            new_image_dir=l2_masked_image_dir,\n",
    "            viband1=4,\n",
    "            viband2=3,\n",
    "            dNDVI_threshold=-0.2,\n",
    "            log=tile_log,\n",
    "        )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Post-classification change detection complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Report image product completed / updated: {}\".format(output_product)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1bc65-f0ca-48c8-a6a6-e2d197904239",
   "metadata": {
    "id": "06f1bc65-f0ca-48c8-a6a6-e2d197904239"
   },
   "source": [
    "## Vectorise the report image file\n",
    "Now, we convert the report image file to vector format. This saves disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cd636-79cf-46e8-a0de-d51eca2d75f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48974,
     "status": "ok",
     "timestamp": 1726530155480,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "e12cd636-79cf-46e8-a0de-d51eca2d75f6",
    "outputId": "831a7bdb-8e6b-4529-eb13-f9bfae825c42"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_vectorise\"]:\n",
    "    # get other parameters\n",
    "    epsg = config_dict[\"epsg\"]\n",
    "    level_1_boundaries_path = config_dict[\"level_1_boundaries_path\"]\n",
    "\n",
    "    # get all report.tif file names that are within the report_image_dir\n",
    "    search_pattern = os.path.join(report_image_dir, \"report*.tif\")\n",
    "    change_report_paths = glob.glob(\n",
    "        os.path.join(config_dict[\"tile_dir\"], search_pattern)\n",
    "    )\n",
    "    if len(change_report_paths) == 0:\n",
    "        tile_log.error(\"No change report image path(s) found that match pattern: \\'\"+\n",
    "                       f\"{search_pattern}\\'\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        tile_log.info(\"Change report image path(s) found:\")\n",
    "        for p in change_report_paths:\n",
    "            tile_log.info(f\"  {p}\")\n",
    "\n",
    "    tile_log.info(\"--\" * 20)\n",
    "    tile_log.info(\"Starting Vectorisation of the Change Report Rasters\")\n",
    "    tile_log.info(\"--\" * 20)\n",
    "\n",
    "    # iterate over the list of report image files\n",
    "    output_vector_files = []\n",
    "    for change_report_path in change_report_paths:\n",
    "        tile_log.info(f\"Processing report image file: {change_report_path}\")\n",
    "\n",
    "        if os.path.exists(change_report_path[:-4]+\".shp\"):\n",
    "            tile_log.info(f\"Skipping. Found {change_report_path[:-4]}.shp\")\n",
    "\n",
    "        else:\n",
    "            path_vectorised_binary = vectorisation.vectorise_from_band(\n",
    "                change_report_path=change_report_path,\n",
    "                band=9, # was 15 before but missed a lot of alerts in the vector file\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "            path_vectorised_binary_filtered = vectorisation.clean_zero_nodata_vectorised_band(\n",
    "                vectorised_band_path=path_vectorised_binary,\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "            tile_log.info(f\"vectorised_file_path = {path_vectorised_binary_filtered}\")\n",
    "\n",
    "            # Note: zonal_statistics() returns None if no statistics were computed.\n",
    "            # In cases where the shapefile is not right, this causes an error.\n",
    "            rb_ndetections_zstats_df = vectorisation.zonal_statistics(\n",
    "                raster_path=change_report_path,\n",
    "                shapefile_path=path_vectorised_binary_filtered,\n",
    "                report_band=5,\n",
    "                log=tile_log\n",
    "                )\n",
    "\n",
    "            rb_confidence_zstats_df = vectorisation.zonal_statistics(\n",
    "                raster_path=change_report_path,\n",
    "                shapefile_path=path_vectorised_binary_filtered,\n",
    "                report_band=9,\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "            rb_first_changedate_zstats_df = vectorisation.zonal_statistics(\n",
    "                raster_path=change_report_path,\n",
    "                shapefile_path=path_vectorised_binary_filtered,\n",
    "                report_band=4,\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "            # table joins, area, lat lon, county\n",
    "            output_vector_files.append(\n",
    "                vectorisation.merge_and_calculate_spatial(\n",
    "                    rb_ndetections_zstats_df=rb_ndetections_zstats_df,\n",
    "                    rb_confidence_zstats_df=rb_confidence_zstats_df,\n",
    "                    rb_first_changedate_zstats_df=rb_first_changedate_zstats_df,\n",
    "                    path_to_vectorised_binary_filtered=path_vectorised_binary_filtered,\n",
    "                    write_csv=False,\n",
    "                    write_shapefile=True,\n",
    "                    write_kml=True,\n",
    "                    write_pkl=False,\n",
    "                    change_report_path=change_report_path,\n",
    "                    log=tile_log,\n",
    "                    epsg=epsg,\n",
    "                    level_1_boundaries_path=level_1_boundaries_path,\n",
    "                    tileid=tile_to_process,\n",
    "                    delete_intermediates=True,\n",
    "                )\n",
    "            )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Report image vectorised. Output file(s) created:\")\n",
    "    for i in range(len(output_vector_files)):\n",
    "        tile_log.info(f\"  {output_vector_files[i]}\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628e59",
   "metadata": {
    "id": "9b628e59"
   },
   "source": [
    "## Final Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8e924",
   "metadata": {
    "id": "3fa8e924"
   },
   "source": [
    "Finally, we run some more housekeeping, deleting or compressing unnecessary files, depending on the argument supplied at the beginning of this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d0921",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1726530156036,
     "user": {
      "displayName": "Heiko Balzter",
      "userId": "05402170786492137055"
     },
     "user_tz": -60
    },
    "id": "b67d0921",
    "outputId": "13cdbf1d-84c9-4366-adc2-67fc5de266c7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "directories = [\n",
    "    categorised_image_dir,\n",
    "    sieved_image_dir,\n",
    "    probability_image_dir,\n",
    "]\n",
    "if config_dict[\"do_all\"] or config_dict[\"do_change\"]:\n",
    "    for directory in directories:\n",
    "        if os.path.exists(directory):\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(f\"Compressing tiff files in directory {directory} and \"+\n",
    "                          \"all subdirectories\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                all_tiffs = [\n",
    "                    image_name for image_name in files if image_name.endswith(\".tif\")\n",
    "                ]\n",
    "                for this_tiff in all_tiffs:\n",
    "                    raster_manipulation.compress_tiff(\n",
    "                        os.path.join(root, this_tiff),\n",
    "                        os.path.join(root, this_tiff),\n",
    "                        log=tile_log\n",
    "                    )\n",
    "\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    if config_dict[\"do_delete\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"Deleting intermediate class images used in change detection.\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"They can be recreated from the cloud-masked, band-stacked L2A images and the saved model.\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        for directory in directories:\n",
    "            if os.path.exists(directory):\n",
    "                paths = [f for f in os.listdir(directory)]\n",
    "                for f in paths:\n",
    "                    # keep the classified composite layers and the report image\n",
    "                    #    product for the next change detection\n",
    "                    if not f.startswith(\"composite_\") and not f.startswith(\"report_\"):\n",
    "                        tile_log.info(f\"Deleting {os.path.join(directory, f)}\")\n",
    "                        if os.path.isdir(os.path.join(directory, f)):\n",
    "                            shutil.rmtree(os.path.join(directory, f))\n",
    "                        else:\n",
    "                            os.remove(os.path.join(directory, f))\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Deletion of intermediate file products complete.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "    else:\n",
    "        if config_dict[\"do_zip\"]:\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"Zipping intermediate class images used in change detection\"\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            directories = [categorised_image_dir, sieved_image_dir]\n",
    "            for directory in directories:\n",
    "                filesystem_utilities.zip_contents(\n",
    "                    directory, notstartswith=[\"composite_\", \"report_\"]\n",
    "                )\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            tile_log.info(\"Zipping complete\")\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Change detection and report image product updating, file compression, zipping\"\n",
    "    )\n",
    "    tile_log.info(\n",
    "        \"and deletion of intermediate file products (if selected) are complete.\"\n",
    "    )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    if config_dict[\"do_delete\"]:\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Deleting temporary directories starting with 'tmp*'\")\n",
    "        tile_log.info(\"These can be left over from interrupted processing runs.\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        directory = pyeo_dir\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            temp_dirs = [d for d in dirs if d.startswith(\"tmp\")]\n",
    "            for temp_dir in temp_dirs:\n",
    "                tile_log.info(f\"Deleting {os.path.join(root, temp_dir)}\")\n",
    "                if os.path.isdir(os.path.join(directory, f)):\n",
    "                    shutil.rmtree(os.path.join(directory, f))\n",
    "                else:\n",
    "                    tile_log.warning(\n",
    "                        \"This should not have happened. \"+\n",
    "                        f\"{os.path.join(root, temp_dir)} is not a directory. \"+\n",
    "                        \"Skipping deletion.\"\n",
    "                    )\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Deletion of temporary directories complete.\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "tile_log.info(\"---------------------------------------------------------------\")\n",
    "tile_log.info(\"---                  PROCESSING END                         ---\")\n",
    "tile_log.info(\"---------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
