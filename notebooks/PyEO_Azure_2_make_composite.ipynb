{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c075ae52-fa2e-4490-acd5-99baaa8fa569",
   "metadata": {},
   "source": [
    "# PyEO Forest Alerts: How to create a median image composite from a time-series of Sentinel-2 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acb1d3-96a5-452a-8914-b176287f3ae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook was developed for pyeo on a Linux VM for Azure Lab.\n",
    "\n",
    "- This notebook will cover how to query the Sentinel-2 image archive on the Copernicus Data Space Ecosystem (CDSE), how to download selected images based on the query results, and how to create a (nearly) cloud-free image composite from several images.\n",
    "- The image composite will be used as a baseline against which the forest alerts will be assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bd835",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Image Composite Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af63284",
   "metadata": {},
   "source": [
    "- This section will take us stepwise through the imagery query, download and composite creation aspects of the `run_acd_national.py` script, which runs the full PyEO pipeline from the command line in a terminal.  \n",
    "- Jupyter notebooks provide a useful and engaging interface to understand the components of this script, so we will follow an extracted version throughout this notebook.\n",
    "\n",
    "This section comprises several stages:   \n",
    "1. Directory and V=variable setup.\n",
    "1. Querying for Sentinel-2 imagery that meets our search criteria.\n",
    "1. Downloading the Sentinel-2 imagery identified from the Query.\n",
    "1. If necessary, preprocess any L1C to L2A by applying atmospheric corrections. \n",
    "1. Cloud-masking the L2A imagery.\n",
    "1. Creation of a composite baseline reference from the time series that has been downloaded and processed. \n",
    "1. Query and Download of a set of Change Detection Images\n",
    "1. Classification of Baseline and Change Detection Images\n",
    "1. Creation of Forest Alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea452e7-c5a0-4d5f-9cda-82333f2b1545",
   "metadata": {},
   "source": [
    "# Setup: Requirements to use this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f950c",
   "metadata": {},
   "source": [
    "Navigate to the pyeo installation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8790ae9-e63c-46cd-b520-0819bd97a5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cmsstudent/pyeo\n"
     ]
    }
   ],
   "source": [
    "cd ~/pyeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498fd70",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "423f8dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries successfully imported\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import sys\n",
    "\n",
    "from pyeo import (classification, filesystem_utilities,\n",
    "                    queries_and_downloads, raster_manipulation)\n",
    "\n",
    "from pyeo.acd_national import (acd_initialisation,\n",
    "                                 acd_config_to_log,\n",
    "                                 acd_roi_tile_intersection)\n",
    "import configparser\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "print(\"Libraries successfully imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91268ca5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declare Processing Parameters with In-Notebook Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45b00b-0602-45ce-b783-2644c377cc20",
   "metadata": {},
   "source": [
    "- When running the `pyeo` pipeline we use an initialisation file (.ini) to provide the required parameters.  \n",
    "- For Azure Labs, we will use `pyeo_linux_azure.ini`  \n",
    "- Below the parameters are explained, but we will read these in via the config parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2633ca",
   "metadata": {},
   "source": [
    "- Now, let's read in the `.ini` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed25ff-9f70-4b31-853c-395c0c3b73a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declare the path to the initialisation file\n",
    "- The ini file contains a whole range of parameters that control how pyeo is run.\n",
    "- It is worth opening it in a text editor to see which parameters can be changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ee703a3-ca73-47ba-b7df-34ce92ed0fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cmsstudent/pyeo'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d943d13-0f65-4697-b9f9-0de863748885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_path = \"pyeo_linux_azure.ini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0e050-60ea-44aa-adbb-984ed605e4a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Edit the `pyeo_linux_azure.ini` file\n",
    "You can either:  \n",
    "- Check that `pyeo_dir` and `tile_dir` in `pyeo_linux_azure.ini` are correct.\n",
    "    <br>\n",
    "- Or, amend the `.ini` file to match your file paths if you cloned `pyeo` into a different directory:\n",
    "    - Right-Click and 'Open' `pyeo_linux_azure.ini` in the file browser on the left to be able to edit it\n",
    "    - Change pyeo_dir to point to the pyeo code in your installation directory\n",
    "    - Change tile_dir to point to your directory, where you want to save the created and downloaded data files\n",
    "    - Save the edited initialisation file - by pressing ```Ctrl+S```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c21844-9c03-4e28-8316-4f57fca827e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Edit the `credentials.ini` file:\n",
    "- Ensure the credentials path in the ``pyeo_linux_azure.ini` corresponds to your credentials file. The file contains your login details to the Copernicus Data Space Ecosystem.\n",
    "- The default path from within pyeo is to `.\\credentials\\credentials.ini`\n",
    "- To use this default option open the file `credentials_dummy.ini` in the editor (Right-Click then 'Open')\n",
    "- Edit the file to add your personal credentials for the dataspace API - following the convention of this file.\n",
    "- Save the file as `credentials.ini` into the credentials folder (using File -> Save File As)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c80083a-43fa-4632-920c-2bfdfd11b600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:30,425: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:30,426: INFO: ---                 PROCESSING START                        ---\n",
      "2024-09-25 14:15:30,427: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:30,428: INFO: conda environment path found: /home/cmsstudent/miniconda3//envs/pyeo_env\n",
      "2024-09-25 14:15:30,428: INFO: True\n",
      "2024-09-25 14:15:30,429: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:30,430: INFO: ---                  INTEGRATED PROCESSING START            ---\n",
      "2024-09-25 14:15:30,430: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:30,431: INFO: Reading in parameters defined in: pyeo_linux_azure.ini\n",
      "2024-09-25 14:15:30,432: INFO: ---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config_dict, acd_log = acd_initialisation(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7312a4a-5c13-4210-8493-bbfa38ea17ae",
   "metadata": {},
   "source": [
    "## Print the configuration parameters\n",
    "- We print the configuration parameter to create a record of what pyeo has been configured to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cd5ccfe-a8d9-4097-9218-336c298ed1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:31,150: INFO:   run_mode :  watch_period_seconds\n",
      "2024-09-25 14:15:31,152: INFO:   forest_sentinel :  model\n",
      "2024-09-25 14:15:31,153: INFO:   environment :  sen2cor_path\n",
      "2024-09-25 14:15:31,153: INFO:   raster_processing_parameters :  change_to_classes\n",
      "2024-09-25 14:15:31,154: INFO:   vector_processing_parameters :  minimum_area_to_report_m2\n",
      "2024-09-25 14:15:31,155: INFO:   alerts_sending_options :  whatsapp_list_file\n",
      "2024-09-25 14:15:31,155: INFO:   qsub_processor_options :  nodes=1:ppn=16,vmem=64Gb\n",
      "2024-09-25 14:15:31,156: WARNING:    --do_parallel is depracated\n",
      "2024-09-25 14:15:31,157: INFO:   wall_time_hours :  3\n",
      "2024-09-25 14:15:31,157: INFO:   watch_time_hours :  3\n",
      "2024-09-25 14:15:31,158: INFO:   watch_period_seconds :  60\n",
      "2024-09-25 14:15:31,159: INFO:   --do_tile_intersection enables Sentinel-2 tile intersection with region of interest (ROI).\n",
      "2024-09-25 14:15:31,159: WARNING:    --do_raster is depracated\n",
      "2024-09-25 14:15:31,160: WARNING:    --do_dev is depracated\n",
      "2024-09-25 14:15:31,161: INFO:   do_all :  False\n",
      "2024-09-25 14:15:31,161: INFO:   --do_classify applies the random forest model and creates classification layers\n",
      "2024-09-25 14:15:31,162: INFO:   --do_change produces change detection layers and report images\n",
      "2024-09-25 14:15:31,163: INFO:     --download_source = dataspace\n",
      "2024-09-25 14:15:31,163: INFO:       change start date : 20240201\n",
      "2024-09-25 14:15:31,164: INFO:       change end date   : TODAY\n",
      "2024-09-25 14:15:31,165: INFO:   --download of change detection images enabled\n",
      "2024-09-25 14:15:31,165: WARNING:    --do_update is depracated\n",
      "2024-09-25 14:15:31,166: INFO:   --quicklooks saves image quicklooks for visual quality checking\n",
      "2024-09-25 14:15:31,167: INFO:   do_delete :  False\n",
      "2024-09-25 14:15:31,168: INFO:   --do_zip archives downloaded and intermediate image products    to reduce disk space usage.\n",
      "2024-09-25 14:15:31,168: INFO:   --build_composite makes a baseline image composite\n",
      "2024-09-25 14:15:31,169: INFO:     --download_source = dataspace\n",
      "2024-09-25 14:15:31,170: INFO:       composite start date :  20220101\n",
      "2024-09-25 14:15:31,170: INFO:       composite end date   : 20221231\n",
      "2024-09-25 14:15:31,171: INFO:   build_prob_image :  False\n",
      "2024-09-25 14:15:31,172: INFO:   do_skip_existing :  True\n",
      "2024-09-25 14:15:31,172: INFO:   aoi_name :  Kenya\n",
      "2024-09-25 14:15:31,173: INFO:   start_date :  20240201\n",
      "2024-09-25 14:15:31,174: INFO:   end_date :  TODAY\n",
      "2024-09-25 14:15:31,174: INFO:   composite_start :  20220101\n",
      "2024-09-25 14:15:31,175: INFO:   composite_end :  20221231\n",
      "2024-09-25 14:15:31,176: INFO:   EPSG code for output map projection: 21097\n",
      "2024-09-25 14:15:31,177: INFO:   cloud_cover :  25\n",
      "2024-09-25 14:15:31,177: INFO:   cloud_certainty_threshold :  0\n",
      "2024-09-25 14:15:31,178: INFO: Model used: ./models/model_36MYE_Unoptimised_20230505_no_haze.pkl\n",
      "2024-09-25 14:15:31,179: INFO: dataspace selected as download source for the Copernicus Data Space Ecosystem.\n",
      "2024-09-25 14:15:31,179: INFO:     Faulty Granule Threshold: 200\n",
      "2024-09-25 14:15:31,180: INFO:   download_source :  dataspace\n",
      "2024-09-25 14:15:31,180: INFO:   List of image bands: ['B02', 'B03', 'B04', 'B08']\n",
      "2024-09-25 14:15:31,181: INFO:   resolution_string :  \"10m\"\n",
      "2024-09-25 14:15:31,182: INFO:   output_resolution :  10\n",
      "2024-09-25 14:15:31,183: INFO:   buffer_size_cloud_masking :  20\n",
      "2024-09-25 14:15:31,184: INFO:   buffer_size_cloud_masking_composite :  10\n",
      "2024-09-25 14:15:31,185: INFO:   download_limit :  3\n",
      "2024-09-25 14:15:31,186: INFO:   faulty_granule_threshold :  200\n",
      "2024-09-25 14:15:31,187: INFO:   sieve :  0\n",
      "2024-09-25 14:15:31,187: INFO:   chunks :  8\n",
      "2024-09-25 14:15:31,188: INFO:   List of class labels:\n",
      "2024-09-25 14:15:31,189: INFO:     1 : primary forest\n",
      "2024-09-25 14:15:31,190: INFO:     2 : plantation forest\n",
      "2024-09-25 14:15:31,191: INFO:     3 : bare soil\n",
      "2024-09-25 14:15:31,191: INFO:     4 : crops\n",
      "2024-09-25 14:15:31,192: INFO:     5 : grassland\n",
      "2024-09-25 14:15:31,193: INFO:     6 : open water\n",
      "2024-09-25 14:15:31,194: INFO:     7 : burn scar\n",
      "2024-09-25 14:15:31,195: INFO:     8 : cloud\n",
      "2024-09-25 14:15:31,196: INFO:     9 : cloud shadow\n",
      "2024-09-25 14:15:31,197: INFO:     10 : haze\n",
      "2024-09-25 14:15:31,198: INFO:     11 : sparse woodland\n",
      "2024-09-25 14:15:31,198: INFO:     12 : dense woodland\n",
      "2024-09-25 14:15:31,199: INFO:     13 : artificial\n",
      "2024-09-25 14:15:31,200: INFO: Detecting changes from any of the classes: [1, 2]\n",
      "2024-09-25 14:15:31,201: INFO:                     to any of the classes: [3]\n",
      "2024-09-25 14:15:31,201: INFO:   from_classes :  [1, 2]\n",
      "2024-09-25 14:15:31,202: INFO:   to_classes :  [3]\n",
      "2024-09-25 14:15:31,203: INFO:     Environment Manager to use is : conda\n",
      "2024-09-25 14:15:31,204: INFO: The Conda Environment specified in .ini file is :  pyeo_env\n",
      "2024-09-25 14:15:31,204: INFO:   conda_directory :  /home/cmsstudent/miniconda3/\n",
      "2024-09-25 14:15:31,205: INFO:   conda_env_name :  pyeo_env\n",
      "2024-09-25 14:15:31,206: INFO: Pyeo Working Directory is   : /home/cmsstudent/pyeo\n",
      "2024-09-25 14:15:31,207: INFO:   Integrated Directory           : ./integrated\n",
      "2024-09-25 14:15:31,207: INFO:   ROI Directory for image search : ./roi\n",
      "2024-09-25 14:15:31,208: INFO:   Geometry Directory for admin shapefile : ./geometry\n",
      "2024-09-25 14:15:31,209: INFO:   Path to the Admin Boundaries for Vectorisation : ./geometry/gadm41_KEN_1.json\n",
      "2024-09-25 14:15:31,210: INFO: Main Tile Directory for tile subdirs : /home/cmsstudent/Desktop/pyeo_data\n",
      "2024-09-25 14:15:31,210: INFO:   integrated_dir :  ./integrated\n",
      "2024-09-25 14:15:31,211: INFO:   roi_dir :  ./roi\n",
      "2024-09-25 14:15:31,212: INFO:   roi_filename :  kfs_roi_subset_c.shp\n",
      "2024-09-25 14:15:31,212: INFO:   geometry_dir :  ./geometry\n",
      "2024-09-25 14:15:31,213: INFO:   s2_tiles_filename :  kenya_s2_tiles.shp\n",
      "2024-09-25 14:15:31,214: INFO:   log_dir :  /home/cmsstudent/Desktop/pyeo_data/log\n",
      "2024-09-25 14:15:31,215: INFO:   log_filename :  my_log.log\n",
      "2024-09-25 14:15:31,216: INFO: Path to Sen2Cor is   : /home/cmsstudent/Sen2Cor-02.10.01-Linux64/bin/L2A_Process\n",
      "2024-09-25 14:15:31,217: INFO:   level_1_filename :  gadm41_KEN_1.json\n",
      "2024-09-25 14:15:31,218: INFO:   level_2_filename :  gadm41_KEN_2.json\n",
      "2024-09-25 14:15:31,218: INFO:   level_3_filename :  gadm41_KEN_3.json\n",
      "2024-09-25 14:15:31,220: INFO:   level_1_boundaries_path :  ./geometry/gadm41_KEN_1.json\n",
      "2024-09-25 14:15:31,220: INFO:   --do_delete_existing_vector, when vectorising the change report rasters,\n",
      "2024-09-25 14:15:31,221: INFO:     existing vectors files will be deleted and new vector files created.\n",
      "2024-09-25 14:15:31,222: INFO:   --do_vectorise produces vector files from raster report images\n",
      "2024-09-25 14:15:31,223: INFO:   --do_integrate merges vectorised reports together\n",
      "2024-09-25 14:15:31,224: INFO:   do_filter :  False\n",
      "2024-09-25 14:15:31,225: INFO:   --admin_areas_of_interest\n",
      "2024-09-25 14:15:31,226: INFO:         Admin boundaries to filter the national geodataframe:\n",
      "2024-09-25 14:15:31,226: INFO:   --minimum_area_to_report_m2\n",
      "2024-09-25 14:15:31,227: INFO:     Only Change Detections > 120 square metres will be reported\n",
      "2024-09-25 14:15:31,228: INFO:   minimum_area_to_report_m2 :  120\n",
      "2024-09-25 14:15:31,229: INFO:   do_distribution :  False\n",
      "2024-09-25 14:15:31,230: INFO:   email_alerts :  True\n",
      "2024-09-25 14:15:31,230: INFO:   email_list_file :  /home/cmsstudent/pyeo/subscribers.txt\n",
      "2024-09-25 14:15:31,231: INFO:   whatsapp_alerts :  False\n",
      "2024-09-25 14:15:31,232: INFO:   whatsapp_list_file :  /home/cmsstudent/pyeo/whatsapp_list.txt\n",
      "2024-09-25 14:15:31,233: INFO:   credentials_path :  /home/cmsstudent/pyeo/credentials/credentials.ini\n",
      "2024-09-25 14:15:31,233: INFO: -----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acd_config_to_log(config_dict, acd_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8668a8-6e76-47c3-b5d4-f58d69480016",
   "metadata": {},
   "source": [
    "## Identify the required Sentinel-2 tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800e86c-c409-48e3-a401-73bc7f75ca49",
   "metadata": {},
   "source": [
    "- PyEO operates by looking at a shapefile to determine the Region of Interest (ROI)\n",
    "- This directory path and filename of this shapefile needs to be specified in these two lines in the .ini file:\n",
    "    - `roi_dir = roi`\n",
    "    - `roi_filename = kfs_roi_subset_c.shp`\n",
    "- Then in the cell below, PyEO identifies what Sentinel-2 tiles intersect with the Region Of Interest (ROI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "399b4729-a380-4293-b9d2-1196f0ffe93a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:33,260: INFO: The provided ROI intersects with 2 Sentinel-2 tiles:\n",
      "2024-09-25 14:15:33,261: INFO:   1 : 36NXG\n",
      "2024-09-25 14:15:33,261: INFO:   2 : 36NYG\n"
     ]
    }
   ],
   "source": [
    "os.chdir(config_dict[\"pyeo_dir\"]) # ensures pyeo is looking in the correct directory\n",
    "tilelist_filepath = acd_roi_tile_intersection(config_dict, acd_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f83faf41-ed28-4f86-b15a-510df4da74e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./roi/tilelist.csv\n"
     ]
    }
   ],
   "source": [
    "print(tilelist_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40461f-d885-4c7f-8dbf-e16711ca6902",
   "metadata": {},
   "source": [
    "- **Right-Click on tile_list.csv in the JupyterLab explorer to the left and select 'open' to view it in a tab within JupyterLab.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f23947-f5cb-455d-b64e-22d7396009b1",
   "metadata": {},
   "source": [
    "## Running PyEO Per Tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161a3fd-652d-46cb-ba75-12df4a5df04d",
   "metadata": {},
   "source": [
    "- PyEO is designed to run per-tile.\n",
    "- It takes `tilelist.csv` created in the above cell and runs the pipeline for each tile in this `.csv` file.\n",
    "- This tutorial will run through the pipeline for the first tile in `tilelist.csv` : `36NXG`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb06594",
   "metadata": {},
   "source": [
    "## Create the Folder Structure PyEO Expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "245cb708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure build successfully finished\n"
     ]
    }
   ],
   "source": [
    "os.chdir(config_dict[\"pyeo_dir\"]) # ensures pyeo is looking in the correct directory\n",
    "\n",
    "tile_to_process = pd.read_csv(tilelist_filepath)[\"tile\"][0]\n",
    "individual_tile_directory_path = os.path.join(config_dict[\"tile_dir\"], tile_to_process)\n",
    "filesystem_utilities.create_folder_structure_for_tiles(individual_tile_directory_path)\n",
    "print(\"Folder structure build successfully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c5ebc-dec2-436a-b7ff-4b9c10ee7973",
   "metadata": {},
   "source": [
    "- You can now use the JupyterLab file explorer to view the new folder structure which should be in your installation directory and called `36NXG`\n",
    "- These folders provide the skeleton for the pipeline to store and process the tile's imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236f4703-f869-4a5e-812d-27ac679a15d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cmsstudent/Desktop/pyeo_data/36NXG'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_tile_directory_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776dc55b",
   "metadata": {},
   "source": [
    "## Create the Tile Log File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7c121",
   "metadata": {},
   "source": [
    "- `PyEO` uses a Log file as a convenient location to monitor pipeline progress\n",
    "- Additionally, the log file acts as a record of which parameters were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "616d0ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:42,880: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:42,882: INFO: ---                 PROCESSING START                        ---\n",
      "2024-09-25 14:15:42,882: INFO: ---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tile_log = filesystem_utilities.init_log_acd(\n",
    "    log_path=os.path.join(individual_tile_directory_path, \"log\", tile_to_process + \".log\"),\n",
    "    logger_name=f\"pyeo_{tile_to_process}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684df524-0e73-4148-9339-7898adb6a690",
   "metadata": {},
   "source": [
    "- You can now use the JupyterLab file explorer to find the log file which will be in a log folder beneath the main tile directory\n",
    "    - For example, the path to the Log file for `36NXG`, is : `20230626_pyeo_installation/36NXG/log/36NXG.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00117de-7c4e-4f34-9086-b713215ca01c",
   "metadata": {},
   "source": [
    "## Create the Processing Argument Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94b0d6-4948-4c06-abd3-e017cb93f0f0",
   "metadata": {},
   "source": [
    "- `PyEO` uses these parameters to make decisions throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8258ae90-a781-4338-aeb4-554c46ba6c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(config_dict[\"pyeo_dir\"]) # ensures pyeo is looking in the correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b9a4ca4-7858-4e8f-bfa3-41c04c4be795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:46,592: INFO: dataspace API is the download source\n",
      "2024-09-25 14:15:46,593: INFO: Faulty Granule Threshold is set to   : 200\n",
      "2024-09-25 14:15:46,594: INFO:     Files below this threshold will not be downloaded\n",
      "2024-09-25 14:15:46,596: INFO: Successfully read the processing arguments and credentials\n"
     ]
    }
   ],
   "source": [
    "start_date = config_dict[\"start_date\"]\n",
    "end_date = config_dict[\"end_date\"]\n",
    "composite_start_date = config_dict[\"composite_start\"]\n",
    "composite_end_date = config_dict[\"composite_end\"]\n",
    "cloud_cover = config_dict[\"cloud_cover\"]\n",
    "cloud_certainty_threshold = config_dict[\"cloud_certainty_threshold\"]\n",
    "model_path = config_dict[\"model_path\"]\n",
    "sen2cor_path = config_dict[\"sen2cor_path\"]\n",
    "epsg = config_dict[\"epsg\"]\n",
    "bands = config_dict[\"bands\"]\n",
    "resolution = config_dict[\"resolution_string\"]\n",
    "out_resolution = config_dict[\"output_resolution\"]\n",
    "buffer_size = config_dict[\"buffer_size_cloud_masking\"]\n",
    "buffer_size_composite = config_dict[\"buffer_size_cloud_masking_composite\"]\n",
    "max_image_number = config_dict[\"download_limit\"]\n",
    "faulty_granule_threshold = config_dict[\"faulty_granule_threshold\"]\n",
    "download_limit = config_dict[\"download_limit\"]\n",
    "\n",
    "skip_existing = config_dict[\"do_skip_existing\"]\n",
    "sieve = config_dict[\"sieve\"]\n",
    "from_classes = config_dict[\"from_classes\"]\n",
    "to_classes = config_dict[\"to_classes\"]\n",
    "\n",
    "download_source = config_dict[\"download_source\"]\n",
    "if download_source == \"scihub\":\n",
    "    tile_log.info(\"scihub API is the download source\")\n",
    "if download_source == \"dataspace\":\n",
    "    tile_log.info(\"dataspace API is the download source\")\n",
    "\n",
    "tile_log.info(f\"Faulty Granule Threshold is set to   : {config_dict['faulty_granule_threshold']}\")\n",
    "tile_log.info(\"    Files below this threshold will not be downloaded\")\n",
    "\n",
    "credentials_path = config_dict[\"credentials_path\"]\n",
    "if not os.path.exists(credentials_path):\n",
    "    tile_log.error(f\"The credentials path does not exist  :{credentials_path}\")\n",
    "    tile_log.error(f\"Current working directory :{os.getcwd()}\")\n",
    "    tile_log.error(\"Exiting raster pipeline\")\n",
    "    sys.exit(1)\n",
    "\n",
    "conf = configparser.ConfigParser(allow_no_value=True, interpolation=None)\n",
    "conf.read(credentials_path)\n",
    "credentials_dict = {}\n",
    "\n",
    "tile_log.info(\"Successfully read the processing arguments and credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52714e4",
   "metadata": {},
   "source": [
    "## Create the Necessary Variables to the Directory Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70878b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:49,712: INFO: Creating the directory paths\n",
      "2024-09-25 14:15:49,714: INFO: Successfully created the directory paths\n"
     ]
    }
   ],
   "source": [
    "tile_log.info(\"Creating the directory paths\")\n",
    "\n",
    "change_image_dir = os.path.join(individual_tile_directory_path, r\"images\")\n",
    "l1_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"L1C\")\n",
    "l2_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"L2A\")\n",
    "l2_masked_image_dir = os.path.join(individual_tile_directory_path, r\"images\", r\"cloud_masked\")\n",
    "categorised_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"classifications\")\n",
    "probability_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"probabilities\")\n",
    "sieved_image_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"sieved\")\n",
    "composite_dir = os.path.join(individual_tile_directory_path, r\"composite\")\n",
    "composite_l1_image_dir = os.path.join(individual_tile_directory_path, r\"composite\", r\"L1C\")\n",
    "composite_l2_image_dir = os.path.join(individual_tile_directory_path, r\"composite\", r\"L2A\")\n",
    "composite_l2_masked_image_dir = os.path.join(individual_tile_directory_path, r\"composite\", r\"cloud_masked\")\n",
    "quicklook_dir = os.path.join(individual_tile_directory_path, r\"output\", r\"quicklooks\")\n",
    "\n",
    "tile_log.info(\"Successfully created the directory paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9894b-c798-4f53-a9ea-21511b88c57f",
   "metadata": {},
   "source": [
    "## Read the Specified Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58aa1cde-169e-4824-b37a-45369e196a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:51,409: INFO: Running download handler for dataspace\n",
      "2024-09-25 14:15:51,411: INFO: Successfully configured the credentials for dataspace\n"
     ]
    }
   ],
   "source": [
    "if download_source == \"dataspace\":\n",
    "\n",
    "    tile_log.info(f'Running download handler for {download_source}')\n",
    "\n",
    "    credentials_dict[\"sent_2\"] = {}\n",
    "    credentials_dict[\"sent_2\"][\"user\"] = conf[\"dataspace\"][\"user\"]\n",
    "    credentials_dict[\"sent_2\"][\"pass\"] = conf[\"dataspace\"][\"pass\"]\n",
    "    sen_user = credentials_dict[\"sent_2\"][\"user\"]\n",
    "    sen_pass = credentials_dict[\"sent_2\"][\"pass\"]\n",
    "\n",
    "if download_source == \"scihub\":\n",
    "\n",
    "    tile_log.info(f'Running download handler for {download_source}')\n",
    "\n",
    "    credentials_dict[\"sent_2\"] = {}\n",
    "    credentials_dict[\"sent_2\"][\"user\"] = conf[\"sent_2\"][\"user\"]\n",
    "    credentials_dict[\"sent_2\"][\"pass\"] = conf[\"sent_2\"][\"pass\"]\n",
    "    sen_user = credentials_dict[\"sent_2\"][\"user\"]\n",
    "    sen_pass = credentials_dict[\"sent_2\"][\"pass\"]\n",
    "    \n",
    "tile_log.info(f\"Successfully configured the credentials for {download_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ad6c3",
   "metadata": {},
   "source": [
    "# Query Sentinel-2 Composite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0c510",
   "metadata": {},
   "source": [
    "First, a brief primer on the two Sentinel-2 data products we are concerned with:\n",
    "- L1C\n",
    "- L2A\n",
    "\n",
    "**L1C** corresponds to the 1st processing level for the imagery. <br>\n",
    "\n",
    "**L2A** corresponds to the 2nd processing level and this is the imagery we want to work with as these have been **atmospherically corrected**.\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "Now that we have the query, file handling and log parameters set up, we can start querying the Copernicus Hub for the Sentinel-2 imagery that we want.  \n",
    "\n",
    "The cell below starts the `build_composite` process. First, we query for the `L1C` products that match our criteria (date range, tile of interest, cloud cover).\n",
    "\n",
    "Since we have declared a download limit of 12 images, the software caps the number of images in our query. This is a useful tool if we have limited disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ec13a-eb92-45ac-ade9-3d303ca3e8c1",
   "metadata": {},
   "source": [
    "## Submit the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02a8c720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:15:58,025: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:58,027: INFO: Creating an initial cloud-free median composite from Sentinel-2 as a baseline map\n",
      "2024-09-25 14:15:58,027: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:15:58,028: INFO: Searching for images for initial composite.\n",
      "2024-09-25 14:15:58,029: INFO: Path to the S2 tile geometry information absolute path: /home/cmsstudent/pyeo/geometry/kenya_s2_tiles.shp\n",
      "2024-09-25 14:16:03,496: INFO: Removed 0 faulty scenes <0MB in size from the list\n",
      "2024-09-25 14:16:03,500: INFO:     36 L1C products\n",
      "2024-09-25 14:16:03,501: INFO:     27 L2A products\n",
      "2024-09-25 14:16:03,501: INFO: Capping the number of L1C products to 3\n",
      "2024-09-25 14:16:03,502: INFO: Relative orbits found covering tile: [135]\n",
      "2024-09-25 14:16:03,503: INFO: dataspace branch reaches here\n",
      "2024-09-25 14:16:03,505: INFO:     3 L1C products remain:\n",
      "2024-09-25 14:16:03,506: INFO:        S2A_MSIL1C_20220126T075211_N0400_R135_T36NXG_20220126T090631.SAFE\n",
      "2024-09-25 14:16:03,507: INFO:        S2A_MSIL1C_20220307T074801_N0400_R135_T36NXG_20220307T091249.SAFE\n",
      "2024-09-25 14:16:03,507: INFO:        S2B_MSIL1C_20220312T074719_N0400_R135_T36NXG_20220312T094827.SAFE\n",
      "2024-09-25 14:16:03,508: INFO: len of L1C products for dataspace is 3\n",
      "2024-09-25 14:16:03,509: INFO: Capping the number of L2A products to 3\n",
      "2024-09-25 14:16:03,509: INFO: Relative orbits found covering tile: [135]\n",
      "2024-09-25 14:16:03,511: INFO:     3 L2A products remain:\n",
      "2024-09-25 14:16:03,512: INFO:        S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:16:03,512: INFO:        S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:16:03,513: INFO:        S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE\n",
      "2024-09-25 14:16:03,514: INFO: len of L2A products for dataspace is 3\n",
      "2024-09-25 14:16:03,515: INFO: Filtering out L1C products that have the same 'beginposition' time stamp as an existing L2A product.\n",
      "2024-09-25 14:16:03,515: INFO: Before filtering, 3 L1C and 3 L2A\n",
      "2024-09-25 14:16:03,516: INFO: L1C : S2A_MSIL1C_20220126T075211_N0400_R135_T36NXG_20220126T090631.SAFE\n",
      "2024-09-25 14:16:03,517: INFO: L1C : S2A_MSIL1C_20220307T074801_N0400_R135_T36NXG_20220307T091249.SAFE\n",
      "2024-09-25 14:16:03,518: INFO: L1C : S2B_MSIL1C_20220312T074719_N0400_R135_T36NXG_20220312T094827.SAFE\n",
      "2024-09-25 14:16:03,519: INFO: L2A : S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:16:03,520: INFO: L2A : S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:16:03,520: INFO: L2A : S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE\n",
      "2024-09-25 14:16:03,532: INFO: After filtering, 1 L1C and 3 L2A\n",
      "2024-09-25 14:16:03,534: INFO: Unique L1C : S2B_MSIL1C_20220312T074719_N0400_R135_T36NXG_20220312T094827.SAFE\n",
      "2024-09-25 14:16:03,536: INFO: Unique L2A : S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:16:03,537: INFO: Unique L2A : S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:16:03,539: INFO: Unique L2A : S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE\n",
      "2024-09-25 14:16:03,540: INFO:  1 L1C products for the Composite\n",
      "2024-09-25 14:16:03,541: INFO:  3 L2A products for the Composite\n",
      "2024-09-25 14:16:03,541: INFO: Successfully queried the L1C and L2A products for the Composite\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\n",
    "        \"Creating an initial cloud-free median composite from Sentinel-2 as a baseline map\"\n",
    "    )\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Searching for images for initial composite.\")\n",
    "\n",
    "    if download_source == \"dataspace\":\n",
    "\n",
    "        try:\n",
    "            tiles_geom_path = os.path.join(config_dict[\"pyeo_dir\"], os.path.join(config_dict[\"geometry_dir\"], config_dict[\"s2_tiles_filename\"]))\n",
    "            tile_log.info(f\"Path to the S2 tile geometry information absolute path: {os.path.abspath(tiles_geom_path)}\")\n",
    "            tiles_geom = gpd.read_file(os.path.abspath(tiles_geom_path))\n",
    "        except FileNotFoundError:\n",
    "            tile_log.error(f\"Path to the S2 tile geometry does not exist, absolute path given: {os.path.abspath(tiles_geom_path)}\")\n",
    "\n",
    "        tile_geom = tiles_geom[tiles_geom[\"Name\"] == tile_to_process]\n",
    "        tile_geom = tile_geom.to_crs(epsg=4326)\n",
    "        geometry = tile_geom[\"geometry\"].iloc[0]\n",
    "        geometry = geometry.representative_point().wkt\n",
    "\n",
    "        # convert date string to YYYY-MM-DD\n",
    "        date_object = datetime.strptime(composite_start_date, \"%Y%m%d\")\n",
    "        dataspace_composite_start = date_object.strftime(\"%Y-%m-%d\")\n",
    "        date_object = datetime.strptime(composite_end_date, \"%Y%m%d\")\n",
    "        dataspace_composite_end = date_object.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        try:\n",
    "            dataspace_composite_products_all = queries_and_downloads.query_dataspace_by_polygon(\n",
    "                max_cloud_cover=cloud_cover,\n",
    "                start_date=dataspace_composite_start,\n",
    "                end_date=dataspace_composite_end,\n",
    "                area_of_interest=geometry,\n",
    "                max_records=100,\n",
    "                log=tile_log\n",
    "            )\n",
    "        except Exception as error:\n",
    "            tile_log.error(f\"query_dataspace_by_polygon received this error: {error}\")\n",
    "\n",
    "        titles = dataspace_composite_products_all[\"title\"].tolist()\n",
    "        sizes = list()\n",
    "        uuids = list()\n",
    "        for elem in dataspace_composite_products_all.itertuples(index=False):\n",
    "            sizes.append(elem[-2][\"download\"][\"size\"])\n",
    "            uuids.append(elem[-2][\"download\"][\"url\"].split(\"/\")[-1])\n",
    "\n",
    "        relative_orbit_numbers = dataspace_composite_products_all[\"relativeOrbitNumber\"].tolist()\n",
    "        processing_levels = dataspace_composite_products_all[\"processingLevel\"].tolist()\n",
    "        transformed_levels = ['Level-1C' if level == 'S2MSI1C' else 'Level-2A' for level in processing_levels]\n",
    "        cloud_covers = dataspace_composite_products_all[\"cloudCover\"].tolist()\n",
    "        begin_positions = dataspace_composite_products_all[\"startDate\"].tolist()\n",
    "        statuses = dataspace_composite_products_all[\"status\"].tolist()\n",
    "\n",
    "        scihub_compatible_df = pd.DataFrame({\"title\": titles,\n",
    "                                            \"size\": sizes,\n",
    "                                            \"beginposition\": begin_positions,\n",
    "                                            \"relativeorbitnumber\": relative_orbit_numbers,\n",
    "                                            \"cloudcoverpercentage\": cloud_covers,\n",
    "                                            \"processinglevel\": transformed_levels,\n",
    "                                            \"uuid\": uuids,\n",
    "                                            \"status\": statuses})\n",
    "\n",
    "        # check granule sizes on the server\n",
    "        scihub_compatible_df[\"size\"] = scihub_compatible_df[\"size\"].apply(lambda x: round(float(x) * 1e-6, 2))\n",
    "        # reassign to match the scihub variable\n",
    "        df_all = scihub_compatible_df\n",
    "\n",
    "\n",
    "    if download_source == \"scihub\":\n",
    "\n",
    "        try:\n",
    "            composite_products_all = queries_and_downloads.check_for_s2_data_by_date(\n",
    "                config_dict[\"tile_dir\"],\n",
    "                composite_start_date,\n",
    "                composite_end_date,\n",
    "                conf=credentials_dict,\n",
    "                cloud_cover=cloud_cover,\n",
    "                tile_id=tile_to_process,\n",
    "                producttype=None,\n",
    "            )\n",
    "\n",
    "        except Exception as error:\n",
    "            tile_log.error(\n",
    "                f\"check_for_s2_data_by_date failed, got this error :  {error}\"\n",
    "            )\n",
    "\n",
    "        tile_log.info(\n",
    "            \"--> Found {} L1C and L2A products for the composite:\".format(\n",
    "                len(composite_products_all)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_all = pd.DataFrame.from_dict(composite_products_all, orient=\"index\")\n",
    "\n",
    "        # check granule sizes on the server\n",
    "        df_all[\"size\"] = (\n",
    "            df_all[\"size\"]\n",
    "            .str.split(\" \")\n",
    "            .apply(lambda x: float(x[0]) * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]])\n",
    "        )\n",
    "\n",
    "    if download_source == \"scihub\":\n",
    "        min_granule_size = faulty_granule_threshold\n",
    "    else:\n",
    "        min_granule_size = 0  # Required for dataspace API which doesn't report size correctly (often reported as zero)\n",
    "\n",
    "    df = df_all.query(\"size >= \" + str(min_granule_size))\n",
    "\n",
    "    tile_log.info(\n",
    "        \"Removed {} faulty scenes <{}MB in size from the list\".format(\n",
    "            len(df_all) - len(df), min_granule_size\n",
    "        )\n",
    "    )\n",
    "    # find < threshold sizes, report to log\n",
    "    df_faulty = df_all.query(\"size < \" + str(min_granule_size))\n",
    "    for r in range(len(df_faulty)):\n",
    "        tile_log.info(\n",
    "            \"   {} MB: {}\".format(\n",
    "                df_faulty.iloc[r, :][\"size\"], df_faulty.iloc[r, :][\"title\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    l1c_products = df[df.processinglevel == \"Level-1C\"]\n",
    "    l2a_products = df[df.processinglevel == \"Level-2A\"]\n",
    "    tile_log.info(\"    {} L1C products\".format(l1c_products.shape[0]))\n",
    "    tile_log.info(\"    {} L2A products\".format(l2a_products.shape[0]))\n",
    "\n",
    "\n",
    "    rel_orbits = np.unique(l1c_products[\"relativeorbitnumber\"])\n",
    "    if len(rel_orbits) > 0:\n",
    "        if l1c_products.shape[0] > max_image_number / len(rel_orbits):\n",
    "            tile_log.info(\n",
    "                \"Capping the number of L1C products to {}\".format(max_image_number)\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"Relative orbits found covering tile: {}\".format(rel_orbits)\n",
    "            )\n",
    "            tile_log.info(\"dataspace branch reaches here\")\n",
    "            uuids = []\n",
    "            for orb in rel_orbits:\n",
    "                uuids = uuids + list(\n",
    "                    l1c_products.loc[\n",
    "                        l1c_products[\"relativeorbitnumber\"] == orb\n",
    "                    ].sort_values(by=[\"cloudcoverpercentage\"], ascending=True)[\n",
    "                        \"uuid\"\n",
    "                    ][\n",
    "                        : int(max_image_number / len(rel_orbits))\n",
    "                    ]\n",
    "                )\n",
    "            # keeps least cloudy n (max image number)\n",
    "            l1c_products = l1c_products[l1c_products[\"uuid\"].isin(uuids)]\n",
    "            tile_log.info(\n",
    "                \"    {} L1C products remain:\".format(l1c_products.shape[0])\n",
    "            )\n",
    "            for product in l1c_products[\"title\"]:\n",
    "                tile_log.info(\"       {}\".format(product))\n",
    "            tile_log.info(f\"len of L1C products for dataspace is {len(l1c_products['title'])}\")\n",
    "\n",
    "    rel_orbits = np.unique(l2a_products[\"relativeorbitnumber\"])\n",
    "    if len(rel_orbits) > 0:\n",
    "        if l2a_products.shape[0] > max_image_number / len(rel_orbits):\n",
    "            tile_log.info(\n",
    "                \"Capping the number of L2A products to {}\".format(max_image_number)\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"Relative orbits found covering tile: {}\".format(rel_orbits)\n",
    "            )\n",
    "            uuids = []\n",
    "            for orb in rel_orbits:\n",
    "                uuids = uuids + list(\n",
    "                    l2a_products.loc[\n",
    "                        l2a_products[\"relativeorbitnumber\"] == orb\n",
    "                    ].sort_values(by=[\"cloudcoverpercentage\"], ascending=True)[\n",
    "                        \"uuid\"\n",
    "                    ][\n",
    "                        : int(max_image_number / len(rel_orbits))\n",
    "                    ]\n",
    "                )\n",
    "            l2a_products = l2a_products[l2a_products[\"uuid\"].isin(uuids)]\n",
    "            tile_log.info(\n",
    "                \"    {} L2A products remain:\".format(l2a_products.shape[0])\n",
    "            )\n",
    "            for product in l2a_products[\"title\"]:\n",
    "                tile_log.info(\"       {}\".format(product))\n",
    "            tile_log.info(f\"len of L2A products for dataspace is {len(l2a_products['title'])}\")\n",
    "\n",
    "    if l1c_products.shape[0] > 0 and l2a_products.shape[0] > 0:\n",
    "        tile_log.info(\n",
    "            \"Filtering out L1C products that have the same 'beginposition' time stamp as an existing L2A product.\"\n",
    "        )\n",
    "        if download_source == \"scihub\":\n",
    "            (l1c_products,l2a_products,) = queries_and_downloads.filter_unique_l1c_and_l2a_data(df,log=tile_log)\n",
    "\n",
    "        if download_source == \"dataspace\":\n",
    "            l1c_products = queries_and_downloads.filter_unique_dataspace_products(l1c_products=l1c_products, l2a_products=l2a_products, log=tile_log)\n",
    "\n",
    "    df = None\n",
    "    tile_log.info(f\" {len(l1c_products['title'])} L1C products for the Composite\")\n",
    "    tile_log.info(f\" {len(l2a_products['title'])} L2A products for the Composite\")\n",
    "    \n",
    "    tile_log.info(\"Successfully queried the L1C and L2A products for the Composite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcc87f",
   "metadata": {},
   "source": [
    "## Search for L2A Images Corresponding to L1C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c90415",
   "metadata": {},
   "source": [
    "- The cell below searches our download directory for any existing imagery. If we have downloaded any imagery already, `pyeo` will remove the matching image from our search query.  \n",
    "\n",
    "- Secondly, if we have opted to use `scihub` as our `download_source`, then `pyeo` searches the Copernicus archive for any corresponding `L2A` products. If it finds a matching L2A product, then it removes the `L1C` counterpart from the query. The `dataspace` option handles this on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98d740d4-f9f3-499b-aef7-e3f8bd4db8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:16:14,853: INFO:     1 L1C products remaining for download\n",
      "2024-09-25 14:16:14,854: INFO:     3 L2A products remaining for download\n",
      "2024-09-25 14:16:14,855: INFO: Cell successfully finished\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    # Search the local directories, composite/L2A and L1C, checking if scenes have already been downloaded and/or processed whilst checking their dir sizes\n",
    "    if download_source == \"scihub\":\n",
    "        if l1c_products.shape[0] > 0:\n",
    "            tile_log.info(\n",
    "                \"Checking for already downloaded and zipped L1C or L2A products and\"\n",
    "            )\n",
    "            tile_log.info(\"  availability of matching L2A products for download.\")\n",
    "            n = len(l1c_products)\n",
    "            drop = []\n",
    "            add = []\n",
    "            for r in range(n):\n",
    "                id = l1c_products.iloc[r, :][\"title\"]\n",
    "                search_term = (\n",
    "                    id.split(\"_\")[2]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[3]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[4]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[5]\n",
    "                )\n",
    "                tile_log.info(\n",
    "                    \"Searching locally for file names containing: {}.\".format(\n",
    "                        search_term\n",
    "                    )\n",
    "                )\n",
    "                file_list = (\n",
    "                    [\n",
    "                        os.path.join(composite_l1_image_dir, f)\n",
    "                        for f in os.listdir(composite_l1_image_dir)\n",
    "                    ]\n",
    "                    + [\n",
    "                        os.path.join(composite_l2_image_dir, f)\n",
    "                        for f in os.listdir(composite_l2_image_dir)\n",
    "                    ]\n",
    "                    + [\n",
    "                        os.path.join(composite_l2_masked_image_dir, f)\n",
    "                        for f in os.listdir(composite_l2_masked_image_dir)\n",
    "                    ]\n",
    "                )\n",
    "                for f in file_list:\n",
    "                    if search_term in f:\n",
    "                        tile_log.info(\"  Product already downloaded: {}\".format(f))\n",
    "                        drop.append(l1c_products.index[r])\n",
    "                search_term = (\n",
    "                    \"*\"\n",
    "                    + id.split(\"_\")[2]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[3]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[4]\n",
    "                    + \"_\"\n",
    "                    + id.split(\"_\")[5]\n",
    "                    + \"*\"\n",
    "                )\n",
    "\n",
    "\n",
    "                tile_log.info(\n",
    "                    \"Searching on the data hub for files containing: {}.\".format(\n",
    "                        search_term\n",
    "                    )\n",
    "                )\n",
    "                matching_l2a_products = queries_and_downloads._file_api_query(\n",
    "                    user=sen_user,\n",
    "                    passwd=sen_pass,\n",
    "                    start_date=composite_start_date,\n",
    "                    end_date=composite_end_date,\n",
    "                    filename=search_term,\n",
    "                    cloud=cloud_cover,\n",
    "                    producttype=\"S2MSI2A\",\n",
    "                )\n",
    "\n",
    "                matching_l2a_products_df = pd.DataFrame.from_dict(\n",
    "                    matching_l2a_products, orient=\"index\"\n",
    "                )\n",
    "                # 07/03/2023: Matt - Applied Ali's fix for converting product size to MB to compare against faulty_grandule_threshold\n",
    "                if (\n",
    "                    len(matching_l2a_products_df) == 1\n",
    "                    and [\n",
    "                        float(x[0]) * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]]\n",
    "                        for x in [matching_l2a_products_df[\"size\"][0].split(\" \")]\n",
    "                    ][0]\n",
    "                    > faulty_granule_threshold\n",
    "                ):\n",
    "                    tile_log.info(\"Replacing L1C {} with L2A product:\".format(id))\n",
    "                    tile_log.info(\n",
    "                        \"              {}\".format(\n",
    "                            matching_l2a_products_df.iloc[0, :][\"title\"]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    drop.append(l1c_products.index[r])\n",
    "                    add.append(matching_l2a_products_df.iloc[0, :])\n",
    "                if len(matching_l2a_products_df) == 0:\n",
    "                    pass\n",
    "                if len(matching_l2a_products_df) > 1:\n",
    "                    # check granule sizes on the server\n",
    "                    matching_l2a_products_df[\"size\"] = (\n",
    "                        matching_l2a_products_df[\"size\"]\n",
    "                        .str.split(\" \")\n",
    "                        .apply(\n",
    "                            lambda x: float(x[0])\n",
    "                            * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]]\n",
    "                        )\n",
    "                    )\n",
    "                    matching_l2a_products_df = matching_l2a_products_df.query(\n",
    "                        \"size >= \" + str(faulty_granule_threshold)\n",
    "                    )\n",
    "                    if (\n",
    "                        matching_l2a_products_df.iloc[0, :][\"size\"]\n",
    "                        .str.split(\" \")\n",
    "                        .apply(\n",
    "                            lambda x: float(x[0])\n",
    "                            * {\"GB\": 1e3, \"MB\": 1, \"KB\": 1e-3}[x[1]]\n",
    "                        )\n",
    "                        > faulty_granule_threshold\n",
    "                    ):\n",
    "                        tile_log.info(\"Replacing L1C {} with L2A product:\".format(id))\n",
    "                        tile_log.info(\n",
    "                            \"              {}\".format(\n",
    "                                matching_l2a_products_df.iloc[0, :][\"title\"]\n",
    "                            )\n",
    "                        )\n",
    "                        drop.append(l1c_products.index[r])\n",
    "                        add.append(matching_l2a_products_df.iloc[0, :])\n",
    "            if len(drop) > 0:\n",
    "                l1c_products = l1c_products.drop(index=drop)\n",
    "            if len(add) > 0:\n",
    "                # l2a_products = l2a_products.append(add)\n",
    "                add = pd.DataFrame(add)\n",
    "                l2a_products = pd.concat([l2a_products, add])\n",
    "\n",
    "            tile_log.info(\"\\n Successfully searched for the L2A counterparts for the L1C products for the Composite\")\n",
    "        \n",
    "    # here, dataspace and scihub derived l1c_products and l2a_products lists are the \"same\"\n",
    "    l2a_products = l2a_products.drop_duplicates(subset=\"title\")\n",
    "    tile_log.info(\n",
    "        \"    {} L1C products remaining for download\".format(\n",
    "            l1c_products.shape[0]\n",
    "        )\n",
    "    )\n",
    "    tile_log.info(\n",
    "        \"    {} L2A products remaining for download\".format(\n",
    "            l2a_products.shape[0]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    tile_log.info(\"Cell successfully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108c91a",
   "metadata": {},
   "source": [
    "# Download Sentinel-2 Composite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e777708",
   "metadata": {},
   "source": [
    "## Download and Process L1Cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef54e1d",
   "metadata": {},
   "source": [
    "- From the `log` output above in the previous section, we can see that `pyeo` has found a matching `L2A` image for each of the `L1Cs` in our search query. So now we have only L2As in our search query.  \n",
    "\n",
    "- If we did have `L1Cs` in our search query, then the cell below would download these L1Cs and apply `atmospheric_correction` using `Sen2Cor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0e2fa54-3ba0-4dd2-b1b2-7b5b7a50fccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:31:10,383: INFO: Path to Sen2Cor is   : /home/cmsstudent/Sen2Cor-02.10.01-Linux64/bin/L2A_Process\n",
      "2024-09-25 14:31:10,384: WARNING:   Sen2Cor path does not exist. Cannot convert L1C to L2A. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    tile_log.info(f\"Path to Sen2Cor is   : {config_dict['sen2cor_path']}\")\n",
    "    # check whether Sen2cor is installed\n",
    "    if os.path.isdir(config_dict['sen2cor_path']):\n",
    "        log.info(\"  Sen2Cor path found.\")\n",
    "        if l1c_products.shape[0] > 0:\n",
    "            tile_log.info(f\"Downloading Sentinel-2 L1C products from {download_source}:\")\n",
    "    \n",
    "            if download_source == \"scihub\":\n",
    "    \n",
    "                queries_and_downloads.download_s2_data_from_df(\n",
    "                    l1c_products,\n",
    "                    composite_l1_image_dir,\n",
    "                    composite_l2_image_dir,\n",
    "                    source=\"scihub\",\n",
    "                    user=sen_user,\n",
    "                    passwd=sen_pass,\n",
    "                    try_scihub_on_fail=True\n",
    "                )\n",
    "    \n",
    "            if download_source == \"dataspace\":\n",
    "    \n",
    "                queries_and_downloads.download_s2_data_from_dataspace(\n",
    "                    product_df=l1c_products,\n",
    "                    l1c_directory=composite_l1_image_dir,\n",
    "                    l2a_directory=composite_l2_image_dir,\n",
    "                    dataspace_username=sen_user,\n",
    "                    dataspace_password=sen_pass,\n",
    "                    log=tile_log\n",
    "                )\n",
    "            tile_log.info(\"Atmospheric correction with sen2cor.\")\n",
    "            raster_manipulation.atmospheric_correction(\n",
    "                composite_l1_image_dir,\n",
    "                composite_l2_image_dir,\n",
    "                sen2cor_path,\n",
    "                delete_unprocessed_image=False,\n",
    "                log=tile_log,\n",
    "            )\n",
    "        tile_log.info(\"Successfully downloaded the Sentinel-2 L1C products\")\n",
    "    else:\n",
    "        tile_log.warning(\"  Sen2Cor path does not exist. Cannot convert L1C to L2A. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d51568",
   "metadata": {},
   "source": [
    "## Download L2As"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54385c8f",
   "metadata": {},
   "source": [
    "In this subsection, we will download the L2As from our search query.  \n",
    "\n",
    "But first, let's take a look at what our search query result, `l2a_products` looks like by printing the first 3 rows with `.head(3)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9465c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    l2a_products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755487d",
   "metadata": {},
   "source": [
    "Let's highlight a few columns of interest:  \n",
    "\n",
    "In the cell output above, we can see the product `uuid` as the dataframe index (*the first column, it has no column name*). These are the unique identifiers used to distinguish the scenes from each other.  \n",
    "\n",
    "From the `title` column, we can see the titles of each product, the titles themselves show us important information, for example: the Satellite (*S2A or S2B*), the Sensor (*MSI*), the product type (*L2A*), the date the image was captured (*YYYYMMDD*) or the corresponding tile for the image (*TXXXXX*).\n",
    "\n",
    "We can also see if the product is online or in the Long-Term Archive (`LTA`), by looking at the column `ondemand`, where `false` indicates the product is in the LTA or `true` indicates the product is online and ready for download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee158dd",
   "metadata": {},
   "source": [
    "Now, let's download the `L2As` in our search query `l2a_products`, by asking `pyeo` to download these images from the Copernicus archive. If any incomplete downloads are present from a previous run (*remember, pyeo is an iterative download, classification and change detection process*), then `pyeo` will flag these files to the user through the log file.\n",
    "\n",
    "If the images are in the Long Term Archive (`LTA`), then `pyeo` will linearly activate and wait for the LTA image to become available, before downloading and moving onto the next L2A in the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25dce346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:31:21,149: INFO: Downloading Sentinel-2 L2A products.\n",
      "2024-09-25 14:31:21,151: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 14:31:21,152: INFO: Checking 1 of 3 : S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:31:21,153: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE does not exist.\n",
      "2024-09-25 14:31:21,154: INFO:     Downloading  : S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:31:21,774: INFO: response.status_code: 301\n",
      "2024-09-25 14:31:21,775: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(b64fb22c-b8c5-5f2a-a23b-5e4ba581512b)/$value\n",
      "2024-09-25 14:35:22,286: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 14:35:22,287: INFO: Checking 2 of 3 : S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:35:22,289: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE does not exist.\n",
      "2024-09-25 14:35:22,289: INFO:     Downloading  : S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:35:22,780: INFO: response.status_code: 301\n",
      "2024-09-25 14:35:22,781: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(1048c725-326a-583d-a40b-4964dbb76dfb)/$value\n",
      "2024-09-25 14:40:53,557: INFO: --------------------------------------------------------------------------------\n",
      "2024-09-25 14:40:53,558: INFO: Checking 3 of 3 : S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE\n",
      "2024-09-25 14:40:53,559: INFO: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE does not exist.\n",
      "2024-09-25 14:40:53,560: INFO:     Downloading  : S2A_MSIL2A_20220307T074801_N0400_R135_T36NXG_20220307T113320.SAFE\n",
      "2024-09-25 14:40:54,007: INFO: response.status_code: 301\n",
      "2024-09-25 14:40:54,009: INFO: download url = response.headers['Location']: https://catalogue.dataspace.copernicus.eu/odata/v1/Products(e5a7337d-2745-5c5c-aa0c-e56630cec20e)/$value\n",
      "2024-09-25 14:48:16,967: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:48:16,968: INFO: Image download for composite is complete.\n",
      "2024-09-25 14:48:16,968: INFO: ---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    if l2a_products.shape[0] > 0:\n",
    "        tile_log.info(\"Downloading Sentinel-2 L2A products.\")\n",
    "\n",
    "        if download_source == \"scihub\":\n",
    "\n",
    "            queries_and_downloads.download_s2_data(\n",
    "                l2a_products.to_dict(\"index\"),\n",
    "                composite_l1_image_dir,\n",
    "                composite_l2_image_dir,\n",
    "                source=\"scihub\",\n",
    "                user=sen_user,\n",
    "                passwd=sen_pass,\n",
    "                try_scihub_on_fail=True,\n",
    "            )\n",
    "        if download_source == \"dataspace\":\n",
    "\n",
    "            queries_and_downloads.download_s2_data_from_dataspace(\n",
    "                product_df=l2a_products,\n",
    "                l1c_directory=composite_l1_image_dir,\n",
    "                l2a_directory=composite_l2_image_dir,\n",
    "                dataspace_username=sen_user,\n",
    "                dataspace_password=sen_pass,\n",
    "                log=tile_log\n",
    "            )\n",
    "\n",
    "    # check for incomplete L2A downloads\n",
    "    incomplete_downloads, sizes = raster_manipulation.find_small_safe_dirs(\n",
    "        composite_l2_image_dir, threshold=faulty_granule_threshold * 1024 * 1024\n",
    "    )\n",
    "    if len(incomplete_downloads) > 0:\n",
    "        for index, safe_dir in enumerate(incomplete_downloads):\n",
    "            if sizes[\n",
    "                index\n",
    "            ] / 1024 / 1024 < faulty_granule_threshold and os.path.exists(safe_dir):\n",
    "                tile_log.warning(\"Found likely incomplete download of size {} MB: {}\".format(\n",
    "                        str(round(sizes[index] / 1024 / 1024)), safe_dir))\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Image download for composite is complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2e4e7",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c153a",
   "metadata": {},
   "source": [
    "The cell below performs some housekeeping if we have told `pyeo` to delete or zip imagery. This functionality is useful for ensuring disk space is kept to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "664b70df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:50:18,216: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:18,218: INFO: Zipping downloaded L1C images for composite after atmospheric correction\n",
      "2024-09-25 14:50:18,219: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:18,220: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:18,220: INFO: Zipping complete\n",
      "2024-09-25 14:50:18,221: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:18,222: INFO: Cell successfully finished\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    if config_dict[\"do_delete\"]:\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Deleting downloaded L1C images for composite, keeping only derived L2A products\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        directory = composite_l1_image_dir\n",
    "        tile_log.info(\"Deleting {}\".format(directory))\n",
    "        shutil.rmtree(directory)\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Deletion of L1C images complete. Keeping only L2A images.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "    else:\n",
    "        if config_dict[\"do_zip\"]:\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(\"Zipping downloaded L1C images for composite after atmospheric correction\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            filesystem_utilities.zip_contents(composite_l1_image_dir)\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(\"Zipping complete\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    tile_log.info(\"Cell successfully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20c04f",
   "metadata": {},
   "source": [
    "# Process the Downloaded Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363aa7c",
   "metadata": {},
   "source": [
    "Now that we have downloaded the L2A Imagery, we will process the imagery. Processing refers to:  \n",
    "\n",
    "1. Applying the `SCL Cloud Mask` to remove cloud, haze or cloud shadow pixels from the imagery.\n",
    "2. Applying a `Processing Baseline Correction Offset` to the imagery, if applicable.\n",
    "3. Create `Quicklooks` (*.png*) of the processed imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa852abf",
   "metadata": {},
   "source": [
    "## Apply SCL Cloud Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f596f",
   "metadata": {},
   "source": [
    "Optical data is affected by the presence of clouds over the land cover of interest. So, we use `apply_scl_cloud_mask` to remove cloudy pixels from the imagery, as we are not interested in clouds.\n",
    "\n",
    "The cell below peforms two things:\n",
    "\n",
    "- Checks whether any L2A SAFE files have been cloud masked from a previous run.\n",
    "\n",
    "- If any L2A SAFE files have not been cloud masked, then `apply_scl_cloud_mask` is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c32f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:50:26,746: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:26,747: INFO: Applying simple cloud, cloud shadow and haze mask based on SCL files and stacking the masked band raster files.\n",
      "2024-09-25 14:50:26,748: INFO: ---------------------------------------------------------------\n",
      "2024-09-25 14:50:26,751: INFO: 3 L2A raster files marked for SCL cloud masking.\n",
      "2024-09-25 14:50:26,751: INFO:   Applying SCL cloud mask to L2A raster file: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:50:26,752: INFO: TMP:  Granule ID  : S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313\n",
      "2024-09-25 14:50:26,752: INFO: TMP:  File pattern: S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG\n",
      "2024-09-25 14:50:26,762: INFO: Merging band rasters into a single file:\n",
      "2024-09-25 14:50:26,763: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE/GRANULE/L2A_T36NXG_A027045_20220511T080451/IMG_DATA/R10m/T36NXG_20220511T074609_B02_10m.jp2\n",
      "2024-09-25 14:50:26,764: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE/GRANULE/L2A_T36NXG_A027045_20220511T080451/IMG_DATA/R10m/T36NXG_20220511T074609_B03_10m.jp2\n",
      "2024-09-25 14:50:26,765: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE/GRANULE/L2A_T36NXG_A027045_20220511T080451/IMG_DATA/R10m/T36NXG_20220511T074609_B04_10m.jp2\n",
      "2024-09-25 14:50:26,766: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE/GRANULE/L2A_T36NXG_A027045_20220511T080451/IMG_DATA/R10m/T36NXG_20220511T074609_B08_10m.jp2\n",
      "2024-09-25 14:54:23,713: INFO: Creating scene classification mask for /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE\n",
      "2024-09-25 14:54:23,715: INFO:   containing SCL classes: [0, 1, 2, 3, 8, 9, 10, 11]\n",
      "2024-09-25 14:54:23,718: INFO:   Opening scene classification layer (SCL) file: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313.SAFE/GRANULE/L2A_T36NXG_A027045_20220511T080451/IMG_DATA/R20m/T36NXG_20220511T074609_SCL_20m.jp2\n",
      "2024-09-25 14:54:23,718: INFO: TMP:  SCL class values to be masked out: [0, 1, 2, 3, 8, 9, 10, 11]\n",
      "2024-09-25 14:54:25,440: INFO: TMP:  SCL class value histogram:\n",
      "2024-09-25 14:54:25,441: INFO: TMP:    0: 1673420 --> NO_DATA\n",
      "2024-09-25 14:54:25,441: INFO: TMP:    2: 8420 --> DARK_AREA_PIXELS\n",
      "2024-09-25 14:54:25,442: INFO: TMP:    3: 163514 --> CLOUD_SHADOWS\n",
      "2024-09-25 14:54:25,442: INFO: TMP:    4: 23444940 --> VEGETATION\n",
      "2024-09-25 14:54:25,443: INFO: TMP:    5: 3958093 --> NOT_VEGETATED\n",
      "2024-09-25 14:54:25,444: INFO: TMP:    6: 90936 --> WATER\n",
      "2024-09-25 14:54:25,444: INFO: TMP:    7: 173915 --> UNCLASSIFIED\n",
      "2024-09-25 14:54:25,445: INFO: TMP:    8: 289192 --> CLOUD_MEDIUM_PROBABILITY\n",
      "2024-09-25 14:54:25,446: INFO: TMP:    9: 337670 --> CLOUD_HIGH_PROBABILITY\n",
      "2024-09-25 14:54:26,596: INFO: TMP:  Mask value histogram:\n",
      "2024-09-25 14:54:26,597: INFO: TMP:    0: 2472216\n",
      "2024-09-25 14:54:26,598: INFO: TMP:    1: 27667884\n",
      "2024-09-25 14:56:10,811: INFO:   Reprojecting stacked and masked image to EPSG code 21097\n",
      "2024-09-25 14:56:10,812: INFO: TMP:  epsg: 21097, wkt: PROJCS[\"Arc 1960 / UTM zone 37N\",GEOGCS[\"Arc 1960\",DATUM[\"Arc_1960\",SPHEROID[\"Clarke 1880 (RGS)\",6378249.145,293.465,AUTHORITY[\"EPSG\",\"7012\"]],AUTHORITY[\"EPSG\",\"6210\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4210\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",39],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"21097\"]]\n",
      "2024-09-25 14:56:10,813: INFO: Reprojecting /home/cmsstudent/pyeo/tmp0c8abiia/S2B_MSIL2A_20220511T074609_N0400_R135_T36NXG_20220511T103313_stacked_masked.tif\n",
      "2024-09-25 14:56:40,193: INFO:   Applying SCL cloud mask to L2A raster file: /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE\n",
      "2024-09-25 14:56:40,194: INFO: TMP:  Granule ID  : S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035\n",
      "2024-09-25 14:56:40,195: INFO: TMP:  File pattern: S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG\n",
      "2024-09-25 14:56:41,858: INFO: Merging band rasters into a single file:\n",
      "2024-09-25 14:56:41,859: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE/GRANULE/L2A_T36NXG_A034452_20220126T075213/IMG_DATA/R10m/T36NXG_20220126T075211_B02_10m.jp2\n",
      "2024-09-25 14:56:41,860: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE/GRANULE/L2A_T36NXG_A034452_20220126T075213/IMG_DATA/R10m/T36NXG_20220126T075211_B03_10m.jp2\n",
      "2024-09-25 14:56:41,861: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE/GRANULE/L2A_T36NXG_A034452_20220126T075213/IMG_DATA/R10m/T36NXG_20220126T075211_B04_10m.jp2\n",
      "2024-09-25 14:56:41,861: INFO:   /home/cmsstudent/Desktop/pyeo_data/36NXG/composite/L2A/S2A_MSIL2A_20220126T075211_N0400_R135_T36NXG_20220126T111035.SAFE/GRANULE/L2A_T36NXG_A034452_20220126T075213/IMG_DATA/R10m/T36NXG_20220126T075211_B08_10m.jp2\n"
     ]
    }
   ],
   "source": [
    "# Check for pre-downloaded Imagery\n",
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Applying simple cloud, cloud shadow and haze mask based on SCL files and stacking the masked band raster files.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    directory = composite_l2_masked_image_dir\n",
    "    masked_file_paths = [\n",
    "        f\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(\".tif\") and os.path.isfile(os.path.join(directory, f))\n",
    "    ]\n",
    "\n",
    "    directory = composite_l2_image_dir\n",
    "    l2a_zip_file_paths = [f for f in os.listdir(directory) if f.endswith(\".zip\")]\n",
    "\n",
    "    if len(l2a_zip_file_paths) > 0:\n",
    "        for f in l2a_zip_file_paths:\n",
    "            # check whether the zipped file has already been cloud masked\n",
    "            zip_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "                os.path.basename(f)\n",
    "            ).strftime(\"%Y%m%dT%H%M%S\")\n",
    "            if any(zip_timestamp in f for f in masked_file_paths):\n",
    "                continue\n",
    "            else:\n",
    "                # extract it if not\n",
    "                filesystem_utilities.unzip_contents(\n",
    "                    os.path.join(composite_l2_image_dir, f),\n",
    "                    ifstartswith=\"S2\",\n",
    "                    ending=\".SAFE\",\n",
    "                )\n",
    "\n",
    "    directory = composite_l2_image_dir\n",
    "    l2a_safe_file_paths = [\n",
    "        f\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(\".SAFE\") and os.path.isdir(os.path.join(directory, f))\n",
    "    ]\n",
    "\n",
    "    files_for_cloud_masking = []\n",
    "    if len(l2a_safe_file_paths) > 0:\n",
    "        for f in l2a_safe_file_paths:\n",
    "            # check whether the L2A SAFE file has already been cloud masked\n",
    "            safe_timestamp = filesystem_utilities.get_image_acquisition_time(\n",
    "                os.path.basename(f)\n",
    "            ).strftime(\"%Y%m%dT%H%M%S\")\n",
    "            if any(safe_timestamp in f for f in masked_file_paths):\n",
    "                continue\n",
    "            else:\n",
    "                # add it to the list of files to do if it has not been cloud masked yet\n",
    "                files_for_cloud_masking = files_for_cloud_masking + [f]\n",
    "\n",
    "    # Apply the cloud masks to images\n",
    "    if len(files_for_cloud_masking) == 0:\n",
    "        tile_log.info(\"No L2A images found for cloud masking. They may already have been done.\")\n",
    "    else:\n",
    "        raster_manipulation.apply_scl_cloud_mask(\n",
    "            composite_l2_image_dir,\n",
    "            composite_l2_masked_image_dir,\n",
    "            scl_classes=[0, 1, 2, 3, 8, 9, 10, 11],\n",
    "            buffer_size=buffer_size_composite,\n",
    "            bands=bands,\n",
    "            out_resolution=out_resolution,\n",
    "            haze=None,\n",
    "            epsg=epsg,\n",
    "            skip_existing=skip_existing,\n",
    "            log=tile_log\n",
    "        )\n",
    "\n",
    "    tile_log.info(\"Successfully applied the Cloud Masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4819b1b",
   "metadata": {},
   "source": [
    "## Apply Processing Baseline Offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b54b2",
   "metadata": {},
   "source": [
    "Before Sentinel-2 imagery is provided to the user as L1C or L2A formats, the raw imagery (L0) are processed by the ESA Copernicus Ground Segment ([see here](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/processing-levels)). The algorithms used in the processing baseline, are indicated by the field `N0XXX` in the product title and the changes introduced by each processing baseline iteration are listed [here](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/processing-baseline).\n",
    "\n",
    "The advent of processing baseline `N0400` introduced an offset of `-1000` in the spectral reflectance values, the reasoning and suggested reading can be viewed [here](https://forum.step.esa.int/t/info-introduction-of-additional-radiometric-offset-in-pb04-00-products/35431). Therefore, to ensure that the spectral reflectance of imagery before and after `N0400` can be compared, we apply the offset correction of `+1000`.\n",
    "\n",
    "The cell below, applies such an offset correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9e3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Offsetting cloud masked L2A images for composite.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "\n",
    "    raster_manipulation.apply_processing_baseline_offset_correction_to_tiff_file_directory(\n",
    "        in_tif_directory = composite_l2_masked_image_dir,\n",
    "        out_tif_directory = composite_l2_masked_image_dir,\n",
    "        bands_to_offset_labels = (\"B02\", \"B03\", \"B04\", \"B08\"),\n",
    "        bands_to_offset_index = [0, 1, 2, 3],\n",
    "        BOA_ADD_OFFSET = -1000,\n",
    "        backup_flag = False,\n",
    "        log=tile_log\n",
    "    )\n",
    "\n",
    "    tile_log.info(\"---------------------------------------------------------------\")\n",
    "    tile_log.info(\"Offsetting of cloud masked L2A images for composite complete.\")\n",
    "    tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63cf8e",
   "metadata": {},
   "source": [
    "## Create Quicklooks of Cloud-Masked Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febea00",
   "metadata": {},
   "source": [
    "- We can also create quicklooks of the Cloud-Masked images. These are especially useful for viewing the images quickly using a standard photo viewer, and for use in presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a54841d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 16:56:04,422: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 16:56:04,424: INFO: Producing quicklooks.\n",
      "2024-08-05 16:56:04,426: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 16:56:04,429: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220106T075321_N0301_R135_T36NXG_20220106T112039.png\n",
      "2024-08-05 16:56:14,801: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220126T075211_NA400_R135_T36NXG_20220126T111035.png\n",
      "2024-08-05 16:56:28,559: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220307T074801_NA400_R135_T36NXG_20220307T113320.png\n",
      "2024-08-05 16:56:42,566: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220406T074611_NA400_R135_T36NXG_20220406T102936.png\n",
      "2024-08-05 16:56:55,636: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220516T074621_NA400_R135_T36NXG_20220516T124012.png\n",
      "2024-08-05 16:57:08,674: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20220615T074621_NA400_R135_T36NXG_20220615T113017.png\n",
      "2024-08-05 16:57:22,230: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20221013T074851_NA400_R135_T36NXG_20221013T112156.png\n",
      "2024-08-05 16:57:35,586: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2A_MSIL2A_20221202T075301_NA400_R135_T36NXG_20221202T111602.png\n",
      "2024-08-05 16:57:48,504: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220111T075209_N0301_R135_T36NXG_20220111T102011.png\n",
      "2024-08-05 16:57:58,168: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220302T074829_NA400_R135_T36NXG_20220302T105800.png\n",
      "2024-08-05 16:58:10,645: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220312T074719_NA400_R135_T36NXG_20220312T103427.png\n",
      "2024-08-05 16:58:23,821: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220401T074609_NA400_R135_T36NXG_20220401T105750.png\n",
      "2024-08-05 16:58:36,529: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220511T074609_NA400_R135_T36NXG_20220511T103313.png\n",
      "2024-08-05 16:58:49,638: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220521T074609_NA400_R135_T36NXG_20220521T102923.png\n",
      "2024-08-05 16:59:02,205: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\S2B_MSIL2A_20220918T074619_NA400_R135_T36NXG_20220918T101459.png\n",
      "2024-08-05 16:59:15,587: INFO: Quicklooks complete.\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    if config_dict[\"do_quicklooks\"] or config_dict[\"do_all\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Producing quicklooks.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        dirs_for_quicklooks = [composite_l2_masked_image_dir]\n",
    "        for main_dir in dirs_for_quicklooks:\n",
    "            files = [\n",
    "                f.path\n",
    "                for f in os.scandir(main_dir)\n",
    "                if f.is_file() and os.path.basename(f).endswith(\".tif\")\n",
    "            ]\n",
    "            # files = [ f.path for f in os.scandir(main_dir) if f.is_file() and os.path.basename(f).endswith(\".tif\") and \"class\" in os.path.basename(f) ] # do classification images only\n",
    "            if len(files) == 0:\n",
    "                tile_log.warning(\"No images found in {}.\".format(main_dir))\n",
    "            else:\n",
    "                for f in files:\n",
    "                    quicklook_path = os.path.join(\n",
    "                        quicklook_dir,\n",
    "                        os.path.basename(f).split(\".\")[0] + \".png\",\n",
    "                    )\n",
    "                    tile_log.info(\"Creating quicklook: {}\".format(quicklook_path))\n",
    "                    raster_manipulation.create_quicklook(\n",
    "                        in_raster_path = f,\n",
    "                        out_raster_path = quicklook_path,\n",
    "                        width = 512,\n",
    "                        height = 512,\n",
    "                        format = \"PNG\",\n",
    "                        bands = [3, 2, 1],\n",
    "                        nodata = 0,\n",
    "                        scale_factors=[[0, 2000, 0, 255]],\n",
    "                        log=tile_log\n",
    "                    )\n",
    "        tile_log.info(\"Quicklooks complete.\")\n",
    "    else:\n",
    "        tile_log.info(\"Quicklook option disabled in ini file.\")\n",
    "\n",
    "\n",
    "    if config_dict[\"do_zip\"]:\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"Zipping downloaded L2A images for composite after cloud masking and band stacking\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        filesystem_utilities.zip_contents(composite_l2_image_dir)\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\"Zipping complete\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23034122",
   "metadata": {},
   "source": [
    "# Create Composite from the Baseline Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428cac1",
   "metadata": {},
   "source": [
    "Now we come to the last section of Tutorial Section 2. Previously, we have queried the Copernicus archive for Sentinel-2 images that matched our search criteria, we evaluated which L2A products were present in the archive to avoid unecessary processing from pyeo for conversion from L1C to L2A. We then downloaded the resulting imagery, applied a cloud mask and a baseline offset correction, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea530b9-8537-4e4d-89d3-e5c1034c203d",
   "metadata": {},
   "source": [
    "## Create the Image Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c969c686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:32:14,907: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 17:32:14,909: INFO: Building initial cloud-free median composite from directory Z:\\gy7709\\36NXG\\composite\\cloud_masked\n",
      "2024-08-05 17:32:14,911: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 17:32:14,918: INFO: Cleverly compositing all images in directory into a median composite: Z:\\gy7709\\36NXG\\composite\\cloud_masked\n",
      "2024-08-05 17:32:14,922: INFO: Image number 1 has time stamp 20220106T075321\n",
      "2024-08-05 17:32:14,923: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220106T075321_N0301_R135_T36NXG_20220106T112039.tif\n",
      "2024-08-05 17:32:14,924: INFO: Image number 2 has time stamp 20220111T075209\n",
      "2024-08-05 17:32:14,925: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220111T075209_N0301_R135_T36NXG_20220111T102011.tif\n",
      "2024-08-05 17:32:14,925: INFO: Image number 3 has time stamp 20220126T075211\n",
      "2024-08-05 17:32:14,927: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220126T075211_NA400_R135_T36NXG_20220126T111035.tif\n",
      "2024-08-05 17:32:14,929: INFO: Image number 4 has time stamp 20220302T074829\n",
      "2024-08-05 17:32:14,930: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220302T074829_NA400_R135_T36NXG_20220302T105800.tif\n",
      "2024-08-05 17:32:14,931: INFO: Image number 5 has time stamp 20220307T074801\n",
      "2024-08-05 17:32:14,932: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220307T074801_NA400_R135_T36NXG_20220307T113320.tif\n",
      "2024-08-05 17:32:14,933: INFO: Image number 6 has time stamp 20220312T074719\n",
      "2024-08-05 17:32:14,934: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220312T074719_NA400_R135_T36NXG_20220312T103427.tif\n",
      "2024-08-05 17:32:14,935: INFO: Image number 7 has time stamp 20220401T074609\n",
      "2024-08-05 17:32:14,936: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220401T074609_NA400_R135_T36NXG_20220401T105750.tif\n",
      "2024-08-05 17:32:14,937: INFO: Image number 8 has time stamp 20220406T074611\n",
      "2024-08-05 17:32:14,937: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220406T074611_NA400_R135_T36NXG_20220406T102936.tif\n",
      "2024-08-05 17:32:14,940: INFO: Image number 9 has time stamp 20220511T074609\n",
      "2024-08-05 17:32:14,941: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220511T074609_NA400_R135_T36NXG_20220511T103313.tif\n",
      "2024-08-05 17:32:14,943: INFO: Image number 10 has time stamp 20220516T074621\n",
      "2024-08-05 17:32:14,944: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220516T074621_NA400_R135_T36NXG_20220516T124012.tif\n",
      "2024-08-05 17:32:14,947: INFO: Image number 11 has time stamp 20220521T074609\n",
      "2024-08-05 17:32:14,949: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220521T074609_NA400_R135_T36NXG_20220521T102923.tif\n",
      "2024-08-05 17:32:14,951: INFO: Image number 12 has time stamp 20220615T074621\n",
      "2024-08-05 17:32:14,953: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220615T074621_NA400_R135_T36NXG_20220615T113017.tif\n",
      "2024-08-05 17:32:14,954: INFO: Image number 13 has time stamp 20220918T074619\n",
      "2024-08-05 17:32:14,956: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220918T074619_NA400_R135_T36NXG_20220918T101459.tif\n",
      "2024-08-05 17:32:14,958: INFO: Image number 14 has time stamp 20221013T074851\n",
      "2024-08-05 17:32:14,959: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20221013T074851_NA400_R135_T36NXG_20221013T112156.tif\n",
      "2024-08-05 17:32:14,960: INFO: Image number 15 has time stamp 20221202T075301\n",
      "2024-08-05 17:32:14,961: INFO:   File: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20221202T075301_NA400_R135_T36NXG_20221202T111602.tif\n",
      "2024-08-05 17:32:14,979: INFO: Creating median composite at Z:\\gy7709\\36NXG\\composite\\composite_T36NXG_20221202T075301.tif\n",
      "2024-08-05 17:32:16,054: INFO: Chunk processing. 5 chunks per band of size 2208, 11039.\n",
      "2024-08-05 17:32:16,068: INFO: Processing chunk 1\n",
      "2024-08-05 17:33:04,825: INFO: Processing chunk 2\n",
      "2024-08-05 17:33:55,285: INFO: Processing chunk 3\n",
      "2024-08-05 17:34:51,589: INFO: Processing chunk 4\n",
      "2024-08-05 17:35:42,527: INFO: Processing chunk 5\n",
      "2024-08-05 17:36:53,994: INFO: Raster file stats for Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band1.tif\n",
      "2024-08-05 17:36:54,021: INFO:    band_1 : min=4.000, max=9000.000000, mean=490.089294, stdev=153.043030\n",
      "2024-08-05 17:36:55,054: INFO: Chunk processing. 5 chunks per band of size 2208, 11039.\n",
      "2024-08-05 17:36:55,057: INFO: Processing chunk 1\n",
      "2024-08-05 17:37:44,261: INFO: Processing chunk 2\n",
      "2024-08-05 17:38:36,233: INFO: Processing chunk 3\n",
      "2024-08-05 17:39:30,275: INFO: Processing chunk 4\n",
      "2024-08-05 17:40:21,909: INFO: Processing chunk 5\n",
      "2024-08-05 17:41:28,074: INFO: Raster file stats for Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band2.tif\n",
      "2024-08-05 17:41:28,105: INFO:    band_1 : min=31.000, max=9064.000000, mean=766.868958, stdev=190.453461\n",
      "2024-08-05 17:41:28,957: INFO: Chunk processing. 5 chunks per band of size 2208, 11039.\n",
      "2024-08-05 17:41:28,957: INFO: Processing chunk 1\n",
      "2024-08-05 17:42:19,667: INFO: Processing chunk 2\n",
      "2024-08-05 17:43:12,061: INFO: Processing chunk 3\n",
      "2024-08-05 17:44:03,325: INFO: Processing chunk 4\n",
      "2024-08-05 17:44:59,425: INFO: Processing chunk 5\n",
      "2024-08-05 17:46:08,760: INFO: Raster file stats for Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band3.tif\n",
      "2024-08-05 17:46:08,788: INFO:    band_1 : min=31.000, max=9296.000000, mean=818.038269, stdev=328.913483\n",
      "2024-08-05 17:46:09,748: INFO: Chunk processing. 5 chunks per band of size 2208, 11039.\n",
      "2024-08-05 17:46:09,748: INFO: Processing chunk 1\n",
      "2024-08-05 17:46:59,511: INFO: Processing chunk 2\n",
      "2024-08-05 17:47:50,204: INFO: Processing chunk 3\n",
      "2024-08-05 17:48:42,654: INFO: Processing chunk 4\n",
      "2024-08-05 17:49:34,774: INFO: Processing chunk 5\n",
      "2024-08-05 17:50:42,224: INFO: Raster file stats for Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band4.tif\n",
      "2024-08-05 17:50:42,254: INFO:    band_1 : min=1.000, max=14216.000000, mean=2526.416016, stdev=625.400269\n",
      "2024-08-05 17:50:42,355: INFO: Merging band rasters into a single file:\n",
      "2024-08-05 17:50:42,355: INFO:   Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band1.tif\n",
      "2024-08-05 17:50:42,357: INFO:   Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band2.tif\n",
      "2024-08-05 17:50:42,359: INFO:   Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band3.tif\n",
      "2024-08-05 17:50:42,361: INFO:   Z:\\gy7709\\pyeo\\tmp3x5au1mv\\composite_T36NXG_20221202T075301_band4.tif\n",
      "2024-08-05 17:54:02,167: INFO: Raster file stats for Z:\\gy7709\\36NXG\\composite\\composite_T36NXG_20221202T075301.tif\n",
      "2024-08-05 17:54:02,170: INFO:    band_1 : min=4.000, max=9000.000000, mean=5.470953, stdev=508.115612\n",
      "2024-08-05 17:54:02,171: INFO:    band_2 : min=31.000, max=9064.000000, mean=-15.896130, stdev=805.525997\n",
      "2024-08-05 17:54:02,172: INFO:    band_3 : min=31.000, max=9296.000000, mean=-1.982777, stdev=883.476824\n",
      "2024-08-05 17:54:02,173: INFO:    band_4 : min=1.000, max=14216.000000, mean=-8.156320, stdev=2610.591044\n",
      "2024-08-05 17:54:03,904: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 17:54:03,904: INFO: Baseline composite complete.\n",
      "2024-08-05 17:54:03,908: INFO: ---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\n",
    "            \"Building initial cloud-free median composite from directory {}\".format(\n",
    "                composite_l2_masked_image_dir\n",
    "            )\n",
    "        )\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        directory = composite_l2_masked_image_dir\n",
    "        masked_file_paths = [\n",
    "            f\n",
    "            for f in os.listdir(directory)\n",
    "            if f.endswith(\".tif\") and os.path.isfile(os.path.join(directory, f))\n",
    "        ]\n",
    "\n",
    "        if len(masked_file_paths) > 0:\n",
    "            raster_manipulation.clever_composite_directory(\n",
    "                composite_l2_masked_image_dir,\n",
    "                composite_dir,\n",
    "                chunks=config_dict[\"chunks\"],\n",
    "                generate_date_images=True,\n",
    "                missing_data_value=0,\n",
    "                log=tile_log\n",
    "            )\n",
    "            tile_log.info(\"---------------------------------------------------------------\")\n",
    "            tile_log.info(\"Baseline composite complete.\")\n",
    "            tile_log.info(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2762c54",
   "metadata": {},
   "source": [
    "## Create Quicklook of the Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2321632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:27:04,903: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 18:27:04,905: INFO: Producing quicklooks.\n",
      "2024-08-05 18:27:04,906: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 18:27:04,908: INFO: Creating quicklook: Z:\\gy7709\\36NXG\\output\\quicklooks\\composite_T36NXG_20221202T075301.png\n",
      "2024-08-05 18:27:18,571: INFO: Quicklooks complete.\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    if config_dict[\"do_quicklooks\"] or config_dict[\"do_all\"]:\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        tile_log.info(\"Producing quicklooks.\")\n",
    "        tile_log.info(\"---------------------------------------------------------------\")\n",
    "        dirs_for_quicklooks = [composite_dir]\n",
    "        for main_dir in dirs_for_quicklooks:\n",
    "            files = [\n",
    "                f.path\n",
    "                for f in os.scandir(main_dir)\n",
    "                if f.is_file() and os.path.basename(f).endswith(\".tif\")\n",
    "            ]\n",
    "            if len(files) == 0:\n",
    "                tile_log.warning(\"No images found in {}.\".format(main_dir))\n",
    "            else:\n",
    "                for f in files:\n",
    "                    quicklook_path = os.path.join(\n",
    "                        quicklook_dir,\n",
    "                        os.path.basename(f).split(\".\")[0] + \".png\",\n",
    "                    )\n",
    "                    tile_log.info(\n",
    "                        \"Creating quicklook: {}\".format(quicklook_path)\n",
    "                    )\n",
    "                    raster_manipulation.create_quicklook(\n",
    "                        in_raster_path = f,\n",
    "                        out_raster_path = quicklook_path,\n",
    "                        width = 512,\n",
    "                        height = 512,\n",
    "                        format = \"PNG\",\n",
    "                        bands = [3, 2, 1],\n",
    "                        nodata = 0,\n",
    "                        scale_factors=[[0, 2000, 0, 255]],\n",
    "                        log=tile_log\n",
    "                    )\n",
    "        tile_log.info(\"Quicklooks complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc25d1c",
   "metadata": {},
   "source": [
    "## Final Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2c3c7",
   "metadata": {},
   "source": [
    "Now that we have created our composite and produced any quicklooks, we tell `pyeo` to delete or compress the cloud-masked L2A images that the composite was derived from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200fcba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:28:24,179: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 18:28:24,179: INFO: Compressing tiff files in directory Z:\\gy7709\\36NXG\\composite and all subdirectories\n",
      "2024-08-05 18:28:24,179: INFO: ---------------------------------------------------------------\n",
      "2024-08-05 18:28:24,222: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\composite_T36NXG_20221202T075301.tif\n",
      "2024-08-05 18:28:24,244: INFO: GeoTiff file: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220106T075321_N0301_R135_T36NXG_20220106T112039.tif\n",
      "2024-08-05 18:28:24,245: INFO: Current compression: None\n",
      "2024-08-05 18:28:24,246: INFO: Compressing\n",
      "2024-08-05 18:28:55,752: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220126T075211_NA400_R135_T36NXG_20220126T111035.tif\n",
      "2024-08-05 18:28:55,783: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220307T074801_NA400_R135_T36NXG_20220307T113320.tif\n",
      "2024-08-05 18:28:55,801: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220406T074611_NA400_R135_T36NXG_20220406T102936.tif\n",
      "2024-08-05 18:28:55,817: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220516T074621_NA400_R135_T36NXG_20220516T124012.tif\n",
      "2024-08-05 18:28:55,834: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20220615T074621_NA400_R135_T36NXG_20220615T113017.tif\n",
      "2024-08-05 18:28:55,856: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20221013T074851_NA400_R135_T36NXG_20221013T112156.tif\n",
      "2024-08-05 18:28:55,883: INFO: GeoTiff file is already LZW compressed: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2A_MSIL2A_20221202T075301_NA400_R135_T36NXG_20221202T111602.tif\n",
      "2024-08-05 18:28:55,900: INFO: GeoTiff file: Z:\\gy7709\\36NXG\\composite\\cloud_masked\\S2B_MSIL2A_20220111T075209_N0301_R135_T36NXG_20220111T102011.tif\n",
      "2024-08-05 18:28:55,900: INFO: Current compression: None\n",
      "2024-08-05 18:28:55,900: INFO: Compressing\n"
     ]
    }
   ],
   "source": [
    "if config_dict[\"build_composite\"] or config_dict[\"do_all\"]:\n",
    "    if config_dict[\"do_quicklooks\"] or config_dict[\"do_all\"]:\n",
    "        if config_dict[\"do_delete\"]:\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"Deleting intermediate cloud-masked L2A images used for the baseline composite\"\n",
    "            )\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            f = composite_l2_masked_image_dir\n",
    "            tile_log.info(\"Deleting {}\".format(f))\n",
    "            shutil.rmtree(f)\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "            tile_log.info(\"Intermediate file products have been deleted.\")\n",
    "            tile_log.info(\"They can be reprocessed from the downloaded L2A images.\")\n",
    "            tile_log.info(\n",
    "                \"---------------------------------------------------------------\"\n",
    "            )\n",
    "        else:\n",
    "            if config_dict[\"do_zip\"]:\n",
    "                tile_log.info(\n",
    "                    \"---------------------------------------------------------------\"\n",
    "                )\n",
    "                tile_log.info(\n",
    "                    \"Zipping cloud-masked L2A images used for the baseline composite\"\n",
    "                )\n",
    "                tile_log.info(\n",
    "                    \"---------------------------------------------------------------\"\n",
    "                )\n",
    "                filesystem_utilities.zip_contents(composite_l2_masked_image_dir)\n",
    "                tile_log.info(\n",
    "                    \"---------------------------------------------------------------\"\n",
    "                )\n",
    "                tile_log.info(\"Zipping complete\")\n",
    "                tile_log.info(\n",
    "                    \"---------------------------------------------------------------\"\n",
    "                )\n",
    "\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"Compressing tiff files in directory {} and all subdirectories\".format(\n",
    "                composite_dir\n",
    "            )\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        for root, dirs, files in os.walk(composite_dir):\n",
    "            all_tiffs = [\n",
    "                image_name for image_name in files if image_name.endswith(\".tif\")\n",
    "            ]\n",
    "            for this_tiff in all_tiffs:\n",
    "                raster_manipulation.compress_tiff(\n",
    "                    os.path.join(root, this_tiff), \n",
    "                    os.path.join(root, this_tiff),\n",
    "                    tile_log\n",
    "                )\n",
    "\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )\n",
    "        tile_log.info(\n",
    "            \"Baseline image composite, file compression, zipping and deletion of\"\n",
    "        )\n",
    "        tile_log.info(\"intermediate file products (if selected) are complete.\")\n",
    "        tile_log.info(\n",
    "            \"---------------------------------------------------------------\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
