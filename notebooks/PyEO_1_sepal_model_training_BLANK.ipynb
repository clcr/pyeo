{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216ee4c6-369b-403e-8b96-347bb1bc57ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyEO Machine Learning: How to train your classifier.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e031da1",
   "metadata": {},
   "source": [
    "- Here we will create a model to classify land cover (and thus enable the detection changes in forest cover between two date periods).\n",
    "- To build a model, we will need training data. For PyEO, we define training data as pixel surface reflectance values over multiple wavebands and their corresponding 'true' land cover classes to which they should ideally be assigned by the model\n",
    "- The next section below details how to generate this training data by manually delineating polygons using the QGIS software package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597774d",
   "metadata": {},
   "source": [
    "# Delineate Sample Areas using QGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d59a8-24bb-48c8-a5e5-7ddd246bb76d",
   "metadata": {},
   "source": [
    "## Live Demo: Training Sample Delineation over Mau Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b68b3b-9313-41fc-8e98-dab9472aa570",
   "metadata": {},
   "source": [
    "- Prof. Heiko Balzter will show a live demo of how to delineate training data in QGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cefa3",
   "metadata": {},
   "source": [
    "## Instructional Video: Training sample delineation over Rutland, UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd875a49",
   "metadata": {},
   "source": [
    "- Additionally, a recording of a previous demo is included with the files we distributed to attendees earlier, to view at your leisure.\n",
    "    - Alternatively, use this [link](https://drive.google.com/file/d/1d-eaZ3iOcruZyv35G3wRqHakUWiMoJl-/view?usp=sharing]) to watch the video Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c425d-c751-4612-8431-7f5f42133eac",
   "metadata": {},
   "source": [
    "## QGIS Training Data Specification Process Guide\n",
    "- In the left hand panel of JupyterLab, navigate to `pyeo/models` within your installation directory and right click to download the sample image to your laptop\n",
    "  - You need the file `composite_T36MYE_20230220T074941_clipped.tif`\n",
    "- Once downloaded, open the image in QGIS on your laptop\n",
    "- Add a shapefile layer\n",
    "- Toggle editing of the shapefile layer\n",
    "- Add a field which should be integer and named `class`\n",
    "- Delineate features using the **Add Polygon Feature** tool. It looks like this: ![image](./Create_polygon.PNG) \n",
    "- Add training polygons for classes of interest to your shape file. \n",
    "- So that we can compare results please train for the following land use classes, using the integer CODE assigned to each in the table below:\n",
    "  - `Primary Forest` 1; \n",
    "  - `Plantation Forest` 2;\n",
    "  - `Bare Soil` 3;\n",
    "  - `Crops` 4;\n",
    "  - `Grassland` 5;\n",
    "  - `Artificial` 13;\n",
    "- Save your shapefile to your laptop hard drive\n",
    "- Use the 'Upload' button to bring your saved shapefile to the folder 'model_dir' within your PyEO installation on SEPAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9f32f",
   "metadata": {},
   "source": [
    "## QGIS Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9aeab",
   "metadata": {},
   "source": [
    "- Whilst in QGIS, make sure you have the **Digitizing** and **Advanced Digitizing** toolbars enabled. To do so, click:  \n",
    "    - View > Toolbars > Tick Digitizing and Advanced Digitizing\n",
    "- Avoid delineating near the edges of land cover, e.g. at the forest edge adjacent to a road. These edge pixels will capture the variation in land-cover at the sub-pixel level, confusing your classifier. \n",
    "- The **Reshape Features** tool, is extremely useful for extending already delineated polygons. Click inside the polygon you want to extend, then click any points outside of the polygon (covering your land cover class of interest), once ready - click inside the polygon to complete the loop, and right click to finish delineation. The tool icon looks like this: ![image](./Reshape_features.PNG)\n",
    "- Install Google Earth Pro on your PC, https://www.google.com/earth/about/versions/ , which offers very-high resolution satellite imagery, and Google StreetView, to help you understand the land covers you are delineating.\n",
    "- Install the QGIS plugin, **Send2GE**. This plugin sends your location directly to your installed Google Earth Pro. To do so, click on the Send2GE icon, ![image](./Send2GE.PNG), and then click on the location you want to view in Google Earth Pro.\n",
    "- When developing models in future you may wish to develop your own choice of Land Cover classes and tailor them to what you want your model to achieve. Listed below is the full list of classes that we have evaluated for our `PyEO` forest alert classifier, but alternative classes may be more appropriate for your needs.\n",
    "\n",
    "    1. Primary Forest\n",
    "    2. Plantation Forest\n",
    "    3. Bare Soil\n",
    "    4. Crops\n",
    "    5. Grassland\n",
    "    6. Open Water\n",
    "    7. Burn Scar\n",
    "    8. Cloud\n",
    "    9. Cloud Shadow\n",
    "    10. Haze\n",
    "    11. Sparse Woodland\n",
    "    12. Dense Woodland\n",
    "    13. Artificial\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c526c",
   "metadata": {},
   "source": [
    "# Setup: Requirements to use this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b7821-1418-485c-bec9-a5b1d4356776",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select the virtual environment\n",
    "- Use the drop-down list at the top right of the Jupyter notebook window\n",
    "- Select `(venv) Python for Earth Observation (PyEO)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55421d-8756-4d52-8970-c43376989d27",
   "metadata": {},
   "source": [
    "## Check the working directory is set to `pyeo` within your PyEO installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1327872-0a99-465a-ac20-8cc72c8caa13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f4e43-3090-4bc6-adcc-b66b871ae217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /home/sepal-user/20230626_pyeo_installation/pyeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b958bb-5431-41e1-bee6-8bd3399f5e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cef591",
   "metadata": {},
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e165f-1880-46eb-9506-2d63139c9f2c",
   "metadata": {},
   "source": [
    "Before proceeding, let's check that the import statements from pyeo execute correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pyeo import classification as cls\n",
    "from pyeo import filesystem_utilities as file_utils\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble as ens\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "print(\"Library imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d58bd",
   "metadata": {},
   "source": [
    "# Specify the Model Storage Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5cfce7-3f18-4051-9130-3f32eee6a991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyeo_dir = \"/home/sepal-user/20230626_pyeo_installation/pyeo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092654c4-8590-4e75-ab8f-705eefdd0efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(pyeo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7229b0-32ea-4277-bc95-f39792cc46f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a5bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"./models/my_model\"\n",
    "log_dir = \"./log\"\n",
    "\n",
    "# Create the folder if it doesn't yet exist\n",
    "os.chdir(pyeo_dir)\n",
    "if not os.path.exists(model_dir): \n",
    "    os.mkdir(model_dir)\n",
    "if not os.path.exists(log_dir): \n",
    "    os.mkdir(log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7e3f5-712d-4ec8-8e8e-88a37b189656",
   "metadata": {},
   "source": [
    "- Use the File Browser to check your new folder now exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e8447",
   "metadata": {},
   "source": [
    "# Initialise Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0bab2",
   "metadata": {},
   "source": [
    "- When running `PyEO`, we record our processing efforts, parameters etc. in a log file (a `.log` file).\n",
    "- If we are ever curious about what `PyEO` has done and when, we can look at the log file.  \n",
    "- Below, we initialise our log file \n",
    "- **Note: the .log does not need to exist before running the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52bacb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_filename = \"model_log.log\"\n",
    "log = file_utils.init_log(os.path.join(log_dir, log_filename))\n",
    "\n",
    "# Let's add some information to the log\n",
    "log.info(f'pyeo_Model_Training Notebook Started:')\n",
    "log.info(f'- pyeo_dir set to: {pyeo_dir}')\n",
    "log.info(f'- model_dir set to: {model_dir}')\n",
    "log.info(f'- log_dir set to: {log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac9a06",
   "metadata": {},
   "source": [
    "- Whenever a function writes to the log, the output will be displayed in the Python cell output, but the log file can also be viewed in a text editor.  \n",
    "- **Right-Click on model_log.txt in the JupyterLab explorer to the left and select 'open' to view in a tab within JupyterLab.**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ee6c1",
   "metadata": {},
   "source": [
    "# Model Training and Classification, Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b904e",
   "metadata": {},
   "source": [
    "- In this section, we will follow the individual steps to extract spectral information from the Sentinel-2 imagery using our training shapefiles, train a Random Forest model on the spectral values of the land cover classes, and classify a Sentinel-2 image tile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c6a58",
   "metadata": {},
   "source": [
    "## Extract Spectral Information from Sentinel-2 Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472abb8-5507-43a6-88a0-37466d8f4962",
   "metadata": {},
   "source": [
    "- Since we have delineated our training polygons, we can now extract the spectral information from the imagery, by running `cls.extract_features_to_csv()` in the cell below.  \n",
    "- First, specify the paths to the training shapefile, training raster and the out directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52ab52-e797-4523-8146-af4245fcf8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the path of the training shapefile\n",
    "training_shape_filename = \"composite_T36MYE_20230220T074941_clipped_features.shp\"\n",
    "# specify the path of the training raster\n",
    "training_raster_filename = \"composite_T36MYE_20230220T074941_clipped.tif\"\n",
    "# specify the output folder\n",
    "out_dir = model_dir\n",
    "# specify the output filename for the model\n",
    "model_name = \"my_model\"\n",
    "model_out_filename = f\"{model_name}.pkl\"\n",
    "# specify the output filename for the csv\n",
    "feature_out_filename = f'{model_name}_features.csv'\n",
    "\n",
    "log.info(f'File and Folder Specification Started::')\n",
    "log.info(f'- training_shape_filename set to: {training_shape_filename}')\n",
    "log.info(f'- training_raster_filename set to: {training_raster_filename}')\n",
    "log.info(f'- out_dir set to: {out_dir}')\n",
    "log.info(f'- model_out_filename set to: {model_out_filename}')\n",
    "log.info(f'- feature_out_filename set to: {feature_out_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d41973",
   "metadata": {},
   "source": [
    "### Create `out_folder` if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47425b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists(os.path.join(pyeo_dir, out_dir)):\n",
    "    # os.mkdir(os.path.join(pyeo_dir, out_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747e16f",
   "metadata": {},
   "source": [
    "### Run `extract_features_to_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733353e",
   "metadata": {},
   "source": [
    "Now, we can run the `cls.extract_features_to_csv` function.  \n",
    "If the column heading of your training shapefile is not `CODE`, substitute the correct column name with the `attribute` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972137b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declare our path variables as easier to read variables\n",
    "out_path = os.path.join(out_dir, feature_out_filename)\n",
    "training_raster_path = os.path.join(model_dir, training_raster_filename)\n",
    "training_shapefile_path = os.path.join(model_dir, training_shape_filename)\n",
    "\n",
    "log.info(f'Feature Extraction Started:')\n",
    "log.info(f'- out_path set to: {out_path}')\n",
    "log.info(f'- training_raster_path set to: {training_raster_path}')\n",
    "log.info(f'- training_shapefile_path set to: {training_shapefile_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c58935-b8db-4979-9164-6721a75d8d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the function to extract the spectral values and assigned classes from the training raster and training shapefile\n",
    "cls.extract_features_to_csv(in_ras_path=training_raster_path,\n",
    "                            training_shape_path=training_shapefile_path,\n",
    "                            out_path=out_path,\n",
    "                            attribute=\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8dded-36ab-4a1c-b01c-3c94a57a4f86",
   "metadata": {},
   "source": [
    "- Let's see what `features.csv` looks like, by reading in the csv and printing the first 5 rows.  \n",
    "- Each row represents a pixel of a certain class. The first column in each row is the class of that pixel, with the columns after that being the Sentinel 2 blue, green, red and NIR value of that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a23871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declare out_path from previous cell as csv_path, to avoid confusion\n",
    "csv_path = out_path\n",
    "\n",
    "# read in our spectral signatures\n",
    "features = pd.read_csv(csv_path)\n",
    "\n",
    "features.columns = [\"class\", \"R\", \"G\", \"B\", \"NIR\"]\n",
    "\n",
    "# prints the first 5 rows of features\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf8c6e-0da9-4485-930c-57ed4c5974ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffab395-617e-40e3-9947-46acfcb9f9f6",
   "metadata": {},
   "source": [
    "- Note: your model folder should now contain a .csv file of features - check using the file explorer on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1ed4c",
   "metadata": {},
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781a305-df46-4492-b14a-d8b6e6b13dc3",
   "metadata": {},
   "source": [
    "- Now we can create a scikit-learn Extra Trees Classifier using PyEO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893f1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(f'Model Building Started:')\n",
    "\n",
    "# initialise an Extra Trees Classifier\n",
    "model = ens.ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.55, min_samples_leaf=2,\n",
    "                                    min_samples_split=16, n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# load signatures from csv file\n",
    "features, labels = cls.load_signatures(csv_path, sig_datatype=np.int32)\n",
    "\n",
    "# split into test and train samples, reserving 25% for testing model accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=.25, random_state=101)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save the model\n",
    "model_path = os.path.join(out_dir, model_out_filename)\n",
    "joblib.dump(model, filename = model_path)\n",
    "\n",
    "log.info(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141c983-f92c-41ff-a1a9-11a0a87cd20b",
   "metadata": {},
   "source": [
    "- Note: your model folder should now contain a .pkl file containing your model - check using the file explorer on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fed51",
   "metadata": {},
   "source": [
    "## Accuracy Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f882e83",
   "metadata": {},
   "source": [
    "- Now that we have a model trained from shapefiles defined over Sentinel-2 image tile, we should assess the model accuracy.  \n",
    "- To do that, we will use the model to predict the classes of `y_test` from the values of `X_test`, which comprise the 25% that we reserved for testing model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb4a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(f'Model Performance Analysis Started:')\n",
    "\n",
    "confusion_matrix_out_filename = f'{model_name}_confusion_matrix.txt'\n",
    "class_scores_out_filename = f'{model_name}_class_scores.txt'\n",
    "\n",
    "# make a prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create a confusion matrix\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred,)\n",
    "\n",
    "# write the confusion matrix to file\n",
    "with open(os.path.join(out_dir, confusion_matrix_out_filename), \"w\") as txt:\n",
    "    print(matrix, file=txt)\n",
    "\n",
    "# write classification labels\n",
    "target_names = [\"Primary Forest\",\n",
    "          \"Plantation Forest\",\n",
    "          \"Bare Soil\",\n",
    "          \"Crops\",\n",
    "          \"Grassland\",\n",
    "          \"Artificial\"]\n",
    "\n",
    "# view the matrix\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d873269-e7e6-4878-a39a-1ceff7e55f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create classification metrics report\n",
    "report = classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names, digits=6)\n",
    "\n",
    "# write classification report to file\n",
    "with open(os.path.join(out_dir, class_scores_out_filename), \"w\") as txt:\n",
    "    print(report, file=txt)\n",
    "\n",
    "# view the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daad613",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2b312",
   "metadata": {},
   "source": [
    "- Once we are happy with the performance of the model we can now classify a Sentinel-2 image tiles so long as they have similar land use and vegetation cover (and thus spectral characteristics) to the imagery used to train the model.\n",
    "- Here, we will simply use our training image and see how well the classification extends over the untrained areas of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896f468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(f'Image Classification with Model Started:')\n",
    "\n",
    "# test_raster_path = training_raster_path\n",
    "test_raster_filename = 'composite_T36MYE_20230220T074941_clipped.tif'\n",
    "test_raster_path = os.path.join(model_dir, test_raster_filename)\n",
    "\n",
    "class_out_filename = f'{os.path.splitext(test_raster_filename)[0]}_full_class.tif'\n",
    "class_out_path = os.path.join(out_dir, class_out_filename)\n",
    "\n",
    "cls.classify_image(image_path=test_raster_path,\n",
    "                   model_path=model_path,\n",
    "                   class_out_path=class_out_path,\n",
    "                   prob_out_path=None,\n",
    "                   apply_mask=False,\n",
    "                   out_format=\"GTiff\",\n",
    "                   chunks=10,\n",
    "                   nodata=0,\n",
    "                   skip_existing = False)\n",
    "\n",
    "log.info(f'Classified Image Saved: {class_out_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ed5e4-2307-4f3d-9fda-95f2beb33bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Note: your model folder should now contain a classified image with '_full_class' appended to the raw image name - check using the file explorer on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725b6fa",
   "metadata": {},
   "source": [
    "## Visualise the Classified Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16f6d0",
   "metadata": {},
   "source": [
    "Now we can now define a function to colormap and visualise the classified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a695a-a00d-46c9-91d9-be81df81147d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Visualise the Classified Imagery\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from osgeo import gdal\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "log.info(f'Classified Image Visualisation function has been defined.')\n",
    "\n",
    "def visualise_classification(classified_path: str, labels: list):\n",
    "\n",
    "    ds = gdal.Open(classified_path)\n",
    "    array = np.array(ds.GetRasterBand(1).ReadAsArray())\n",
    "   \n",
    "    unique, _counts = np.unique(array, return_counts=True)\n",
    "\n",
    "    counts=list(np.zeros(max(unique)+1,'int'))\n",
    "    for i in range(0, len(_counts)):\n",
    "        counts[unique[i]] = _counts[i]\n",
    "\n",
    "    #counts, _ = np.histogram(array, bins = len(labels))\n",
    "    print(counts)\n",
    "   \n",
    "    percent = counts / sum(counts)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "\n",
    "\n",
    "    def discrete_cmap(N, base_cmap=None):\n",
    "        \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "        # this function was taken on 10/03/2023 from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "        # author: Jake Vanderplas\n",
    "        \n",
    "        # warnings.filterwarnings(\"ignore\", category=MatplotlibDeprecationWarning)\n",
    "        base = plt.cm.get_cmap(base_cmap)\n",
    "        color_list = base(np.linspace(0, 1, N))\n",
    "        cmap_name = base.name + str(N)\n",
    "        return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "    cmap = discrete_cmap(len(labels), base_cmap=\"coolwarm\")\n",
    "    # cmap = discrete_cmap(len(labels), base_cmap=\"cubehelix\")\n",
    "    # cmap.set_bad(\"red\")\n",
    "    colour_list = [mcolors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "    if cmap.N <=14:\n",
    "        log.info(\"Defining custom colour table for up to 13 classes and a missing data class of 0 (0..13)\")\n",
    "        colour_list = [\n",
    "                      [0, 0, 0, 1],  # no data\n",
    "                      [0, 100/255, 0, 1],  # Primary Forest\n",
    "                      [154/255, 205/255, 50/255, 1],  # plantation Forest\n",
    "                      [139/255, 69/255, 19/255, 1],  # Bare Soil\n",
    "                      [189/255, 183/255, 107/255, 1],  # Crops\n",
    "                      [240/255, 230/255, 140/255, 1],  # Grassland\n",
    "                      [0, 0, 205/255, 1],  # Open Water\n",
    "                      [128/255, 0, 0, 1],  # Burn Scar\n",
    "                      [255/255, 255/255, 255/255, 1],  # cloud\n",
    "                      [60/255, 60/255, 60/255, 1],  # cloud shadow\n",
    "                      [128/255, 128/255, 128/255, 1],  # Haze\n",
    "                      [46/255, 139/255, 87/255, 1],  # Open Woodland\n",
    "                      [92/255, 145/255, 92/255, 1],  # Closed Woodland\n",
    "                      [255/255, 30/255, 30/255, 1]  # Artificial\n",
    "                      ]\n",
    "    # Create the colormap\n",
    "    n_bins = len(labels)\n",
    "    cmap_name = 'my_colour_map'\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colour_list, N=n_bins)\n",
    "   \n",
    "    x = np.arange(0, len(labels))\n",
    "    ax1.bar(x, percent, color=colour_list)\n",
    "    ax1.set_title(\"Classes distribution\")\n",
    "    ax2.set_title(\"Classification raster displayed\")\n",
    "    ax2.imshow(array, cmap=cmap, aspect=\"auto\", vmin=-0.5, vmax=len(labels)+0.5)\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54feb6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of class labels\n",
    "\n",
    "labels = [\n",
    "    \"No Data\",\n",
    "    \"Primary Forest\",\n",
    "    \"Plantation Forest\",\n",
    "    \"Bare Soil\",\n",
    "    \"Crops\",\n",
    "    \"Grassland\",\n",
    "    \"Open Water\",\n",
    "    \"Burn Scar\",\n",
    "    \"Cloud\",\n",
    "    \"Cloud Shadow\",\n",
    "    \"Haze\",\n",
    "    \"Open Woodland\",\n",
    "    \"Closed Woodland\",\n",
    "    \"Artificial\"\n",
    "    ]\n",
    "\n",
    "visualise_classification(classified_path=class_out_path, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68d643",
   "metadata": {},
   "source": [
    "# Extended Model Training and Classification\n",
    "- **NOTE: These PyEO capabilities are beyond the tutorial's scope but illustrative code and outputs are included below as a guide to their use**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee9c76-41df-4114-a26b-295b10e451b6",
   "metadata": {},
   "source": [
    "## Model Building from Multiple Tiles and Shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00405bc7",
   "metadata": {},
   "source": [
    "- PyEO can also train a Random Forest classifier on multiple Sentinel-2 tiles with multiple training shapefiles. This approach can create a superior classifier because the training shapefiles can cover more tiles, providing the model with a variety of spectral values per class, and thus show greater versatility over a wide range of seasonal land cover and variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b9659",
   "metadata": {},
   "source": [
    "The `create_rf_model_for_region` function assumes the training rasters and training shapefiles are structured like the cell diagram below.   \n",
    "**Note, the filenames do not need to be a specific format**\n",
    "\n",
    "The second function will we use is `classify_directory`, which classifies multiple images in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder\n",
    "    # training_raster_tile_1\n",
    "    # training_shapefile_tile_1\n",
    "    # training_raster_tile_2\n",
    "    # training_shapefile_tile_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyeo_home = \"/data/clcr/shared/IMPRESS/Ivan/kenya_national_prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86064c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_folder = \"models/model_36MYE_37MER_37NCC_20230417\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specify the path to the directory structure\n",
    "# region_folder = os.path.join(pyeo_home, out_folder)\n",
    "\n",
    "# # name the model that will be created\n",
    "# model_file = \"model_36MYE_37MER_37NCC_Unoptimised_20230417.pkl\"\n",
    "# model_path = os.path.join(region_folder, model_file)\n",
    "\n",
    "# cls.create_rf_model_for_region(path_to_region=region_folder,\n",
    "#                                model_out=model_path,\n",
    "#                                attribute=\"class\"\n",
    "#                                #,attribute=\"CODE\" # replace this line with the one above, if training shapefile has CODE as class heading\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view classification report metrics\n",
    "# with open(f\"{os.path.join(pyeo_home, out_folder)}{os.sep}class_scores.txt\", \"r\") as report:\n",
    "#     print(report.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd4242",
   "metadata": {},
   "source": [
    "## Classify Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac3097-2b6b-4ddc-99c4-ee89fa57d24b",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Another useful PyEO capability to be aware of is that classification (and other functions) can be automatically over a directory of images\n",
    "- This provides the basis to build automated data pipelines that process image sets as a chain from directory to directory\n",
    "- The code below shows how to classify a directory of images given its path, a random forest model to apply, and a destination folder for the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d39316",
   "metadata": {},
   "source": [
    "`cls.classify_directory` requires the `class_out_dir` to already exist, so make sure that this directory is present before running the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of the directory of images to classify\n",
    "# image_directory = pyeo_home\n",
    "\n",
    "# # provide the path of the classified output folder\n",
    "# class_out_dir = f\"{os.path.join(pyeo_home, out_folder)}{os.sep}\"\n",
    "\n",
    "# # run the function to classify the directory of images you provided\n",
    "# cls.classify_directory(in_dir=image_directory,\n",
    "#                        model_path=model_path,\n",
    "#                        class_out_dir=class_out_dir,\n",
    "#                        chunks=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b7e7c",
   "metadata": {},
   "source": [
    "## Visualise Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4c75b",
   "metadata": {},
   "source": [
    "Here, we can visualise the images we have just classified. Just pass the filename of the classified image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the directory of a classified image\n",
    "# classified_path = f\"{class_out_dir}/composite_T36NYF_20221202T075301_clipped_class.tif\"\n",
    "\n",
    "# # create a list of class labels. In this example we have more classes because the additional classes were delineated to train this region rf model.\n",
    "# labels = [\n",
    "#     \"Primary Forest\",\n",
    "#     \"Plantation Forest\",\n",
    "#     \"Bare Soil\",\n",
    "#     \"Crops\",\n",
    "#     \"Grassland\",\n",
    "#     \"Open Water\",\n",
    "#     \"Artificial\"\n",
    "# ]\n",
    "\n",
    "# visualise_classification(classified_path=classified_path, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specify the directory of a classified image\n",
    "# classified_path = f\"{class_out_dir}/composite_T36MYE_20230220T074941_clipped_class.tif\"\n",
    "\n",
    "# visualise_classification(classified_path=classified_path, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ad189-d57e-4037-aacb-db843b4b23f3",
   "metadata": {},
   "source": [
    "**Question: Has this classifier done a better jo than than the simple one we created?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e17d9d-275f-4bcb-8b62-e93a049f604b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " (venv) Python for Earth Observation (PyEO)",
   "language": "python",
   "name": "venv-pyeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
